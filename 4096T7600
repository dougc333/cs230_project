
togrep : []

Namespace(LSTM_num_layers=1, batch_size=128, data_dir='/home/dc/cs230_project/dataset', decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=4096, encoder_type='InferSent', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=2, n_enc_layers=1, n_epochs=12, nlipath='/home/dc/InferSent/dataset/SNLI', nonlinear_fc=1, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='3layernonlinear4096.pickle', pool_type='max', seed=1234, weight_decay=0.0005, word_emb_dim=300)
quora checkpoint len(train[s1]):60623,len(train[s2]):60623,          len(train[label]):60623
============
len(valid['s1']):20208, len(valid[s2]):20208,           len(valid['label']):20208
============
len(test['s1']):20208,len(test['s2']):20208,           len(test['label']):20208
Found 47877(/106290) words with glove vectors
Vocab size : 47877
NLINet(
  (encoder): InferSent(
    (enc_lstm): LSTM(300, 4096, bidirectional=True)
  )
  (classifier): Sequential(
    (0): Linear(in_features=32768, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.0)
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.0)
    (8): Linear(in_features=512, out_features=512, bias=True)
    (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.0)
    (12): Linear(in_features=512, out_features=2, bias=True)
  )
)
total num epochs:12

TRAINING : Epoch 1
Learning rate : 0.1
<class 'torch.Tensor'> tensor(8597) 8597
12672 ; loss 0.6 ; sentence/s 156 ; words/s 11568 ; accuracy train : 67.16
<class 'torch.Tensor'> tensor(17671) 17671
25472 ; loss 0.55 ; sentence/s 158 ; words/s 11293 ; accuracy train : 69.03
<class 'torch.Tensor'> tensor(27053) 27053
38272 ; loss 0.52 ; sentence/s 155 ; words/s 11657 ; accuracy train : 70.45
<class 'torch.Tensor'> tensor(36481) 36481
51072 ; loss 0.51 ; sentence/s 154 ; words/s 11686 ; accuracy train : 71.25
results : epoch 1 ; mean accuracy train : 71.73

VALIDATION : Epoch 1
togrep : results : epoch 1 ; mean accuracy valid :              75.3
saving model at epoch 1

TRAINING : Epoch 2
Learning rate : 0.099
<class 'torch.Tensor'> tensor(9824) 9824
12672 ; loss 0.47 ; sentence/s 156 ; words/s 11489 ; accuracy train : 76.75
<class 'torch.Tensor'> tensor(19714) 19714
25472 ; loss 0.47 ; sentence/s 156 ; words/s 11632 ; accuracy train : 77.01
<class 'torch.Tensor'> tensor(29600) 29600
38272 ; loss 0.46 ; sentence/s 157 ; words/s 11346 ; accuracy train : 77.08
<class 'torch.Tensor'> tensor(39554) 39554
51072 ; loss 0.45 ; sentence/s 155 ; words/s 11617 ; accuracy train : 77.25
results : epoch 2 ; mean accuracy train : 77.42

VALIDATION : Epoch 2
togrep : results : epoch 2 ; mean accuracy valid :              76.87
saving model at epoch 2

TRAINING : Epoch 3
Learning rate : 0.09801
<class 'torch.Tensor'> tensor(10225) 10225
12672 ; loss 0.42 ; sentence/s 156 ; words/s 11493 ; accuracy train : 79.88
<class 'torch.Tensor'> tensor(20565) 20565
25472 ; loss 0.42 ; sentence/s 158 ; words/s 11294 ; accuracy train : 80.33
<class 'torch.Tensor'> tensor(30866) 30866
38272 ; loss 0.42 ; sentence/s 155 ; words/s 11468 ; accuracy train : 80.38
<class 'torch.Tensor'> tensor(41091) 41091
51072 ; loss 0.42 ; sentence/s 153 ; words/s 11771 ; accuracy train : 80.26
results : epoch 3 ; mean accuracy train : 80.36

VALIDATION : Epoch 3
togrep : results : epoch 3 ; mean accuracy valid :              77.89
saving model at epoch 3

TRAINING : Epoch 4
Learning rate : 0.0970299
<class 'torch.Tensor'> tensor(10692) 10692
12672 ; loss 0.38 ; sentence/s 152 ; words/s 11815 ; accuracy train : 83.53
<class 'torch.Tensor'> tensor(21285) 21285
25472 ; loss 0.38 ; sentence/s 158 ; words/s 11380 ; accuracy train : 83.14
<class 'torch.Tensor'> tensor(31958) 31958
38272 ; loss 0.37 ; sentence/s 156 ; words/s 11634 ; accuracy train : 83.22
<class 'torch.Tensor'> tensor(42589) 42589
51072 ; loss 0.37 ; sentence/s 155 ; words/s 11601 ; accuracy train : 83.18
results : epoch 4 ; mean accuracy train : 83.24

VALIDATION : Epoch 4
togrep : results : epoch 4 ; mean accuracy valid :              77.86
Shrinking lr by : 5. New lr = 0.01940598

TRAINING : Epoch 5
Learning rate : 0.0192119202
<class 'torch.Tensor'> tensor(11094) 11094
12672 ; loss 0.33 ; sentence/s 158 ; words/s 11290 ; accuracy train : 86.67
<class 'torch.Tensor'> tensor(22152) 22152
25472 ; loss 0.34 ; sentence/s 157 ; words/s 11382 ; accuracy train : 86.53
<class 'torch.Tensor'> tensor(33207) 33207
38272 ; loss 0.34 ; sentence/s 157 ; words/s 11484 ; accuracy train : 86.48
<class 'torch.Tensor'> tensor(44238) 44238
51072 ; loss 0.34 ; sentence/s 152 ; words/s 11787 ; accuracy train : 86.4
results : epoch 5 ; mean accuracy train : 86.46

VALIDATION : Epoch 5
togrep : results : epoch 5 ; mean accuracy valid :              78.8
saving model at epoch 5

TRAINING : Epoch 6
Learning rate : 0.019019800998
<class 'torch.Tensor'> tensor(11135) 11135
12672 ; loss 0.32 ; sentence/s 154 ; words/s 11664 ; accuracy train : 86.99
<class 'torch.Tensor'> tensor(22268) 22268
25472 ; loss 0.33 ; sentence/s 156 ; words/s 11498 ; accuracy train : 86.98
<class 'torch.Tensor'> tensor(33360) 33360
38272 ; loss 0.32 ; sentence/s 154 ; words/s 11573 ; accuracy train : 86.88
<class 'torch.Tensor'> tensor(44522) 44522
51072 ; loss 0.33 ; sentence/s 154 ; words/s 11589 ; accuracy train : 86.96
results : epoch 6 ; mean accuracy train : 87.03

VALIDATION : Epoch 6
togrep : results : epoch 6 ; mean accuracy valid :              78.88
saving model at epoch 6

TRAINING : Epoch 7
Learning rate : 0.01882960298802
<class 'torch.Tensor'> tensor(11264) 11264
12672 ; loss 0.32 ; sentence/s 155 ; words/s 11520 ; accuracy train : 88.0
<class 'torch.Tensor'> tensor(22547) 22547
25472 ; loss 0.31 ; sentence/s 155 ; words/s 11463 ; accuracy train : 88.07
<class 'torch.Tensor'> tensor(33713) 33713
38272 ; loss 0.32 ; sentence/s 156 ; words/s 11488 ; accuracy train : 87.79
<class 'torch.Tensor'> tensor(44985) 44985
51072 ; loss 0.31 ; sentence/s 157 ; words/s 11382 ; accuracy train : 87.86
results : epoch 7 ; mean accuracy train : 87.77

VALIDATION : Epoch 7
togrep : results : epoch 7 ; mean accuracy valid :              79.0
saving model at epoch 7

TRAINING : Epoch 8
Learning rate : 0.0186413069581398
<class 'torch.Tensor'> tensor(11284) 11284
12672 ; loss 0.31 ; sentence/s 158 ; words/s 11403 ; accuracy train : 88.16
<class 'torch.Tensor'> tensor(22626) 22626
25472 ; loss 0.3 ; sentence/s 155 ; words/s 11403 ; accuracy train : 88.38
<class 'torch.Tensor'> tensor(33960) 33960
38272 ; loss 0.31 ; sentence/s 157 ; words/s 11491 ; accuracy train : 88.44
<class 'torch.Tensor'> tensor(45325) 45325
51072 ; loss 0.3 ; sentence/s 152 ; words/s 11818 ; accuracy train : 88.53
results : epoch 8 ; mean accuracy train : 88.53

VALIDATION : Epoch 8
togrep : results : epoch 8 ; mean accuracy valid :              79.11
saving model at epoch 8

TRAINING : Epoch 9
Learning rate : 0.0184548938885584
<class 'torch.Tensor'> tensor(11445) 11445
12672 ; loss 0.29 ; sentence/s 153 ; words/s 11791 ; accuracy train : 89.41
<class 'torch.Tensor'> tensor(22822) 22822
25472 ; loss 0.3 ; sentence/s 156 ; words/s 11530 ; accuracy train : 89.15
<class 'torch.Tensor'> tensor(34240) 34240
38272 ; loss 0.3 ; sentence/s 156 ; words/s 11459 ; accuracy train : 89.17
<class 'torch.Tensor'> tensor(45668) 45668
51072 ; loss 0.29 ; sentence/s 156 ; words/s 11487 ; accuracy train : 89.2
results : epoch 9 ; mean accuracy train : 89.18

VALIDATION : Epoch 9
togrep : results : epoch 9 ; mean accuracy valid :              78.96
Shrinking lr by : 5. New lr = 0.00369097877771168

TRAINING : Epoch 10
Learning rate : 0.003654068989934563
<class 'torch.Tensor'> tensor(11560) 11560
12672 ; loss 0.28 ; sentence/s 155 ; words/s 11516 ; accuracy train : 90.31
<class 'torch.Tensor'> tensor(23101) 23101
25472 ; loss 0.28 ; sentence/s 154 ; words/s 11702 ; accuracy train : 90.24
<class 'torch.Tensor'> tensor(34599) 34599
38272 ; loss 0.29 ; sentence/s 156 ; words/s 11539 ; accuracy train : 90.1
<class 'torch.Tensor'> tensor(46067) 46067
51072 ; loss 0.29 ; sentence/s 156 ; words/s 11575 ; accuracy train : 89.97
results : epoch 10 ; mean accuracy train : 89.96

VALIDATION : Epoch 10
togrep : results : epoch 10 ; mean accuracy valid :              79.11
Shrinking lr by : 5. New lr = 0.0007308137979869126

TRAINING : Epoch 11
Learning rate : 0.0007235056600070435
<class 'torch.Tensor'> tensor(11507) 11507
12672 ; loss 0.28 ; sentence/s 158 ; words/s 11348 ; accuracy train : 89.9
<class 'torch.Tensor'> tensor(23056) 23056
25472 ; loss 0.28 ; sentence/s 154 ; words/s 11849 ; accuracy train : 90.06
<class 'torch.Tensor'> tensor(34589) 34589
38272 ; loss 0.28 ; sentence/s 155 ; words/s 11398 ; accuracy train : 90.08
<class 'torch.Tensor'> tensor(46179) 46179
51072 ; loss 0.28 ; sentence/s 156 ; words/s 11361 ; accuracy train : 90.19
results : epoch 11 ; mean accuracy train : 90.17

VALIDATION : Epoch 11
togrep : results : epoch 11 ; mean accuracy valid :              79.25
saving model at epoch 11

TRAINING : Epoch 12
Learning rate : 0.0007162706034069731
<class 'torch.Tensor'> tensor(11540) 11540
12672 ; loss 0.28 ; sentence/s 155 ; words/s 11462 ; accuracy train : 90.16
<class 'torch.Tensor'> tensor(23072) 23072
25472 ; loss 0.28 ; sentence/s 156 ; words/s 11654 ; accuracy train : 90.12
<class 'torch.Tensor'> tensor(34618) 34618
38272 ; loss 0.28 ; sentence/s 156 ; words/s 11398 ; accuracy train : 90.15
<class 'torch.Tensor'> tensor(46164) 46164
51072 ; loss 0.28 ; sentence/s 155 ; words/s 11557 ; accuracy train : 90.16
results : epoch 12 ; mean accuracy train : 90.18

VALIDATION : Epoch 12
togrep : results : epoch 12 ; mean accuracy valid :              79.18
Shrinking lr by : 5. New lr = 0.0001432541206813946
saving state dict
done saving state dict

TEST : Epoch 13
calculating validation error

VALIDATION : Epoch 1000000.0
finalgrep : accuracy valid : 79.18
calculating test error
finalgrep : accuracy test : 78.92
fin 5227.891575098038
