{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.py  encoder  models.py  mutils.py\t  README.md  train_nli.py\n",
      "dataset  LICENSE  MultiNLI   __pycache__  SNLI\t     Untitled.ipynb\n",
      "# Copyright (c) 2017-present, Facebook, Inc.\n",
      "# All rights reserved.\n",
      "#\n",
      "# This source code is licensed under the license found in the\n",
      "# LICENSE file in the root directory of this source tree.\n",
      "#\n",
      "\n",
      "\"\"\"\n",
      "This file contains the definition of encoders used in https://arxiv.org/pdf/1705.02364.pdf\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "import time\n",
      "\n",
      "import torch\n",
      "from torch.autograd import Variable\n",
      "import torch.nn as nn\n",
      "\n",
      "\"\"\"\n",
      "BLSTM (max/mean) encoder\n",
      "\"\"\"\n",
      "\n",
      "class InferSent(nn.Module):\n",
      "\n",
      "    def __init__(self, config):\n",
      "        super(InferSent, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "        self.version = 1 if 'version' not in config else config['version']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True, dropout=self.dpout_model)\n",
      "\n",
      "        assert self.version in [1, 2]\n",
      "        if self.version == 1:\n",
      "            self.bos = '<s>'\n",
      "            self.eos = '</s>'\n",
      "            self.max_pad = True\n",
      "            self.moses_tok = False\n",
      "        elif self.version == 2:\n",
      "            self.bos = '<p>'\n",
      "            self.eos = '</p>'\n",
      "            self.max_pad = False\n",
      "            self.moses_tok = True\n",
      "\n",
      "    def is_cuda(self):\n",
      "        # either all weights are on cpu or they are on gpu\n",
      "        return 'cuda' in str(type(self.enc_lstm.bias_hh_l0.data))\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (bsize)\n",
      "        # sent: Variable(seqlen x bsize x worddim)\n",
      "        sent, sent_len = sent_tuple\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "\n",
      "        idx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \\\n",
      "            else torch.from_numpy(idx_sort)\n",
      "        sent = sent.index_select(1, Variable(idx_sort))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)\n",
      "        sent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \\\n",
      "            else torch.from_numpy(idx_unsort)\n",
      "        sent_output = sent_output.index_select(1, Variable(idx_unsort))\n",
      "\n",
      "        # Pooling\n",
      "        if self.pool_type == \"mean\":\n",
      "            sent_len = Variable(torch.FloatTensor(sent_len.copy())).unsqueeze(1).cuda()\n",
      "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
      "            emb = emb / sent_len.expand_as(emb)\n",
      "        elif self.pool_type == \"max\":\n",
      "            if not self.max_pad:\n",
      "                sent_output[sent_output == 0] = -1e9\n",
      "            emb = torch.max(sent_output, 0)[0]\n",
      "            if emb.ndimension() == 3:\n",
      "                emb = emb.squeeze(0)\n",
      "                assert emb.ndimension() == 2\n",
      "\n",
      "        return emb\n",
      "\n",
      "    def set_w2v_path(self, w2v_path):\n",
      "        self.w2v_path = w2v_path\n",
      "\n",
      "    def get_word_dict(self, sentences, tokenize=True):\n",
      "        # create vocab of words\n",
      "        word_dict = {}\n",
      "        sentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\n",
      "        for sent in sentences:\n",
      "            for word in sent:\n",
      "                if word not in word_dict:\n",
      "                    word_dict[word] = ''\n",
      "        word_dict[self.bos] = ''\n",
      "        word_dict[self.eos] = ''\n",
      "        return word_dict\n",
      "\n",
      "    def get_w2v(self, word_dict):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        # create word_vec with w2v vectors\n",
      "        word_vec = {}\n",
      "        with open(self.w2v_path) as f:\n",
      "            for line in f:\n",
      "                word, vec = line.split(' ', 1)\n",
      "                if word in word_dict:\n",
      "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
      "        print('Found %s(/%s) words with w2v vectors' % (len(word_vec), len(word_dict)))\n",
      "        return word_vec\n",
      "\n",
      "    def get_w2v_k(self, K):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        # create word_vec with k first w2v vectors\n",
      "        k = 0\n",
      "        word_vec = {}\n",
      "        with open(self.w2v_path) as f:\n",
      "            for line in f:\n",
      "                word, vec = line.split(' ', 1)\n",
      "                if k <= K:\n",
      "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
      "                    k += 1\n",
      "                if k > K:\n",
      "                    if word in [self.bos, self.eos]:\n",
      "                        word_vec[word] = np.fromstring(vec, sep=' ')\n",
      "\n",
      "                if k > K and all([w in word_vec for w in [self.bos, self.eos]]):\n",
      "                    break\n",
      "        return word_vec\n",
      "\n",
      "    def build_vocab(self, sentences, tokenize=True):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        word_dict = self.get_word_dict(sentences, tokenize)\n",
      "        self.word_vec = self.get_w2v(word_dict)\n",
      "        print('Vocab size : %s' % (len(self.word_vec)))\n",
      "\n",
      "    # build w2v vocab with k most frequent words\n",
      "    def build_vocab_k_words(self, K):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        self.word_vec = self.get_w2v_k(K)\n",
      "        print('Vocab size : %s' % (K))\n",
      "\n",
      "    def update_vocab(self, sentences, tokenize=True):\n",
      "        assert hasattr(self, 'w2v_path'), 'warning : w2v path not set'\n",
      "        assert hasattr(self, 'word_vec'), 'build_vocab before updating it'\n",
      "        word_dict = self.get_word_dict(sentences, tokenize)\n",
      "\n",
      "        # keep only new words\n",
      "        for word in self.word_vec:\n",
      "            if word in word_dict:\n",
      "                del word_dict[word]\n",
      "\n",
      "        # udpate vocabulary\n",
      "        if word_dict:\n",
      "            new_word_vec = self.get_w2v(word_dict)\n",
      "            self.word_vec.update(new_word_vec)\n",
      "        else:\n",
      "            new_word_vec = []\n",
      "        print('New vocab size : %s (added %s words)'% (len(self.word_vec), len(new_word_vec)))\n",
      "\n",
      "    def get_batch(self, batch):\n",
      "        # sent in batch in decreasing order of lengths\n",
      "        # batch: (bsize, max_len, word_dim)\n",
      "        embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))\n",
      "\n",
      "        for i in range(len(batch)):\n",
      "            for j in range(len(batch[i])):\n",
      "                embed[j, i, :] = self.word_vec[batch[i][j]]\n",
      "\n",
      "        return torch.FloatTensor(embed)\n",
      "\n",
      "    def tokenize(self, s):\n",
      "        from nltk.tokenize import word_tokenize\n",
      "        if self.moses_tok:\n",
      "            s = ' '.join(word_tokenize(s))\n",
      "            s = s.replace(\" n't \", \"n 't \")  # HACK to get ~MOSES tokenization\n",
      "            return s.split()\n",
      "        else:\n",
      "            return word_tokenize(s)\n",
      "\n",
      "    def prepare_samples(self, sentences, bsize, tokenize, verbose):\n",
      "        sentences = [[self.bos] + s.split() + [self.eos] if not tokenize else\n",
      "                     [self.bos] + self.tokenize(s) + [self.eos] for s in sentences]\n",
      "        n_w = np.sum([len(x) for x in sentences])\n",
      "\n",
      "        # filters words without w2v vectors\n",
      "        for i in range(len(sentences)):\n",
      "            s_f = [word for word in sentences[i] if word in self.word_vec]\n",
      "            if not s_f:\n",
      "                import warnings\n",
      "                warnings.warn('No words in \"%s\" (idx=%s) have w2v vectors. \\\n",
      "                               Replacing by \"</s>\"..' % (sentences[i], i))\n",
      "                s_f = [self.eos]\n",
      "            sentences[i] = s_f\n",
      "\n",
      "        lengths = np.array([len(s) for s in sentences])\n",
      "        n_wk = np.sum(lengths)\n",
      "        if verbose:\n",
      "            print('Nb words kept : %s/%s (%.1f%s)' % (\n",
      "                        n_wk, n_w, 100.0 * n_wk / n_w, '%'))\n",
      "\n",
      "        # sort by decreasing length\n",
      "        lengths, idx_sort = np.sort(lengths)[::-1], np.argsort(-lengths)\n",
      "        sentences = np.array(sentences)[idx_sort]\n",
      "\n",
      "        return sentences, lengths, idx_sort\n",
      "\n",
      "    def encode(self, sentences, bsize=64, tokenize=True, verbose=False):\n",
      "        tic = time.time()\n",
      "        sentences, lengths, idx_sort = self.prepare_samples(\n",
      "                        sentences, bsize, tokenize, verbose)\n",
      "\n",
      "        embeddings = []\n",
      "        for stidx in range(0, len(sentences), bsize):\n",
      "            batch = Variable(self.get_batch(\n",
      "                        sentences[stidx:stidx + bsize]), volatile=True)\n",
      "            if self.is_cuda():\n",
      "                batch = batch.cuda()\n",
      "            batch = self.forward(\n",
      "                (batch, lengths[stidx:stidx + bsize])).data.cpu().numpy()\n",
      "            embeddings.append(batch)\n",
      "        embeddings = np.vstack(embeddings)\n",
      "\n",
      "        # unsort\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        embeddings = embeddings[idx_unsort]\n",
      "\n",
      "        if verbose:\n",
      "            print('Speed : %.1f sentences/s (%s mode, bsize=%s)' % (\n",
      "                    len(embeddings)/(time.time()-tic),\n",
      "                    'gpu' if self.is_cuda() else 'cpu', bsize))\n",
      "        return embeddings\n",
      "\n",
      "    def visualize(self, sent, tokenize=True):\n",
      "\n",
      "        sent = sent.split() if not tokenize else self.tokenize(sent)\n",
      "        sent = [[self.bos] + [word for word in sent if word in self.word_vec] + [self.eos]]\n",
      "\n",
      "        if ' '.join(sent[0]) == '%s %s' % (self.bos, self.eos):\n",
      "            import warnings\n",
      "            warnings.warn('No words in \"%s\" have w2v vectors. Replacing \\\n",
      "                           by \"%s %s\"..' % (sent, self.bos, self.eos))\n",
      "        batch = Variable(self.get_batch(sent), volatile=True)\n",
      "\n",
      "        if self.is_cuda():\n",
      "            batch = batch.cuda()\n",
      "        output = self.enc_lstm(batch)[0]\n",
      "        output, idxs = torch.max(output, 0)\n",
      "        # output, idxs = output.squeeze(), idxs.squeeze()\n",
      "        idxs = idxs.data.cpu().numpy()\n",
      "        argmaxs = [np.sum((idxs == k)) for k in range(len(sent[0]))]\n",
      "\n",
      "        # visualize model\n",
      "        import matplotlib.pyplot as plt\n",
      "        x = range(len(sent[0]))\n",
      "        y = [100.0 * n / np.sum(argmaxs) for n in argmaxs]\n",
      "        plt.xticks(x, sent[0], rotation=45)\n",
      "        plt.bar(x, y)\n",
      "        plt.ylabel('%')\n",
      "        plt.title('Visualisation of words importance')\n",
      "        plt.show()\n",
      "\n",
      "        return output, idxs\n",
      "\n",
      "\"\"\"\n",
      "BiGRU encoder (first/last hidden states)\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class BGRUlastEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(BGRUlastEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.GRU(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                               bidirectional=True, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        _, hn = self.enc_lstm(sent_packed, self.init_lstm)\n",
      "        emb = torch.cat((hn[0], hn[1]), 1)  # batch x 2*nhid\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        emb = emb.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "BLSTM encoder with projection after BiLSTM\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class BLSTMprojEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(BLSTMprojEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "        self.proj_enc = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=False)\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1,\n",
      "                Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = self.proj_enc(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(-1, bsize, 2*self.enc_lstm_dim)\n",
      "        # Pooling\n",
      "        if self.pool_type == \"mean\":\n",
      "            sent_len = Variable(torch.FloatTensor(sent_len)).unsqueeze(1).cuda()\n",
      "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
      "            emb = emb / sent_len.expand_as(emb)\n",
      "        elif self.pool_type == \"max\":\n",
      "            emb = torch.max(sent_output, 0)[0].squeeze(0)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "LSTM encoder\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class LSTMEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(LSTMEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=False, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(1, self.bsize,\n",
      "            self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len [max_len, ..., min_len] (batch) | sent Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(1, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed, (self.init_lstm,\n",
      "                      self.init_lstm))[1][0].squeeze(0)  # batch x 2*nhid\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        emb = sent_output.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "GRU encoder\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class GRUEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(GRUEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim =  config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.GRU(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                               bidirectional=False, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(1, self.bsize,\n",
      "            self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(1, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "\n",
      "        sent_output = self.enc_lstm(sent_packed, self.init_lstm)[1].squeeze(0)\n",
      "        # batch x 2*nhid\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        emb = sent_output.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Inner attention from \"hierarchical attention for document classification\"\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class InnerAttentionNAACLEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(InnerAttentionNAACLEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        self.proj_key = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=False)\n",
      "        self.proj_lstm = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                   bias=False)\n",
      "        self.query_embedding = nn.Embedding(1, 2*self.enc_lstm_dim)\n",
      "        self.softmax = nn.Softmax()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = sent_output.transpose(0,1).contiguous()\n",
      "\n",
      "        sent_output_proj = self.proj_lstm(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_key_proj = self.proj_key(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_key_proj = torch.tanh(sent_key_proj)\n",
      "        # NAACL paper: u_it=tanh(W_w.h_it + b_w)  (bsize, seqlen, 2nhid)\n",
      "\n",
      "        sent_w = self.query_embedding(Variable(torch.LongTensor(bsize*[0]).cuda())).unsqueeze(2) #(bsize, 2*nhid, 1)\n",
      "\n",
      "        Temp = 2\n",
      "        keys = sent_key_proj.bmm(sent_w).squeeze(2) / Temp\n",
      "\n",
      "        # Set probas of padding to zero in softmax\n",
      "        keys = keys + ((keys == 0).float()*-10000)\n",
      "\n",
      "        alphas = self.softmax(keys/Temp).unsqueeze(2).expand_as(sent_output)\n",
      "        if int(time.time()) % 100 == 0:\n",
      "            print('w', torch.max(sent_w), torch.min(sent_w))\n",
      "            print('alphas', alphas[0, :, 0])\n",
      "        emb = torch.sum(alphas * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Inner attention inspired from \"Self-attentive ...\"\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class InnerAttentionMILAEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(InnerAttentionMILAEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim =  config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        self.proj_key = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=False)\n",
      "        self.proj_lstm = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                   bias=False)\n",
      "        self.query_embedding = nn.Embedding(2, 2*self.enc_lstm_dim)\n",
      "        self.softmax = nn.Softmax()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1,\n",
      "            Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = sent_output.transpose(0,1).contiguous()\n",
      "        sent_output_proj = self.proj_lstm(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "        sent_key_proj = self.proj_key(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "        sent_key_proj = torch.tanh(sent_key_proj)\n",
      "        # NAACL : u_it=tanh(W_w.h_it + b_w) like in NAACL paper\n",
      "\n",
      "        # Temperature\n",
      "        Temp = 3\n",
      "\n",
      "        sent_w1 = self.query_embedding(Variable(torch.LongTensor(bsize*[0]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys1 = sent_key_proj.bmm(sent_w1).squeeze(2) / Temp\n",
      "        keys1 = keys1 + ((keys1 == 0).float()*-1000)\n",
      "        alphas1 = self.softmax(keys1).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb1 = torch.sum(alphas1 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "\n",
      "        sent_w2 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys2 = sent_key_proj.bmm(sent_w2).squeeze(2) / Temp\n",
      "        keys2 = keys2 + ((keys2 == 0).float()*-1000)\n",
      "        alphas2 = self.softmax(keys2).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb2 = torch.sum(alphas2 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "        sent_w3 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys3 = sent_key_proj.bmm(sent_w3).squeeze(2) / Temp\n",
      "        keys3 = keys3 + ((keys3 == 0).float()*-1000)\n",
      "        alphas3 = self.softmax(keys3).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb3 = torch.sum(alphas3 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "        sent_w4 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys4 = sent_key_proj.bmm(sent_w4).squeeze(2) / Temp\n",
      "        keys4 = keys4 + ((keys4 == 0).float()*-1000)\n",
      "        alphas4 = self.softmax(keys4).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb4 = torch.sum(alphas4 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "\n",
      "        if int(time.time()) % 100 == 0:\n",
      "            print('alphas', torch.cat((alphas1.data[0, :, 0],\n",
      "                                       alphas2.data[0, :, 0],\n",
      "                                       torch.abs(alphas1.data[0, :, 0] -\n",
      "                                                 alphas2.data[0, :, 0])), 1))\n",
      "\n",
      "        emb = torch.cat((emb1, emb2, emb3, emb4), 1)\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Inner attention from Yang et al.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class InnerAttentionYANGEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(InnerAttentionYANGEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "            self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        self.proj_lstm = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                   bias=True)\n",
      "        self.proj_query = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                    bias=True)\n",
      "        self.proj_enc = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=True)\n",
      "\n",
      "        self.query_embedding = nn.Embedding(1, 2*self.enc_lstm_dim)\n",
      "        self.softmax = nn.Softmax()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1,\n",
      "            Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = sent_output.transpose(0,1).contiguous()\n",
      "\n",
      "        sent_output_proj = self.proj_lstm(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_keys = self.proj_enc(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_max = torch.max(sent_output, 1)[0].squeeze(1)  # (bsize, 2*nhid)\n",
      "        sent_summary = self.proj_query(\n",
      "                       sent_max).unsqueeze(1).expand_as(sent_keys)\n",
      "        # (bsize, seqlen, 2*nhid)\n",
      "\n",
      "        sent_M = torch.tanh(sent_keys + sent_summary)\n",
      "        # (bsize, seqlen, 2*nhid) YANG : M = tanh(Wh_i + Wh_avg\n",
      "        sent_w = self.query_embedding(Variable(torch.LongTensor(\n",
      "            bsize*[0]).cuda())).unsqueeze(2)  # (bsize, 2*nhid, 1)\n",
      "\n",
      "        sent_alphas = self.softmax(sent_M.bmm(sent_w).squeeze(2)).unsqueeze(1)\n",
      "        # (bsize, 1, seqlen)\n",
      "\n",
      "        if int(time.time()) % 200 == 0:\n",
      "            print('w', torch.max(sent_w[0]), torch.min(sent_w[0]))\n",
      "            print('alphas', sent_alphas[0][0][0:sent_len[0]])\n",
      "        # Get attention vector\n",
      "        emb = sent_alphas.bmm(sent_output_proj).squeeze(1)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Hierarchical ConvNet\n",
      "\"\"\"\n",
      "class ConvNetEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(ConvNetEncoder, self).__init__()\n",
      "\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "        self.convnet1 = nn.Sequential(\n",
      "            nn.Conv1d(self.word_emb_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "        self.convnet2 = nn.Sequential(\n",
      "            nn.Conv1d(2*self.enc_lstm_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "        self.convnet3 = nn.Sequential(\n",
      "            nn.Conv1d(2*self.enc_lstm_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "        self.convnet4 = nn.Sequential(\n",
      "            nn.Conv1d(2*self.enc_lstm_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "\n",
      "\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "\n",
      "        sent = sent.transpose(0,1).transpose(1,2).contiguous()\n",
      "        # batch, nhid, seqlen)\n",
      "\n",
      "        sent = self.convnet1(sent)\n",
      "        u1 = torch.max(sent, 2)[0]\n",
      "\n",
      "        sent = self.convnet2(sent)\n",
      "        u2 = torch.max(sent, 2)[0]\n",
      "\n",
      "        sent = self.convnet3(sent)\n",
      "        u3 = torch.max(sent, 2)[0]\n",
      "\n",
      "        sent = self.convnet4(sent)\n",
      "        u4 = torch.max(sent, 2)[0]\n",
      "\n",
      "        emb = torch.cat((u1, u2, u3, u4), 1)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Main module for Natural Language Inference\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class NLINet(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(NLINet, self).__init__()\n",
      "\n",
      "        # classifier\n",
      "        self.nonlinear_fc = config['nonlinear_fc']\n",
      "        self.fc_dim = config['fc_dim']\n",
      "        self.n_classes = config['n_classes']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.encoder_type = config['encoder_type']\n",
      "        self.dpout_fc = config['dpout_fc']\n",
      "\n",
      "        self.encoder = eval(self.encoder_type)(config)\n",
      "        self.inputdim = 4*2*self.enc_lstm_dim\n",
      "        self.inputdim = 4*self.inputdim if self.encoder_type in \\\n",
      "                        [\"ConvNetEncoder\", \"InnerAttentionMILAEncoder\"] else self.inputdim\n",
      "        self.inputdim = self.inputdim/2 if self.encoder_type == \"LSTMEncoder\" \\\n",
      "                                        else self.inputdim\n",
      "        if self.nonlinear_fc:\n",
      "            self.classifier = nn.Sequential(\n",
      "                nn.Dropout(p=self.dpout_fc),\n",
      "                nn.Linear(self.inputdim, self.fc_dim),\n",
      "                nn.Tanh(),\n",
      "                nn.Dropout(p=self.dpout_fc),\n",
      "                nn.Linear(self.fc_dim, self.fc_dim),\n",
      "                nn.Tanh(),\n",
      "                nn.Dropout(p=self.dpout_fc),\n",
      "                nn.Linear(self.fc_dim, self.n_classes),\n",
      "                )\n",
      "        else:\n",
      "            self.classifier = nn.Sequential(\n",
      "                nn.Linear(self.inputdim, self.fc_dim),\n",
      "                nn.Linear(self.fc_dim, self.fc_dim),\n",
      "                nn.Linear(self.fc_dim, self.n_classes)\n",
      "                )\n",
      "\n",
      "    def forward(self, s1, s2):\n",
      "        # s1 : (s1, s1_len)\n",
      "        u = self.encoder(s1)\n",
      "        v = self.encoder(s2)\n",
      "\n",
      "        features = torch.cat((u, v, torch.abs(u-v), u*v), 1)\n",
      "        output = self.classifier(features)\n",
      "        return output\n",
      "\n",
      "    def encode(self, s1):\n",
      "        emb = self.encoder(s1)\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Main module for Classification\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class ClassificationNet(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(ClassificationNet, self).__init__()\n",
      "\n",
      "        # classifier\n",
      "        self.nonlinear_fc = config['nonlinear_fc']\n",
      "        self.fc_dim = config['fc_dim']\n",
      "        self.n_classes = config['n_classes']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.encoder_type = config['encoder_type']\n",
      "        self.dpout_fc = config['dpout_fc']\n",
      "\n",
      "        self.encoder = eval(self.encoder_type)(config)\n",
      "        self.inputdim = 2*self.enc_lstm_dim\n",
      "        self.inputdim = 4*self.inputdim if self.encoder_type == \"ConvNetEncoder\" else self.inputdim\n",
      "        self.inputdim = self.enc_lstm_dim if self.encoder_type ==\"LSTMEncoder\" else self.inputdim\n",
      "        self.classifier = nn.Sequential(\n",
      "            nn.Linear(self.inputdim, 512),\n",
      "            nn.Linear(512, self.n_classes),\n",
      "        )\n",
      "\n",
      "    def forward(self, s1):\n",
      "        # s1 : (s1, s1_len)\n",
      "        u = self.encoder(s1)\n",
      "\n",
      "        output = self.classifier(u)\n",
      "        return output\n",
      "\n",
      "    def encode(self, s1):\n",
      "        emb = self.encoder(s1)\n",
      "        return emb\n"
     ]
    }
   ],
   "source": [
    "!ls\n",
    "!cat models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo.ipynb\t     infersent1.pkl  models.py\t  README.md\n",
      "extract_features.py  infersent2.pkl  __pycache__  samples.txt\n",
      "# Copyright (c) 2017-present, Facebook, Inc.\n",
      "# All rights reserved.\n",
      "#\n",
      "# This source code is licensed under the license found in the\n",
      "# LICENSE file in the root directory of this source tree.\n",
      "#\n",
      "\n",
      "\"\"\"\n",
      "This file contains the definition of encoders used in https://arxiv.org/pdf/1705.02364.pdf\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "import time\n",
      "\n",
      "import torch\n",
      "from torch.autograd import Variable\n",
      "import torch.nn as nn\n",
      "\n",
      "\"\"\"\n",
      "BLSTM (max/mean) encoder\n",
      "\"\"\"\n",
      "\n",
      "class InferSent(nn.Module):\n",
      "\n",
      "    def __init__(self, config):\n",
      "        super(InferSent, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "        self.version = 1 if 'version' not in config else config['version']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True, dropout=self.dpout_model)\n",
      "\n",
      "        assert self.version in [1, 2]\n",
      "        if self.version == 1:\n",
      "            self.bos = '<s>'\n",
      "            self.eos = '</s>'\n",
      "            self.max_pad = True\n",
      "            self.moses_tok = False\n",
      "        elif self.version == 2:\n",
      "            self.bos = '<p>'\n",
      "            self.eos = '</p>'\n",
      "            self.max_pad = False\n",
      "            self.moses_tok = True\n",
      "\n",
      "    def is_cuda(self):\n",
      "        # either all weights are on cpu or they are on gpu\n",
      "        return 'cuda' in str(type(self.enc_lstm.bias_hh_l0.data))\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (bsize)\n",
      "        # sent: Variable(seqlen x bsize x worddim)\n",
      "        sent, sent_len = sent_tuple\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len_sorted, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "\n",
      "        idx_sort = torch.from_numpy(idx_sort).cuda() if self.is_cuda() \\\n",
      "            else torch.from_numpy(idx_sort)\n",
      "        sent = sent.index_select(1, Variable(idx_sort))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len_sorted)\n",
      "        sent_output = self.enc_lstm(sent_packed)[0]  # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = torch.from_numpy(idx_unsort).cuda() if self.is_cuda() \\\n",
      "            else torch.from_numpy(idx_unsort)\n",
      "        sent_output = sent_output.index_select(1, Variable(idx_unsort))\n",
      "\n",
      "        # Pooling\n",
      "        if self.pool_type == \"mean\":\n",
      "            sent_len = Variable(torch.FloatTensor(sent_len.copy())).unsqueeze(1).cuda()\n",
      "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
      "            emb = emb / sent_len.expand_as(emb)\n",
      "        elif self.pool_type == \"max\":\n",
      "            if not self.max_pad:\n",
      "                sent_output[sent_output == 0] = -1e9\n",
      "            emb = torch.max(sent_output, 0)[0]\n",
      "            if emb.ndimension() == 3:\n",
      "                emb = emb.squeeze(0)\n",
      "                assert emb.ndimension() == 2\n",
      "\n",
      "        return emb\n",
      "\n",
      "    def set_w2v_path(self, w2v_path):\n",
      "        self.w2v_path = w2v_path\n",
      "\n",
      "    def get_word_dict(self, sentences, tokenize=True):\n",
      "        # create vocab of words\n",
      "        word_dict = {}\n",
      "        sentences = [s.split() if not tokenize else self.tokenize(s) for s in sentences]\n",
      "        for sent in sentences:\n",
      "            for word in sent:\n",
      "                if word not in word_dict:\n",
      "                    word_dict[word] = ''\n",
      "        word_dict[self.bos] = ''\n",
      "        word_dict[self.eos] = ''\n",
      "        return word_dict\n",
      "\n",
      "    def get_w2v(self, word_dict):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        # create word_vec with w2v vectors\n",
      "        word_vec = {}\n",
      "        with open(self.w2v_path) as f:\n",
      "            for line in f:\n",
      "                word, vec = line.split(' ', 1)\n",
      "                if word in word_dict:\n",
      "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
      "        print('Found %s(/%s) words with w2v vectors' % (len(word_vec), len(word_dict)))\n",
      "        return word_vec\n",
      "\n",
      "    def get_w2v_k(self, K):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        # create word_vec with k first w2v vectors\n",
      "        k = 0\n",
      "        word_vec = {}\n",
      "        with open(self.w2v_path) as f:\n",
      "            for line in f:\n",
      "                word, vec = line.split(' ', 1)\n",
      "                if k <= K:\n",
      "                    word_vec[word] = np.fromstring(vec, sep=' ')\n",
      "                    k += 1\n",
      "                if k > K:\n",
      "                    if word in [self.bos, self.eos]:\n",
      "                        word_vec[word] = np.fromstring(vec, sep=' ')\n",
      "\n",
      "                if k > K and all([w in word_vec for w in [self.bos, self.eos]]):\n",
      "                    break\n",
      "        return word_vec\n",
      "\n",
      "    def build_vocab(self, sentences, tokenize=True):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        word_dict = self.get_word_dict(sentences, tokenize)\n",
      "        self.word_vec = self.get_w2v(word_dict)\n",
      "        print('Vocab size : %s' % (len(self.word_vec)))\n",
      "\n",
      "    # build w2v vocab with k most frequent words\n",
      "    def build_vocab_k_words(self, K):\n",
      "        assert hasattr(self, 'w2v_path'), 'w2v path not set'\n",
      "        self.word_vec = self.get_w2v_k(K)\n",
      "        print('Vocab size : %s' % (K))\n",
      "\n",
      "    def update_vocab(self, sentences, tokenize=True):\n",
      "        assert hasattr(self, 'w2v_path'), 'warning : w2v path not set'\n",
      "        assert hasattr(self, 'word_vec'), 'build_vocab before updating it'\n",
      "        word_dict = self.get_word_dict(sentences, tokenize)\n",
      "\n",
      "        # keep only new words\n",
      "        for word in self.word_vec:\n",
      "            if word in word_dict:\n",
      "                del word_dict[word]\n",
      "\n",
      "        # udpate vocabulary\n",
      "        if word_dict:\n",
      "            new_word_vec = self.get_w2v(word_dict)\n",
      "            self.word_vec.update(new_word_vec)\n",
      "        else:\n",
      "            new_word_vec = []\n",
      "        print('New vocab size : %s (added %s words)'% (len(self.word_vec), len(new_word_vec)))\n",
      "\n",
      "    def get_batch(self, batch):\n",
      "        # sent in batch in decreasing order of lengths\n",
      "        # batch: (bsize, max_len, word_dim)\n",
      "        embed = np.zeros((len(batch[0]), len(batch), self.word_emb_dim))\n",
      "\n",
      "        for i in range(len(batch)):\n",
      "            for j in range(len(batch[i])):\n",
      "                embed[j, i, :] = self.word_vec[batch[i][j]]\n",
      "\n",
      "        return torch.FloatTensor(embed)\n",
      "\n",
      "    def tokenize(self, s):\n",
      "        from nltk.tokenize import word_tokenize\n",
      "        if self.moses_tok:\n",
      "            s = ' '.join(word_tokenize(s))\n",
      "            s = s.replace(\" n't \", \"n 't \")  # HACK to get ~MOSES tokenization\n",
      "            return s.split()\n",
      "        else:\n",
      "            return word_tokenize(s)\n",
      "\n",
      "    def prepare_samples(self, sentences, bsize, tokenize, verbose):\n",
      "        sentences = [[self.bos] + s.split() + [self.eos] if not tokenize else\n",
      "                     [self.bos] + self.tokenize(s) + [self.eos] for s in sentences]\n",
      "        n_w = np.sum([len(x) for x in sentences])\n",
      "\n",
      "        # filters words without w2v vectors\n",
      "        for i in range(len(sentences)):\n",
      "            s_f = [word for word in sentences[i] if word in self.word_vec]\n",
      "            if not s_f:\n",
      "                import warnings\n",
      "                warnings.warn('No words in \"%s\" (idx=%s) have w2v vectors. \\\n",
      "                               Replacing by \"</s>\"..' % (sentences[i], i))\n",
      "                s_f = [self.eos]\n",
      "            sentences[i] = s_f\n",
      "\n",
      "        lengths = np.array([len(s) for s in sentences])\n",
      "        n_wk = np.sum(lengths)\n",
      "        if verbose:\n",
      "            print('Nb words kept : %s/%s (%.1f%s)' % (\n",
      "                        n_wk, n_w, 100.0 * n_wk / n_w, '%'))\n",
      "\n",
      "        # sort by decreasing length\n",
      "        lengths, idx_sort = np.sort(lengths)[::-1], np.argsort(-lengths)\n",
      "        sentences = np.array(sentences)[idx_sort]\n",
      "\n",
      "        return sentences, lengths, idx_sort\n",
      "\n",
      "    def encode(self, sentences, bsize=64, tokenize=True, verbose=False):\n",
      "        tic = time.time()\n",
      "        sentences, lengths, idx_sort = self.prepare_samples(\n",
      "                        sentences, bsize, tokenize, verbose)\n",
      "\n",
      "        embeddings = []\n",
      "        for stidx in range(0, len(sentences), bsize):\n",
      "            batch = Variable(self.get_batch(\n",
      "                        sentences[stidx:stidx + bsize]), volatile=True)\n",
      "            if self.is_cuda():\n",
      "                batch = batch.cuda()\n",
      "            batch = self.forward(\n",
      "                (batch, lengths[stidx:stidx + bsize])).data.cpu().numpy()\n",
      "            embeddings.append(batch)\n",
      "        embeddings = np.vstack(embeddings)\n",
      "\n",
      "        # unsort\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        embeddings = embeddings[idx_unsort]\n",
      "\n",
      "        if verbose:\n",
      "            print('Speed : %.1f sentences/s (%s mode, bsize=%s)' % (\n",
      "                    len(embeddings)/(time.time()-tic),\n",
      "                    'gpu' if self.is_cuda() else 'cpu', bsize))\n",
      "        return embeddings\n",
      "\n",
      "    def visualize(self, sent, tokenize=True):\n",
      "\n",
      "        sent = sent.split() if not tokenize else self.tokenize(sent)\n",
      "        sent = [[self.bos] + [word for word in sent if word in self.word_vec] + [self.eos]]\n",
      "\n",
      "        if ' '.join(sent[0]) == '%s %s' % (self.bos, self.eos):\n",
      "            import warnings\n",
      "            warnings.warn('No words in \"%s\" have w2v vectors. Replacing \\\n",
      "                           by \"%s %s\"..' % (sent, self.bos, self.eos))\n",
      "        batch = Variable(self.get_batch(sent), volatile=True)\n",
      "\n",
      "        if self.is_cuda():\n",
      "            batch = batch.cuda()\n",
      "        output = self.enc_lstm(batch)[0]\n",
      "        output, idxs = torch.max(output, 0)\n",
      "        # output, idxs = output.squeeze(), idxs.squeeze()\n",
      "        idxs = idxs.data.cpu().numpy()\n",
      "        argmaxs = [np.sum((idxs == k)) for k in range(len(sent[0]))]\n",
      "\n",
      "        # visualize model\n",
      "        import matplotlib.pyplot as plt\n",
      "        x = range(len(sent[0]))\n",
      "        y = [100.0 * n / np.sum(argmaxs) for n in argmaxs]\n",
      "        plt.xticks(x, sent[0], rotation=45)\n",
      "        plt.bar(x, y)\n",
      "        plt.ylabel('%')\n",
      "        plt.title('Visualisation of words importance')\n",
      "        plt.show()\n",
      "\n",
      "        return output, idxs\n",
      "\n",
      "\"\"\"\n",
      "BiGRU encoder (first/last hidden states)\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class BGRUlastEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(BGRUlastEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.GRU(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                               bidirectional=True, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        _, hn = self.enc_lstm(sent_packed, self.init_lstm)\n",
      "        emb = torch.cat((hn[0], hn[1]), 1)  # batch x 2*nhid\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        emb = emb.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "BLSTM encoder with projection after BiLSTM\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class BLSTMprojEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(BLSTMprojEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "        self.proj_enc = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=False)\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1,\n",
      "                Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = self.proj_enc(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(-1, bsize, 2*self.enc_lstm_dim)\n",
      "        # Pooling\n",
      "        if self.pool_type == \"mean\":\n",
      "            sent_len = Variable(torch.FloatTensor(sent_len)).unsqueeze(1).cuda()\n",
      "            emb = torch.sum(sent_output, 0).squeeze(0)\n",
      "            emb = emb / sent_len.expand_as(emb)\n",
      "        elif self.pool_type == \"max\":\n",
      "            emb = torch.max(sent_output, 0)[0].squeeze(0)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "LSTM encoder\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class LSTMEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(LSTMEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=False, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(1, self.bsize,\n",
      "            self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len [max_len, ..., min_len] (batch) | sent Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(1, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed, (self.init_lstm,\n",
      "                      self.init_lstm))[1][0].squeeze(0)  # batch x 2*nhid\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        emb = sent_output.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "GRU encoder\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class GRUEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(GRUEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim =  config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "        self.dpout_model = config['dpout_model']\n",
      "\n",
      "        self.enc_lstm = nn.GRU(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                               bidirectional=False, dropout=self.dpout_model)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(1, self.bsize,\n",
      "            self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(1, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "\n",
      "        sent_output = self.enc_lstm(sent_packed, self.init_lstm)[1].squeeze(0)\n",
      "        # batch x 2*nhid\n",
      "\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        emb = sent_output.index_select(0, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Inner attention from \"hierarchical attention for document classification\"\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class InnerAttentionNAACLEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(InnerAttentionNAACLEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        self.proj_key = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=False)\n",
      "        self.proj_lstm = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                   bias=False)\n",
      "        self.query_embedding = nn.Embedding(1, 2*self.enc_lstm_dim)\n",
      "        self.softmax = nn.Softmax()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1, Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = sent_output.transpose(0,1).contiguous()\n",
      "\n",
      "        sent_output_proj = self.proj_lstm(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_key_proj = self.proj_key(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_key_proj = torch.tanh(sent_key_proj)\n",
      "        # NAACL paper: u_it=tanh(W_w.h_it + b_w)  (bsize, seqlen, 2nhid)\n",
      "\n",
      "        sent_w = self.query_embedding(Variable(torch.LongTensor(bsize*[0]).cuda())).unsqueeze(2) #(bsize, 2*nhid, 1)\n",
      "\n",
      "        Temp = 2\n",
      "        keys = sent_key_proj.bmm(sent_w).squeeze(2) / Temp\n",
      "\n",
      "        # Set probas of padding to zero in softmax\n",
      "        keys = keys + ((keys == 0).float()*-10000)\n",
      "\n",
      "        alphas = self.softmax(keys/Temp).unsqueeze(2).expand_as(sent_output)\n",
      "        if int(time.time()) % 100 == 0:\n",
      "            print('w', torch.max(sent_w), torch.min(sent_w))\n",
      "            print('alphas', alphas[0, :, 0])\n",
      "        emb = torch.sum(alphas * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Inner attention inspired from \"Self-attentive ...\"\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class InnerAttentionMILAEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(InnerAttentionMILAEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim =  config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "                                  self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        self.proj_key = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=False)\n",
      "        self.proj_lstm = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                   bias=False)\n",
      "        self.query_embedding = nn.Embedding(2, 2*self.enc_lstm_dim)\n",
      "        self.softmax = nn.Softmax()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1,\n",
      "            Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = sent_output.transpose(0,1).contiguous()\n",
      "        sent_output_proj = self.proj_lstm(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "        sent_key_proj = self.proj_key(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "        sent_key_proj = torch.tanh(sent_key_proj)\n",
      "        # NAACL : u_it=tanh(W_w.h_it + b_w) like in NAACL paper\n",
      "\n",
      "        # Temperature\n",
      "        Temp = 3\n",
      "\n",
      "        sent_w1 = self.query_embedding(Variable(torch.LongTensor(bsize*[0]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys1 = sent_key_proj.bmm(sent_w1).squeeze(2) / Temp\n",
      "        keys1 = keys1 + ((keys1 == 0).float()*-1000)\n",
      "        alphas1 = self.softmax(keys1).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb1 = torch.sum(alphas1 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "\n",
      "        sent_w2 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys2 = sent_key_proj.bmm(sent_w2).squeeze(2) / Temp\n",
      "        keys2 = keys2 + ((keys2 == 0).float()*-1000)\n",
      "        alphas2 = self.softmax(keys2).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb2 = torch.sum(alphas2 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "        sent_w3 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys3 = sent_key_proj.bmm(sent_w3).squeeze(2) / Temp\n",
      "        keys3 = keys3 + ((keys3 == 0).float()*-1000)\n",
      "        alphas3 = self.softmax(keys3).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb3 = torch.sum(alphas3 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "        sent_w4 = self.query_embedding(Variable(torch.LongTensor(bsize*[1]).cuda())).unsqueeze(2) #(bsize, nhid, 1)\n",
      "        keys4 = sent_key_proj.bmm(sent_w4).squeeze(2) / Temp\n",
      "        keys4 = keys4 + ((keys4 == 0).float()*-1000)\n",
      "        alphas4 = self.softmax(keys4).unsqueeze(2).expand_as(sent_key_proj)\n",
      "        emb4 = torch.sum(alphas4 * sent_output_proj, 1).squeeze(1)\n",
      "\n",
      "\n",
      "        if int(time.time()) % 100 == 0:\n",
      "            print('alphas', torch.cat((alphas1.data[0, :, 0],\n",
      "                                       alphas2.data[0, :, 0],\n",
      "                                       torch.abs(alphas1.data[0, :, 0] -\n",
      "                                                 alphas2.data[0, :, 0])), 1))\n",
      "\n",
      "        emb = torch.cat((emb1, emb2, emb3, emb4), 1)\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Inner attention from Yang et al.\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class InnerAttentionYANGEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(InnerAttentionYANGEncoder, self).__init__()\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "        self.enc_lstm = nn.LSTM(self.word_emb_dim, self.enc_lstm_dim, 1,\n",
      "                                bidirectional=True)\n",
      "        self.init_lstm = Variable(torch.FloatTensor(2, self.bsize,\n",
      "            self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        self.proj_lstm = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                   bias=True)\n",
      "        self.proj_query = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                    bias=True)\n",
      "        self.proj_enc = nn.Linear(2*self.enc_lstm_dim, 2*self.enc_lstm_dim,\n",
      "                                  bias=True)\n",
      "\n",
      "        self.query_embedding = nn.Embedding(1, 2*self.enc_lstm_dim)\n",
      "        self.softmax = nn.Softmax()\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "        bsize = sent.size(1)\n",
      "\n",
      "        self.init_lstm = self.init_lstm if bsize == self.init_lstm.size(1) else \\\n",
      "                Variable(torch.FloatTensor(2, bsize, self.enc_lstm_dim).zero_()).cuda()\n",
      "\n",
      "        # Sort by length (keep idx)\n",
      "        sent_len, idx_sort = np.sort(sent_len)[::-1], np.argsort(-sent_len)\n",
      "        sent = sent.index_select(1, Variable(torch.cuda.LongTensor(idx_sort)))\n",
      "        # Handling padding in Recurrent Networks\n",
      "        sent_packed = nn.utils.rnn.pack_padded_sequence(sent, sent_len)\n",
      "        sent_output = self.enc_lstm(sent_packed,\n",
      "                                    (self.init_lstm, self.init_lstm))[0]\n",
      "        # seqlen x batch x 2*nhid\n",
      "        sent_output = nn.utils.rnn.pad_packed_sequence(sent_output)[0]\n",
      "        # Un-sort by length\n",
      "        idx_unsort = np.argsort(idx_sort)\n",
      "        sent_output = sent_output.index_select(1,\n",
      "            Variable(torch.cuda.LongTensor(idx_unsort)))\n",
      "\n",
      "        sent_output = sent_output.transpose(0,1).contiguous()\n",
      "\n",
      "        sent_output_proj = self.proj_lstm(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_keys = self.proj_enc(sent_output.view(-1,\n",
      "            2*self.enc_lstm_dim)).view(bsize, -1, 2*self.enc_lstm_dim)\n",
      "\n",
      "        sent_max = torch.max(sent_output, 1)[0].squeeze(1)  # (bsize, 2*nhid)\n",
      "        sent_summary = self.proj_query(\n",
      "                       sent_max).unsqueeze(1).expand_as(sent_keys)\n",
      "        # (bsize, seqlen, 2*nhid)\n",
      "\n",
      "        sent_M = torch.tanh(sent_keys + sent_summary)\n",
      "        # (bsize, seqlen, 2*nhid) YANG : M = tanh(Wh_i + Wh_avg\n",
      "        sent_w = self.query_embedding(Variable(torch.LongTensor(\n",
      "            bsize*[0]).cuda())).unsqueeze(2)  # (bsize, 2*nhid, 1)\n",
      "\n",
      "        sent_alphas = self.softmax(sent_M.bmm(sent_w).squeeze(2)).unsqueeze(1)\n",
      "        # (bsize, 1, seqlen)\n",
      "\n",
      "        if int(time.time()) % 200 == 0:\n",
      "            print('w', torch.max(sent_w[0]), torch.min(sent_w[0]))\n",
      "            print('alphas', sent_alphas[0][0][0:sent_len[0]])\n",
      "        # Get attention vector\n",
      "        emb = sent_alphas.bmm(sent_output_proj).squeeze(1)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Hierarchical ConvNet\n",
      "\"\"\"\n",
      "class ConvNetEncoder(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(ConvNetEncoder, self).__init__()\n",
      "\n",
      "        self.bsize = config['bsize']\n",
      "        self.word_emb_dim = config['word_emb_dim']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.pool_type = config['pool_type']\n",
      "\n",
      "        self.convnet1 = nn.Sequential(\n",
      "            nn.Conv1d(self.word_emb_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "        self.convnet2 = nn.Sequential(\n",
      "            nn.Conv1d(2*self.enc_lstm_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "        self.convnet3 = nn.Sequential(\n",
      "            nn.Conv1d(2*self.enc_lstm_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "        self.convnet4 = nn.Sequential(\n",
      "            nn.Conv1d(2*self.enc_lstm_dim, 2*self.enc_lstm_dim, kernel_size=3,\n",
      "                      stride=1, padding=1),\n",
      "            nn.ReLU(inplace=True),\n",
      "            )\n",
      "\n",
      "\n",
      "\n",
      "    def forward(self, sent_tuple):\n",
      "        # sent_len: [max_len, ..., min_len] (batch)\n",
      "        # sent: Variable(seqlen x batch x worddim)\n",
      "\n",
      "        sent, sent_len = sent_tuple\n",
      "\n",
      "        sent = sent.transpose(0,1).transpose(1,2).contiguous()\n",
      "        # batch, nhid, seqlen)\n",
      "\n",
      "        sent = self.convnet1(sent)\n",
      "        u1 = torch.max(sent, 2)[0]\n",
      "\n",
      "        sent = self.convnet2(sent)\n",
      "        u2 = torch.max(sent, 2)[0]\n",
      "\n",
      "        sent = self.convnet3(sent)\n",
      "        u3 = torch.max(sent, 2)[0]\n",
      "\n",
      "        sent = self.convnet4(sent)\n",
      "        u4 = torch.max(sent, 2)[0]\n",
      "\n",
      "        emb = torch.cat((u1, u2, u3, u4), 1)\n",
      "\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Main module for Natural Language Inference\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class NLINet(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(NLINet, self).__init__()\n",
      "\n",
      "        # classifier\n",
      "        self.nonlinear_fc = config['nonlinear_fc']\n",
      "        self.fc_dim = config['fc_dim']\n",
      "        self.n_classes = config['n_classes']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.encoder_type = config['encoder_type']\n",
      "        self.dpout_fc = config['dpout_fc']\n",
      "\n",
      "        self.encoder = eval(self.encoder_type)(config)\n",
      "        self.inputdim = 4*2*self.enc_lstm_dim\n",
      "        self.inputdim = 4*self.inputdim if self.encoder_type in \\\n",
      "                        [\"ConvNetEncoder\", \"InnerAttentionMILAEncoder\"] else self.inputdim\n",
      "        self.inputdim = self.inputdim/2 if self.encoder_type == \"LSTMEncoder\" \\\n",
      "                                        else self.inputdim\n",
      "        if self.nonlinear_fc:\n",
      "            self.classifier = nn.Sequential(\n",
      "                nn.Dropout(p=self.dpout_fc),\n",
      "                nn.Linear(self.inputdim, self.fc_dim),\n",
      "                nn.Tanh(),\n",
      "                nn.Dropout(p=self.dpout_fc),\n",
      "                nn.Linear(self.fc_dim, self.fc_dim),\n",
      "                nn.Tanh(),\n",
      "                nn.Dropout(p=self.dpout_fc),\n",
      "                nn.Linear(self.fc_dim, self.n_classes),\n",
      "                )\n",
      "        else:\n",
      "            self.classifier = nn.Sequential(\n",
      "                nn.Linear(self.inputdim, self.fc_dim),\n",
      "                nn.Linear(self.fc_dim, self.fc_dim),\n",
      "                nn.Linear(self.fc_dim, self.n_classes)\n",
      "                )\n",
      "\n",
      "    def forward(self, s1, s2):\n",
      "        # s1 : (s1, s1_len)\n",
      "        u = self.encoder(s1)\n",
      "        v = self.encoder(s2)\n",
      "\n",
      "        features = torch.cat((u, v, torch.abs(u-v), u*v), 1)\n",
      "        output = self.classifier(features)\n",
      "        return output\n",
      "\n",
      "    def encode(self, s1):\n",
      "        emb = self.encoder(s1)\n",
      "        return emb\n",
      "\n",
      "\n",
      "\"\"\"\n",
      "Main module for Classification\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "class ClassificationNet(nn.Module):\n",
      "    def __init__(self, config):\n",
      "        super(ClassificationNet, self).__init__()\n",
      "\n",
      "        # classifier\n",
      "        self.nonlinear_fc = config['nonlinear_fc']\n",
      "        self.fc_dim = config['fc_dim']\n",
      "        self.n_classes = config['n_classes']\n",
      "        self.enc_lstm_dim = config['enc_lstm_dim']\n",
      "        self.encoder_type = config['encoder_type']\n",
      "        self.dpout_fc = config['dpout_fc']\n",
      "\n",
      "        self.encoder = eval(self.encoder_type)(config)\n",
      "        self.inputdim = 2*self.enc_lstm_dim\n",
      "        self.inputdim = 4*self.inputdim if self.encoder_type == \"ConvNetEncoder\" else self.inputdim\n",
      "        self.inputdim = self.enc_lstm_dim if self.encoder_type ==\"LSTMEncoder\" else self.inputdim\n",
      "        self.classifier = nn.Sequential(\n",
      "            nn.Linear(self.inputdim, 512),\n",
      "            nn.Linear(512, self.n_classes),\n",
      "        )\n",
      "\n",
      "    def forward(self, s1):\n",
      "        # s1 : (s1, s1_len)\n",
      "        u = self.encoder(s1)\n",
      "\n",
      "        output = self.classifier(u)\n",
      "        return output\n",
      "\n",
      "    def encode(self, s1):\n",
      "        emb = self.encoder(s1)\n",
      "        return emb\n"
     ]
    }
   ],
   "source": [
    "!ls encoder\n",
    "!cat encoder/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.py  encoder  models.py  mutils.py\t  README.md  train_nli.py\r\n",
      "dataset  LICENSE  MultiNLI   __pycache__  SNLI\t     Untitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import InferSent\n",
    "V = 2\n",
    "MODEL_PATH = 'encoder/infersent%s.pkl' % V\n",
    "params_model = {'bsize': 64, 'word_emb_dim': 300, 'enc_lstm_dim': 2048,\n",
    "                'pool_type': 'max', 'dpout_model': 0.0, 'version': V}\n",
    "infersent = InferSent(params_model)\n",
    "infersent.load_state_dict(torch.load(MODEL_PATH))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models.InferSent"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(infersent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "togrep : []\n",
      "\n",
      "Namespace(batch_size=64, decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='LSTMEncoder', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=3, n_enc_layers=1, n_epochs=20, nlipath='/home/dc/InferSent/dataset/SNLI', nonlinear_fc=0, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='model.pickle', pool_type='max', seed=1234)\n",
      "** TRAIN DATA : Found 549367 pairs of train sentences.\n",
      "** DEV DATA : Found 9842 pairs of dev sentences.\n",
      "** TEST DATA : Found 9824 pairs of test sentences.\n",
      "Found 38957(/43479) words with glove vectors\n",
      "Vocab size : 38957\n",
      "self.inputdim:8192, self.fc_dim:512\n",
      "<class 'int'> <class 'int'>\n",
      "NLINet(\n",
      "  (encoder): LSTMEncoder(\n",
      "    (enc_lstm): LSTM(300, 2048)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=8192, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "TRAINING : Epoch 1\n",
      "Learning rate : 0.1\n",
      "<class 'torch.Tensor'> tensor(2128) 2128\n",
      "6336 ; loss 1.1 accuracy:33.25 ;\n",
      "<class 'torch.Tensor'> tensor(4314) 4314\n",
      "12736 ; loss 1.1 accuracy:33.7 ;\n",
      "<class 'torch.Tensor'> tensor(6426) 6426\n",
      "19136 ; loss 1.1 accuracy:33.47 ;\n",
      "<class 'torch.Tensor'> tensor(8534) 8534\n",
      "25536 ; loss 1.1 accuracy:33.34 ;\n",
      "<class 'torch.Tensor'> tensor(10663) 10663\n",
      "31936 ; loss 1.1 accuracy:33.32 ;\n",
      "<class 'torch.Tensor'> tensor(12849) 12849\n",
      "38336 ; loss 1.1 accuracy:33.46 ;\n",
      "<class 'torch.Tensor'> tensor(14938) 14938\n",
      "44736 ; loss 1.1 accuracy:33.34 ;\n",
      "<class 'torch.Tensor'> tensor(17105) 17105\n",
      "51136 ; loss 1.1 accuracy:33.41 ;\n",
      "<class 'torch.Tensor'> tensor(19240) 19240\n",
      "57536 ; loss 1.1 accuracy:33.4 ;\n",
      "<class 'torch.Tensor'> tensor(21390) 21390\n",
      "63936 ; loss 1.1 accuracy:33.42 ;\n",
      "<class 'torch.Tensor'> tensor(23523) 23523\n",
      "70336 ; loss 1.1 accuracy:33.41 ;\n",
      "<class 'torch.Tensor'> tensor(25652) 25652\n",
      "76736 ; loss 1.1 accuracy:33.4 ;\n",
      "<class 'torch.Tensor'> tensor(27776) 27776\n",
      "83136 ; loss 1.1 accuracy:33.38 ;\n",
      "<class 'torch.Tensor'> tensor(29911) 29911\n",
      "89536 ; loss 1.1 accuracy:33.38 ;\n",
      "<class 'torch.Tensor'> tensor(32096) 32096\n",
      "95936 ; loss 1.1 accuracy:33.43 ;\n",
      "<class 'torch.Tensor'> tensor(34277) 34277\n",
      "102336 ; loss 1.1 accuracy:33.47 ;\n",
      "<class 'torch.Tensor'> tensor(36428) 36428\n",
      "108736 ; loss 1.1 accuracy:33.48 ;\n",
      "<class 'torch.Tensor'> tensor(38579) 38579\n",
      "115136 ; loss 1.1 accuracy:33.49 ;\n",
      "<class 'torch.Tensor'> tensor(40720) 40720\n",
      "121536 ; loss 1.1 accuracy:33.49 ;\n",
      "<class 'torch.Tensor'> tensor(42929) 42929\n",
      "127936 ; loss 1.1 accuracy:33.54 ;\n",
      "<class 'torch.Tensor'> tensor(45142) 45142\n",
      "134336 ; loss 1.1 accuracy:33.59 ;\n",
      "<class 'torch.Tensor'> tensor(47326) 47326\n",
      "140736 ; loss 1.1 accuracy:33.61 ;\n",
      "<class 'torch.Tensor'> tensor(49435) 49435\n",
      "147136 ; loss 1.1 accuracy:33.58 ;\n",
      "<class 'torch.Tensor'> tensor(51699) 51699\n",
      "153536 ; loss 1.1 accuracy:33.66 ;\n",
      "<class 'torch.Tensor'> tensor(53891) 53891\n",
      "159936 ; loss 1.1 accuracy:33.68 ;\n",
      "<class 'torch.Tensor'> tensor(56120) 56120\n",
      "166336 ; loss 1.1 accuracy:33.73 ;\n",
      "<class 'torch.Tensor'> tensor(58372) 58372\n",
      "172736 ; loss 1.1 accuracy:33.78 ;\n",
      "<class 'torch.Tensor'> tensor(60748) 60748\n",
      "179136 ; loss 1.1 accuracy:33.9 ;\n",
      "<class 'torch.Tensor'> tensor(63008) 63008\n",
      "185536 ; loss 1.1 accuracy:33.95 ;\n",
      "<class 'torch.Tensor'> tensor(65258) 65258\n",
      "191936 ; loss 1.1 accuracy:33.99 ;\n",
      "<class 'torch.Tensor'> tensor(67577) 67577\n",
      "198336 ; loss 1.1 accuracy:34.06 ;\n",
      "<class 'torch.Tensor'> tensor(69896) 69896\n",
      "204736 ; loss 1.1 accuracy:34.13 ;\n",
      "<class 'torch.Tensor'> tensor(72154) 72154\n",
      "211136 ; loss 1.1 accuracy:34.16 ;\n",
      "<class 'torch.Tensor'> tensor(74305) 74305\n",
      "217536 ; loss 1.1 accuracy:34.15 ;\n",
      "<class 'torch.Tensor'> tensor(76466) 76466\n",
      "223936 ; loss 1.1 accuracy:34.14 ;\n",
      "<class 'torch.Tensor'> tensor(78613) 78613\n",
      "230336 ; loss 1.1 accuracy:34.12 ;\n",
      "<class 'torch.Tensor'> tensor(80805) 80805\n",
      "236736 ; loss 1.1 accuracy:34.12 ;\n",
      "<class 'torch.Tensor'> tensor(82944) 82944\n",
      "243136 ; loss 1.1 accuracy:34.11 ;\n",
      "<class 'torch.Tensor'> tensor(85336) 85336\n",
      "249536 ; loss 1.1 accuracy:34.19 ;\n",
      "<class 'torch.Tensor'> tensor(87730) 87730\n",
      "255936 ; loss 1.1 accuracy:34.27 ;\n",
      "<class 'torch.Tensor'> tensor(90122) 90122\n",
      "262336 ; loss 1.1 accuracy:34.35 ;\n",
      "<class 'torch.Tensor'> tensor(92441) 92441\n",
      "268736 ; loss 1.1 accuracy:34.39 ;\n",
      "<class 'torch.Tensor'> tensor(94666) 94666\n",
      "275136 ; loss 1.1 accuracy:34.4 ;\n",
      "<class 'torch.Tensor'> tensor(96818) 96818\n",
      "281536 ; loss 1.1 accuracy:34.38 ;\n",
      "<class 'torch.Tensor'> tensor(98961) 98961\n",
      "287936 ; loss 1.1 accuracy:34.36 ;\n",
      "<class 'torch.Tensor'> tensor(101315) 101315\n",
      "294336 ; loss 1.1 accuracy:34.41 ;\n",
      "<class 'torch.Tensor'> tensor(103627) 103627\n",
      "300736 ; loss 1.1 accuracy:34.45 ;\n",
      "<class 'torch.Tensor'> tensor(105804) 105804\n",
      "307136 ; loss 1.1 accuracy:34.44 ;\n",
      "<class 'torch.Tensor'> tensor(107935) 107935\n",
      "313536 ; loss 1.1 accuracy:34.42 ;\n",
      "<class 'torch.Tensor'> tensor(110062) 110062\n",
      "319936 ; loss 1.1 accuracy:34.39 ;\n",
      "<class 'torch.Tensor'> tensor(112386) 112386\n",
      "326336 ; loss 1.1 accuracy:34.43 ;\n",
      "<class 'torch.Tensor'> tensor(114789) 114789\n",
      "332736 ; loss 1.1 accuracy:34.49 ;\n",
      "<class 'torch.Tensor'> tensor(117288) 117288\n",
      "339136 ; loss 1.1 accuracy:34.58 ;\n",
      "<class 'torch.Tensor'> tensor(119560) 119560\n",
      "345536 ; loss 1.1 accuracy:34.59 ;\n",
      "<class 'torch.Tensor'> tensor(121799) 121799\n",
      "351936 ; loss 1.1 accuracy:34.6 ;\n",
      "<class 'torch.Tensor'> tensor(124218) 124218\n",
      "358336 ; loss 1.1 accuracy:34.66 ;\n",
      "<class 'torch.Tensor'> tensor(126649) 126649\n",
      "364736 ; loss 1.1 accuracy:34.72 ;\n",
      "<class 'torch.Tensor'> tensor(128903) 128903\n",
      "371136 ; loss 1.1 accuracy:34.73 ;\n",
      "<class 'torch.Tensor'> tensor(131166) 131166\n",
      "377536 ; loss 1.1 accuracy:34.74 ;\n",
      "<class 'torch.Tensor'> tensor(133369) 133369\n",
      "383936 ; loss 1.1 accuracy:34.73 ;\n",
      "<class 'torch.Tensor'> tensor(135725) 135725\n",
      "390336 ; loss 1.1 accuracy:34.77 ;\n",
      "<class 'torch.Tensor'> tensor(137911) 137911\n",
      "396736 ; loss 1.1 accuracy:34.76 ;\n",
      "<class 'torch.Tensor'> tensor(140384) 140384\n",
      "403136 ; loss 1.1 accuracy:34.82 ;\n",
      "<class 'torch.Tensor'> tensor(143016) 143016\n",
      "409536 ; loss 1.1 accuracy:34.92 ;\n",
      "<class 'torch.Tensor'> tensor(145525) 145525\n",
      "415936 ; loss 1.1 accuracy:34.98 ;\n",
      "<class 'torch.Tensor'> tensor(148171) 148171\n",
      "422336 ; loss 1.1 accuracy:35.08 ;\n",
      "<class 'torch.Tensor'> tensor(150575) 150575\n",
      "428736 ; loss 1.1 accuracy:35.12 ;\n",
      "<class 'torch.Tensor'> tensor(153129) 153129\n",
      "435136 ; loss 1.1 accuracy:35.19 ;\n",
      "<class 'torch.Tensor'> tensor(155641) 155641\n",
      "441536 ; loss 1.1 accuracy:35.24 ;\n",
      "<class 'torch.Tensor'> tensor(158016) 158016\n",
      "447936 ; loss 1.1 accuracy:35.27 ;\n",
      "<class 'torch.Tensor'> tensor(160316) 160316\n",
      "454336 ; loss 1.1 accuracy:35.28 ;\n",
      "<class 'torch.Tensor'> tensor(162898) 162898\n",
      "460736 ; loss 1.1 accuracy:35.35 ;\n",
      "<class 'torch.Tensor'> tensor(165507) 165507\n",
      "467136 ; loss 1.1 accuracy:35.43 ;\n",
      "<class 'torch.Tensor'> tensor(167747) 167747\n",
      "473536 ; loss 1.1 accuracy:35.42 ;\n",
      "<class 'torch.Tensor'> tensor(169931) 169931\n",
      "479936 ; loss 1.1 accuracy:35.4 ;\n",
      "<class 'torch.Tensor'> tensor(172205) 172205\n",
      "486336 ; loss 1.1 accuracy:35.4 ;\n",
      "<class 'torch.Tensor'> tensor(174410) 174410\n",
      "492736 ; loss 1.1 accuracy:35.39 ;\n",
      "<class 'torch.Tensor'> tensor(176590) 176590\n",
      "499136 ; loss 1.1 accuracy:35.37 ;\n",
      "<class 'torch.Tensor'> tensor(178831) 178831\n",
      "505536 ; loss 1.1 accuracy:35.37 ;\n",
      "<class 'torch.Tensor'> tensor(181025) 181025\n",
      "511936 ; loss 1.1 accuracy:35.36 ;\n",
      "<class 'torch.Tensor'> tensor(183199) 183199\n",
      "518336 ; loss 1.1 accuracy:35.34 ;\n",
      "<class 'torch.Tensor'> tensor(185302) 185302\n",
      "524736 ; loss 1.1 accuracy:35.31 ;\n",
      "<class 'torch.Tensor'> tensor(187596) 187596\n",
      "531136 ; loss 1.1 accuracy:35.32 ;\n",
      "<class 'torch.Tensor'> tensor(189927) 189927\n",
      "537536 ; loss 1.1 accuracy:35.33 ;\n",
      "<class 'torch.Tensor'> tensor(192313) 192313\n",
      "543936 ; loss 1.1 accuracy:35.35 ;\n",
      "results : epoch 1 ; mean accuracy train : 35.36\n",
      "\n",
      "VALIDATION : Epoch 1\n",
      "togrep : results : epoch 1 ; mean accuracy valid :              34.71\n",
      "saving model at epoch 1\n",
      "\n",
      "TRAINING : Epoch 2\n",
      "Learning rate : 0.099\n",
      "<class 'torch.Tensor'> tensor(2192) 2192\n",
      "6336 ; loss 1.1 accuracy:34.25 ;\n",
      "<class 'torch.Tensor'> tensor(4429) 4429\n",
      "12736 ; loss 1.1 accuracy:34.6 ;\n",
      "<class 'torch.Tensor'> tensor(6994) 6994\n",
      "19136 ; loss 1.1 accuracy:36.43 ;\n",
      "<class 'torch.Tensor'> tensor(9537) 9537\n",
      "25536 ; loss 1.1 accuracy:37.25 ;\n",
      "<class 'torch.Tensor'> tensor(12005) 12005\n",
      "31936 ; loss 1.1 accuracy:37.52 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(14411) 14411\n",
      "38336 ; loss 1.1 accuracy:37.53 ;\n",
      "<class 'torch.Tensor'> tensor(16756) 16756\n",
      "44736 ; loss 1.1 accuracy:37.4 ;\n",
      "<class 'torch.Tensor'> tensor(19043) 19043\n",
      "51136 ; loss 1.1 accuracy:37.19 ;\n",
      "<class 'torch.Tensor'> tensor(21303) 21303\n",
      "57536 ; loss 1.1 accuracy:36.98 ;\n",
      "<class 'torch.Tensor'> tensor(23875) 23875\n",
      "63936 ; loss 1.1 accuracy:37.3 ;\n",
      "<class 'torch.Tensor'> tensor(26392) 26392\n",
      "70336 ; loss 1.1 accuracy:37.49 ;\n",
      "<class 'torch.Tensor'> tensor(28667) 28667\n",
      "76736 ; loss 1.1 accuracy:37.33 ;\n",
      "<class 'torch.Tensor'> tensor(30791) 30791\n",
      "83136 ; loss 1.1 accuracy:37.01 ;\n",
      "<class 'torch.Tensor'> tensor(32938) 32938\n",
      "89536 ; loss 1.1 accuracy:36.76 ;\n",
      "<class 'torch.Tensor'> tensor(35163) 35163\n",
      "95936 ; loss 1.1 accuracy:36.63 ;\n",
      "<class 'torch.Tensor'> tensor(37407) 37407\n",
      "102336 ; loss 1.1 accuracy:36.53 ;\n",
      "<class 'torch.Tensor'> tensor(40018) 40018\n",
      "108736 ; loss 1.1 accuracy:36.78 ;\n",
      "<class 'torch.Tensor'> tensor(42503) 42503\n",
      "115136 ; loss 1.1 accuracy:36.89 ;\n",
      "<class 'torch.Tensor'> tensor(45049) 45049\n",
      "121536 ; loss 1.1 accuracy:37.05 ;\n",
      "<class 'torch.Tensor'> tensor(47518) 47518\n",
      "127936 ; loss 1.1 accuracy:37.12 ;\n",
      "<class 'torch.Tensor'> tensor(50079) 50079\n",
      "134336 ; loss 1.1 accuracy:37.26 ;\n",
      "<class 'torch.Tensor'> tensor(52622) 52622\n",
      "140736 ; loss 1.1 accuracy:37.37 ;\n",
      "<class 'torch.Tensor'> tensor(55176) 55176\n",
      "147136 ; loss 1.1 accuracy:37.48 ;\n",
      "<class 'torch.Tensor'> tensor(58083) 58083\n",
      "153536 ; loss 1.1 accuracy:37.81 ;\n",
      "<class 'torch.Tensor'> tensor(60750) 60750\n",
      "159936 ; loss 1.1 accuracy:37.97 ;\n",
      "<class 'torch.Tensor'> tensor(63594) 63594\n",
      "166336 ; loss 1.1 accuracy:38.22 ;\n",
      "<class 'torch.Tensor'> tensor(66040) 66040\n",
      "172736 ; loss 1.1 accuracy:38.22 ;\n",
      "<class 'torch.Tensor'> tensor(68478) 68478\n",
      "179136 ; loss 1.1 accuracy:38.21 ;\n",
      "<class 'torch.Tensor'> tensor(71037) 71037\n",
      "185536 ; loss 1.1 accuracy:38.27 ;\n",
      "<class 'torch.Tensor'> tensor(73575) 73575\n",
      "191936 ; loss 1.1 accuracy:38.32 ;\n",
      "<class 'torch.Tensor'> tensor(76273) 76273\n",
      "198336 ; loss 1.1 accuracy:38.44 ;\n",
      "<class 'torch.Tensor'> tensor(78877) 78877\n",
      "204736 ; loss 1.1 accuracy:38.51 ;\n",
      "<class 'torch.Tensor'> tensor(81324) 81324\n",
      "211136 ; loss 1.1 accuracy:38.51 ;\n",
      "<class 'torch.Tensor'> tensor(83619) 83619\n",
      "217536 ; loss 1.1 accuracy:38.43 ;\n",
      "<class 'torch.Tensor'> tensor(86033) 86033\n",
      "223936 ; loss 1.1 accuracy:38.41 ;\n",
      "<class 'torch.Tensor'> tensor(88862) 88862\n",
      "230336 ; loss 1.1 accuracy:38.57 ;\n",
      "<class 'torch.Tensor'> tensor(91532) 91532\n",
      "236736 ; loss 1.1 accuracy:38.65 ;\n",
      "<class 'torch.Tensor'> tensor(94380) 94380\n",
      "243136 ; loss 1.1 accuracy:38.81 ;\n",
      "<class 'torch.Tensor'> tensor(97336) 97336\n",
      "249536 ; loss 1.1 accuracy:39.0 ;\n",
      "<class 'torch.Tensor'> tensor(100166) 100166\n",
      "255936 ; loss 1.1 accuracy:39.13 ;\n",
      "<class 'torch.Tensor'> tensor(102988) 102988\n",
      "262336 ; loss 1.1 accuracy:39.25 ;\n",
      "<class 'torch.Tensor'> tensor(105886) 105886\n",
      "268736 ; loss 1.1 accuracy:39.39 ;\n",
      "<class 'torch.Tensor'> tensor(108779) 108779\n",
      "275136 ; loss 1.1 accuracy:39.53 ;\n",
      "<class 'torch.Tensor'> tensor(111669) 111669\n",
      "281536 ; loss 1.1 accuracy:39.66 ;\n",
      "<class 'torch.Tensor'> tensor(114457) 114457\n",
      "287936 ; loss 1.1 accuracy:39.74 ;\n",
      "<class 'torch.Tensor'> tensor(116917) 116917\n",
      "294336 ; loss 1.1 accuracy:39.71 ;\n",
      "<class 'torch.Tensor'> tensor(119729) 119729\n",
      "300736 ; loss 1.1 accuracy:39.8 ;\n",
      "<class 'torch.Tensor'> tensor(122332) 122332\n",
      "307136 ; loss 1.1 accuracy:39.82 ;\n",
      "<class 'torch.Tensor'> tensor(124764) 124764\n",
      "313536 ; loss 1.1 accuracy:39.78 ;\n",
      "<class 'torch.Tensor'> tensor(127290) 127290\n",
      "319936 ; loss 1.1 accuracy:39.78 ;\n",
      "<class 'torch.Tensor'> tensor(130050) 130050\n",
      "326336 ; loss 1.1 accuracy:39.84 ;\n",
      "<class 'torch.Tensor'> tensor(133056) 133056\n",
      "332736 ; loss 1.1 accuracy:39.98 ;\n",
      "<class 'torch.Tensor'> tensor(136013) 136013\n",
      "339136 ; loss 1.1 accuracy:40.1 ;\n",
      "<class 'torch.Tensor'> tensor(139025) 139025\n",
      "345536 ; loss 1.1 accuracy:40.23 ;\n",
      "<class 'torch.Tensor'> tensor(142026) 142026\n",
      "351936 ; loss 1.1 accuracy:40.35 ;\n",
      "<class 'torch.Tensor'> tensor(144948) 144948\n",
      "358336 ; loss 1.1 accuracy:40.44 ;\n",
      "<class 'torch.Tensor'> tensor(147721) 147721\n",
      "364736 ; loss 1.1 accuracy:40.49 ;\n",
      "<class 'torch.Tensor'> tensor(150472) 150472\n",
      "371136 ; loss 1.1 accuracy:40.54 ;\n",
      "<class 'torch.Tensor'> tensor(153506) 153506\n",
      "377536 ; loss 1.1 accuracy:40.65 ;\n",
      "<class 'torch.Tensor'> tensor(156260) 156260\n",
      "383936 ; loss 1.1 accuracy:40.69 ;\n",
      "<class 'torch.Tensor'> tensor(159104) 159104\n",
      "390336 ; loss 1.1 accuracy:40.75 ;\n",
      "<class 'torch.Tensor'> tensor(161817) 161817\n",
      "396736 ; loss 1.1 accuracy:40.78 ;\n",
      "<class 'torch.Tensor'> tensor(164526) 164526\n",
      "403136 ; loss 1.1 accuracy:40.81 ;\n",
      "<class 'torch.Tensor'> tensor(167166) 167166\n",
      "409536 ; loss 1.1 accuracy:40.81 ;\n",
      "<class 'torch.Tensor'> tensor(170001) 170001\n",
      "415936 ; loss 1.1 accuracy:40.87 ;\n",
      "<class 'torch.Tensor'> tensor(172799) 172799\n",
      "422336 ; loss 1.1 accuracy:40.91 ;\n",
      "<class 'torch.Tensor'> tensor(175666) 175666\n",
      "428736 ; loss 1.1 accuracy:40.97 ;\n",
      "<class 'torch.Tensor'> tensor(178536) 178536\n",
      "435136 ; loss 1.1 accuracy:41.02 ;\n",
      "<class 'torch.Tensor'> tensor(180945) 180945\n",
      "441536 ; loss 1.1 accuracy:40.97 ;\n",
      "<class 'torch.Tensor'> tensor(183173) 183173\n",
      "447936 ; loss 1.1 accuracy:40.89 ;\n",
      "<class 'torch.Tensor'> tensor(185534) 185534\n",
      "454336 ; loss 1.1 accuracy:40.83 ;\n",
      "<class 'torch.Tensor'> tensor(187975) 187975\n",
      "460736 ; loss 1.1 accuracy:40.79 ;\n",
      "<class 'torch.Tensor'> tensor(190559) 190559\n",
      "467136 ; loss 1.1 accuracy:40.79 ;\n",
      "<class 'torch.Tensor'> tensor(193202) 193202\n",
      "473536 ; loss 1.1 accuracy:40.79 ;\n",
      "<class 'torch.Tensor'> tensor(195972) 195972\n",
      "479936 ; loss 1.1 accuracy:40.83 ;\n",
      "<class 'torch.Tensor'> tensor(198706) 198706\n",
      "486336 ; loss 1.1 accuracy:40.85 ;\n",
      "<class 'torch.Tensor'> tensor(201711) 201711\n",
      "492736 ; loss 1.1 accuracy:40.93 ;\n",
      "<class 'torch.Tensor'> tensor(204665) 204665\n",
      "499136 ; loss 1.1 accuracy:41.0 ;\n",
      "<class 'torch.Tensor'> tensor(207109) 207109\n",
      "505536 ; loss 1.1 accuracy:40.96 ;\n",
      "<class 'torch.Tensor'> tensor(209526) 209526\n",
      "511936 ; loss 1.1 accuracy:40.92 ;\n",
      "<class 'torch.Tensor'> tensor(211989) 211989\n",
      "518336 ; loss 1.1 accuracy:40.89 ;\n",
      "<class 'torch.Tensor'> tensor(214395) 214395\n",
      "524736 ; loss 1.1 accuracy:40.85 ;\n",
      "<class 'torch.Tensor'> tensor(216934) 216934\n",
      "531136 ; loss 1.1 accuracy:40.84 ;\n",
      "<class 'torch.Tensor'> tensor(219314) 219314\n",
      "537536 ; loss 1.1 accuracy:40.8 ;\n",
      "<class 'torch.Tensor'> tensor(221743) 221743\n",
      "543936 ; loss 1.1 accuracy:40.76 ;\n",
      "results : epoch 2 ; mean accuracy train : 40.73\n",
      "\n",
      "VALIDATION : Epoch 2\n",
      "togrep : results : epoch 2 ; mean accuracy valid :              42.33\n",
      "saving model at epoch 2\n",
      "\n",
      "TRAINING : Epoch 3\n",
      "Learning rate : 0.09801\n",
      "<class 'torch.Tensor'> tensor(2640) 2640\n",
      "6336 ; loss 1.1 accuracy:41.25 ;\n",
      "<class 'torch.Tensor'> tensor(5483) 5483\n",
      "12736 ; loss 1.1 accuracy:42.84 ;\n",
      "<class 'torch.Tensor'> tensor(8497) 8497\n",
      "19136 ; loss 1.1 accuracy:44.26 ;\n",
      "<class 'torch.Tensor'> tensor(11467) 11467\n",
      "25536 ; loss 1.1 accuracy:44.79 ;\n",
      "<class 'torch.Tensor'> tensor(14352) 14352\n",
      "31936 ; loss 1.1 accuracy:44.85 ;\n",
      "<class 'torch.Tensor'> tensor(17142) 17142\n",
      "38336 ; loss 1.1 accuracy:44.64 ;\n",
      "<class 'torch.Tensor'> tensor(19950) 19950\n",
      "44736 ; loss 1.1 accuracy:44.53 ;\n",
      "<class 'torch.Tensor'> tensor(22693) 22693\n",
      "51136 ; loss 1.1 accuracy:44.32 ;\n",
      "<class 'torch.Tensor'> tensor(25239) 25239\n",
      "57536 ; loss 1.1 accuracy:43.82 ;\n",
      "<class 'torch.Tensor'> tensor(27697) 27697\n",
      "63936 ; loss 1.1 accuracy:43.28 ;\n",
      "<class 'torch.Tensor'> tensor(30112) 30112\n",
      "70336 ; loss 1.1 accuracy:42.77 ;\n",
      "<class 'torch.Tensor'> tensor(32707) 32707\n",
      "76736 ; loss 1.1 accuracy:42.59 ;\n",
      "<class 'torch.Tensor'> tensor(35317) 35317\n",
      "83136 ; loss 1.1 accuracy:42.45 ;\n",
      "<class 'torch.Tensor'> tensor(38143) 38143\n",
      "89536 ; loss 1.1 accuracy:42.57 ;\n",
      "<class 'torch.Tensor'> tensor(40928) 40928\n",
      "95936 ; loss 1.1 accuracy:42.63 ;\n",
      "<class 'torch.Tensor'> tensor(43663) 43663\n",
      "102336 ; loss 1.1 accuracy:42.64 ;\n",
      "<class 'torch.Tensor'> tensor(46535) 46535\n",
      "108736 ; loss 1.1 accuracy:42.77 ;\n",
      "<class 'torch.Tensor'> tensor(49436) 49436\n",
      "115136 ; loss 1.1 accuracy:42.91 ;\n",
      "<class 'torch.Tensor'> tensor(52537) 52537\n",
      "121536 ; loss 1.1 accuracy:43.2 ;\n",
      "<class 'torch.Tensor'> tensor(55684) 55684\n",
      "127936 ; loss 1.1 accuracy:43.5 ;\n",
      "<class 'torch.Tensor'> tensor(58654) 58654\n",
      "134336 ; loss 1.1 accuracy:43.64 ;\n",
      "<class 'torch.Tensor'> tensor(61660) 61660\n",
      "140736 ; loss 1.1 accuracy:43.79 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(64768) 64768\n",
      "147136 ; loss 1.1 accuracy:44.0 ;\n",
      "<class 'torch.Tensor'> tensor(67767) 67767\n",
      "153536 ; loss 1.1 accuracy:44.12 ;\n",
      "<class 'torch.Tensor'> tensor(70872) 70872\n",
      "159936 ; loss 1.1 accuracy:44.3 ;\n",
      "<class 'torch.Tensor'> tensor(73897) 73897\n",
      "166336 ; loss 1.1 accuracy:44.41 ;\n",
      "<class 'torch.Tensor'> tensor(76760) 76760\n",
      "172736 ; loss 1.1 accuracy:44.42 ;\n",
      "<class 'torch.Tensor'> tensor(79449) 79449\n",
      "179136 ; loss 1.1 accuracy:44.34 ;\n",
      "<class 'torch.Tensor'> tensor(82067) 82067\n",
      "185536 ; loss 1.1 accuracy:44.22 ;\n",
      "<class 'torch.Tensor'> tensor(84372) 84372\n",
      "191936 ; loss 1.1 accuracy:43.94 ;\n",
      "<class 'torch.Tensor'> tensor(86779) 86779\n",
      "198336 ; loss 1.1 accuracy:43.74 ;\n",
      "<class 'torch.Tensor'> tensor(89672) 89672\n",
      "204736 ; loss 1.1 accuracy:43.79 ;\n",
      "<class 'torch.Tensor'> tensor(92753) 92753\n",
      "211136 ; loss 1.1 accuracy:43.92 ;\n",
      "<class 'torch.Tensor'> tensor(95815) 95815\n",
      "217536 ; loss 1.1 accuracy:44.03 ;\n",
      "<class 'torch.Tensor'> tensor(98686) 98686\n",
      "223936 ; loss 1.1 accuracy:44.06 ;\n",
      "<class 'torch.Tensor'> tensor(101521) 101521\n",
      "230336 ; loss 1.1 accuracy:44.06 ;\n",
      "<class 'torch.Tensor'> tensor(104164) 104164\n",
      "236736 ; loss 1.1 accuracy:43.99 ;\n",
      "<class 'torch.Tensor'> tensor(106664) 106664\n",
      "243136 ; loss 1.1 accuracy:43.86 ;\n",
      "<class 'torch.Tensor'> tensor(109494) 109494\n",
      "249536 ; loss 1.1 accuracy:43.87 ;\n",
      "<class 'torch.Tensor'> tensor(112417) 112417\n",
      "255936 ; loss 1.1 accuracy:43.91 ;\n",
      "<class 'torch.Tensor'> tensor(115382) 115382\n",
      "262336 ; loss 1.1 accuracy:43.97 ;\n",
      "<class 'torch.Tensor'> tensor(118232) 118232\n",
      "268736 ; loss 1.1 accuracy:43.99 ;\n",
      "<class 'torch.Tensor'> tensor(121204) 121204\n",
      "275136 ; loss 1.1 accuracy:44.04 ;\n",
      "<class 'torch.Tensor'> tensor(124371) 124371\n",
      "281536 ; loss 1.1 accuracy:44.17 ;\n",
      "<class 'torch.Tensor'> tensor(127488) 127488\n",
      "287936 ; loss 1.1 accuracy:44.27 ;\n",
      "<class 'torch.Tensor'> tensor(130486) 130486\n",
      "294336 ; loss 1.1 accuracy:44.32 ;\n",
      "<class 'torch.Tensor'> tensor(133235) 133235\n",
      "300736 ; loss 1.1 accuracy:44.29 ;\n",
      "<class 'torch.Tensor'> tensor(136026) 136026\n",
      "307136 ; loss 1.1 accuracy:44.28 ;\n",
      "<class 'torch.Tensor'> tensor(138664) 138664\n",
      "313536 ; loss 1.1 accuracy:44.22 ;\n",
      "<class 'torch.Tensor'> tensor(141261) 141261\n",
      "319936 ; loss 1.1 accuracy:44.14 ;\n",
      "<class 'torch.Tensor'> tensor(144105) 144105\n",
      "326336 ; loss 1.1 accuracy:44.15 ;\n",
      "<class 'torch.Tensor'> tensor(147068) 147068\n",
      "332736 ; loss 1.1 accuracy:44.19 ;\n",
      "<class 'torch.Tensor'> tensor(149917) 149917\n",
      "339136 ; loss 1.1 accuracy:44.2 ;\n",
      "<class 'torch.Tensor'> tensor(152790) 152790\n",
      "345536 ; loss 1.1 accuracy:44.21 ;\n",
      "<class 'torch.Tensor'> tensor(155821) 155821\n",
      "351936 ; loss 1.1 accuracy:44.27 ;\n",
      "<class 'torch.Tensor'> tensor(158802) 158802\n",
      "358336 ; loss 1.1 accuracy:44.31 ;\n",
      "<class 'torch.Tensor'> tensor(161626) 161626\n",
      "364736 ; loss 1.1 accuracy:44.31 ;\n",
      "<class 'torch.Tensor'> tensor(164532) 164532\n",
      "371136 ; loss 1.1 accuracy:44.32 ;\n",
      "<class 'torch.Tensor'> tensor(167516) 167516\n",
      "377536 ; loss 1.1 accuracy:44.36 ;\n",
      "<class 'torch.Tensor'> tensor(170632) 170632\n",
      "383936 ; loss 1.1 accuracy:44.44 ;\n",
      "<class 'torch.Tensor'> tensor(173744) 173744\n",
      "390336 ; loss 1.1 accuracy:44.5 ;\n",
      "<class 'torch.Tensor'> tensor(176974) 176974\n",
      "396736 ; loss 1.1 accuracy:44.6 ;\n",
      "<class 'torch.Tensor'> tensor(180095) 180095\n",
      "403136 ; loss 1.1 accuracy:44.67 ;\n",
      "<class 'torch.Tensor'> tensor(183085) 183085\n",
      "409536 ; loss 1.1 accuracy:44.7 ;\n",
      "<class 'torch.Tensor'> tensor(186099) 186099\n",
      "415936 ; loss 1.1 accuracy:44.74 ;\n",
      "<class 'torch.Tensor'> tensor(188999) 188999\n",
      "422336 ; loss 1.1 accuracy:44.74 ;\n",
      "<class 'torch.Tensor'> tensor(191974) 191974\n",
      "428736 ; loss 1.1 accuracy:44.77 ;\n",
      "<class 'torch.Tensor'> tensor(194951) 194951\n",
      "435136 ; loss 1.1 accuracy:44.8 ;\n",
      "<class 'torch.Tensor'> tensor(197993) 197993\n",
      "441536 ; loss 1.1 accuracy:44.84 ;\n",
      "<class 'torch.Tensor'> tensor(201083) 201083\n",
      "447936 ; loss 1.1 accuracy:44.88 ;\n",
      "<class 'torch.Tensor'> tensor(204006) 204006\n",
      "454336 ; loss 1.1 accuracy:44.9 ;\n",
      "<class 'torch.Tensor'> tensor(206802) 206802\n",
      "460736 ; loss 1.1 accuracy:44.88 ;\n",
      "<class 'torch.Tensor'> tensor(209593) 209593\n",
      "467136 ; loss 1.1 accuracy:44.86 ;\n",
      "<class 'torch.Tensor'> tensor(212379) 212379\n",
      "473536 ; loss 1.1 accuracy:44.84 ;\n",
      "<class 'torch.Tensor'> tensor(215187) 215187\n",
      "479936 ; loss 1.1 accuracy:44.83 ;\n",
      "<class 'torch.Tensor'> tensor(218058) 218058\n",
      "486336 ; loss 1.1 accuracy:44.83 ;\n",
      "<class 'torch.Tensor'> tensor(221190) 221190\n",
      "492736 ; loss 1.1 accuracy:44.88 ;\n",
      "<class 'torch.Tensor'> tensor(224281) 224281\n",
      "499136 ; loss 1.1 accuracy:44.93 ;\n",
      "<class 'torch.Tensor'> tensor(227403) 227403\n",
      "505536 ; loss 1.1 accuracy:44.98 ;\n",
      "<class 'torch.Tensor'> tensor(230389) 230389\n",
      "511936 ; loss 1.1 accuracy:45.0 ;\n",
      "<class 'torch.Tensor'> tensor(233431) 233431\n",
      "518336 ; loss 1.1 accuracy:45.03 ;\n",
      "<class 'torch.Tensor'> tensor(236588) 236588\n",
      "524736 ; loss 1.1 accuracy:45.08 ;\n",
      "<class 'torch.Tensor'> tensor(239764) 239764\n",
      "531136 ; loss 1.1 accuracy:45.14 ;\n",
      "<class 'torch.Tensor'> tensor(242894) 242894\n",
      "537536 ; loss 1.1 accuracy:45.18 ;\n",
      "<class 'torch.Tensor'> tensor(246020) 246020\n",
      "543936 ; loss 1.1 accuracy:45.22 ;\n",
      "results : epoch 3 ; mean accuracy train : 45.26\n",
      "\n",
      "VALIDATION : Epoch 3\n",
      "togrep : results : epoch 3 ; mean accuracy valid :              50.13\n",
      "saving model at epoch 3\n",
      "\n",
      "TRAINING : Epoch 4\n",
      "Learning rate : 0.0970299\n",
      "<class 'torch.Tensor'> tensor(3188) 3188\n",
      "6336 ; loss 1.1 accuracy:49.81 ;\n",
      "<class 'torch.Tensor'> tensor(6353) 6353\n",
      "12736 ; loss 1.1 accuracy:49.63 ;\n",
      "<class 'torch.Tensor'> tensor(9498) 9498\n",
      "19136 ; loss 1.1 accuracy:49.47 ;\n",
      "<class 'torch.Tensor'> tensor(12636) 12636\n",
      "25536 ; loss 1.1 accuracy:49.36 ;\n",
      "<class 'torch.Tensor'> tensor(15805) 15805\n",
      "31936 ; loss 1.1 accuracy:49.39 ;\n",
      "<class 'torch.Tensor'> tensor(18774) 18774\n",
      "38336 ; loss 1.1 accuracy:48.89 ;\n",
      "<class 'torch.Tensor'> tensor(21754) 21754\n",
      "44736 ; loss 1.1 accuracy:48.56 ;\n",
      "<class 'torch.Tensor'> tensor(24842) 24842\n",
      "51136 ; loss 1.1 accuracy:48.52 ;\n",
      "<class 'torch.Tensor'> tensor(27954) 27954\n",
      "57536 ; loss 1.1 accuracy:48.53 ;\n",
      "<class 'torch.Tensor'> tensor(31094) 31094\n",
      "63936 ; loss 1.1 accuracy:48.58 ;\n",
      "<class 'torch.Tensor'> tensor(34153) 34153\n",
      "70336 ; loss 1.1 accuracy:48.51 ;\n",
      "<class 'torch.Tensor'> tensor(37257) 37257\n",
      "76736 ; loss 1.1 accuracy:48.51 ;\n",
      "<class 'torch.Tensor'> tensor(40311) 40311\n",
      "83136 ; loss 1.1 accuracy:48.45 ;\n",
      "<class 'torch.Tensor'> tensor(43260) 43260\n",
      "89536 ; loss 1.1 accuracy:48.28 ;\n",
      "<class 'torch.Tensor'> tensor(46233) 46233\n",
      "95936 ; loss 1.1 accuracy:48.16 ;\n",
      "<class 'torch.Tensor'> tensor(49225) 49225\n",
      "102336 ; loss 1.1 accuracy:48.07 ;\n",
      "<class 'torch.Tensor'> tensor(52255) 52255\n",
      "108736 ; loss 1.1 accuracy:48.03 ;\n",
      "<class 'torch.Tensor'> tensor(55342) 55342\n",
      "115136 ; loss 1.1 accuracy:48.04 ;\n",
      "<class 'torch.Tensor'> tensor(58471) 58471\n",
      "121536 ; loss 1.1 accuracy:48.08 ;\n",
      "<class 'torch.Tensor'> tensor(61693) 61693\n",
      "127936 ; loss 1.1 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(64907) 64907\n",
      "134336 ; loss 1.1 accuracy:48.29 ;\n",
      "<class 'torch.Tensor'> tensor(68092) 68092\n",
      "140736 ; loss 1.1 accuracy:48.36 ;\n",
      "<class 'torch.Tensor'> tensor(71113) 71113\n",
      "147136 ; loss 1.1 accuracy:48.31 ;\n",
      "<class 'torch.Tensor'> tensor(74028) 74028\n",
      "153536 ; loss 1.1 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(76961) 76961\n",
      "159936 ; loss 1.1 accuracy:48.1 ;\n",
      "<class 'torch.Tensor'> tensor(80069) 80069\n",
      "166336 ; loss 1.1 accuracy:48.12 ;\n",
      "<class 'torch.Tensor'> tensor(83320) 83320\n",
      "172736 ; loss 1.1 accuracy:48.22 ;\n",
      "<class 'torch.Tensor'> tensor(86380) 86380\n",
      "179136 ; loss 1.1 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(89548) 89548\n",
      "185536 ; loss 1.1 accuracy:48.25 ;\n",
      "<class 'torch.Tensor'> tensor(92540) 92540\n",
      "191936 ; loss 1.1 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(95740) 95740\n",
      "198336 ; loss 1.1 accuracy:48.26 ;\n",
      "<class 'torch.Tensor'> tensor(98797) 98797\n",
      "204736 ; loss 1.1 accuracy:48.24 ;\n",
      "<class 'torch.Tensor'> tensor(101808) 101808\n",
      "211136 ; loss 1.1 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(104632) 104632\n",
      "217536 ; loss 1.1 accuracy:48.08 ;\n",
      "<class 'torch.Tensor'> tensor(107503) 107503\n",
      "223936 ; loss 1.1 accuracy:47.99 ;\n",
      "<class 'torch.Tensor'> tensor(110515) 110515\n",
      "230336 ; loss 1.1 accuracy:47.97 ;\n",
      "<class 'torch.Tensor'> tensor(113681) 113681\n",
      "236736 ; loss 1.1 accuracy:48.01 ;\n",
      "<class 'torch.Tensor'> tensor(116839) 116839\n",
      "243136 ; loss 1.1 accuracy:48.04 ;\n",
      "<class 'torch.Tensor'> tensor(119944) 119944\n",
      "249536 ; loss 1.1 accuracy:48.05 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(122919) 122919\n",
      "255936 ; loss 1.1 accuracy:48.02 ;\n",
      "<class 'torch.Tensor'> tensor(125788) 125788\n",
      "262336 ; loss 1.1 accuracy:47.94 ;\n",
      "<class 'torch.Tensor'> tensor(128987) 128987\n",
      "268736 ; loss 1.1 accuracy:47.99 ;\n",
      "<class 'torch.Tensor'> tensor(132127) 132127\n",
      "275136 ; loss 1.1 accuracy:48.01 ;\n",
      "<class 'torch.Tensor'> tensor(135252) 135252\n",
      "281536 ; loss 1.1 accuracy:48.03 ;\n",
      "<class 'torch.Tensor'> tensor(138437) 138437\n",
      "287936 ; loss 1.1 accuracy:48.07 ;\n",
      "<class 'torch.Tensor'> tensor(141618) 141618\n",
      "294336 ; loss 1.1 accuracy:48.1 ;\n",
      "<class 'torch.Tensor'> tensor(144766) 144766\n",
      "300736 ; loss 1.1 accuracy:48.13 ;\n",
      "<class 'torch.Tensor'> tensor(147928) 147928\n",
      "307136 ; loss 1.1 accuracy:48.15 ;\n",
      "<class 'torch.Tensor'> tensor(150996) 150996\n",
      "313536 ; loss 1.1 accuracy:48.15 ;\n",
      "<class 'torch.Tensor'> tensor(154096) 154096\n",
      "319936 ; loss 1.1 accuracy:48.16 ;\n",
      "<class 'torch.Tensor'> tensor(157203) 157203\n",
      "326336 ; loss 1.09 accuracy:48.16 ;\n",
      "<class 'torch.Tensor'> tensor(160382) 160382\n",
      "332736 ; loss 1.09 accuracy:48.19 ;\n",
      "<class 'torch.Tensor'> tensor(163490) 163490\n",
      "339136 ; loss 1.09 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(166585) 166585\n",
      "345536 ; loss 1.09 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(169795) 169795\n",
      "351936 ; loss 1.09 accuracy:48.24 ;\n",
      "<class 'torch.Tensor'> tensor(172911) 172911\n",
      "358336 ; loss 1.09 accuracy:48.25 ;\n",
      "<class 'torch.Tensor'> tensor(175963) 175963\n",
      "364736 ; loss 1.09 accuracy:48.24 ;\n",
      "<class 'torch.Tensor'> tensor(179037) 179037\n",
      "371136 ; loss 1.09 accuracy:48.23 ;\n",
      "<class 'torch.Tensor'> tensor(182062) 182062\n",
      "377536 ; loss 1.09 accuracy:48.22 ;\n",
      "<class 'torch.Tensor'> tensor(185123) 185123\n",
      "383936 ; loss 1.09 accuracy:48.21 ;\n",
      "<class 'torch.Tensor'> tensor(188067) 188067\n",
      "390336 ; loss 1.09 accuracy:48.17 ;\n",
      "<class 'torch.Tensor'> tensor(191064) 191064\n",
      "396736 ; loss 1.09 accuracy:48.15 ;\n",
      "<class 'torch.Tensor'> tensor(193993) 193993\n",
      "403136 ; loss 1.09 accuracy:48.11 ;\n",
      "<class 'torch.Tensor'> tensor(197036) 197036\n",
      "409536 ; loss 1.09 accuracy:48.1 ;\n",
      "<class 'torch.Tensor'> tensor(200203) 200203\n",
      "415936 ; loss 1.09 accuracy:48.13 ;\n",
      "<class 'torch.Tensor'> tensor(203230) 203230\n",
      "422336 ; loss 1.09 accuracy:48.11 ;\n",
      "<class 'torch.Tensor'> tensor(206415) 206415\n",
      "428736 ; loss 1.09 accuracy:48.14 ;\n",
      "<class 'torch.Tensor'> tensor(209560) 209560\n",
      "435136 ; loss 1.09 accuracy:48.15 ;\n",
      "<class 'torch.Tensor'> tensor(212759) 212759\n",
      "441536 ; loss 1.09 accuracy:48.18 ;\n",
      "<class 'torch.Tensor'> tensor(215938) 215938\n",
      "447936 ; loss 1.09 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(219044) 219044\n",
      "454336 ; loss 1.09 accuracy:48.21 ;\n",
      "<class 'torch.Tensor'> tensor(222128) 222128\n",
      "460736 ; loss 1.09 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(225139) 225139\n",
      "467136 ; loss 1.09 accuracy:48.19 ;\n",
      "<class 'torch.Tensor'> tensor(228080) 228080\n",
      "473536 ; loss 1.09 accuracy:48.16 ;\n",
      "<class 'torch.Tensor'> tensor(231156) 231156\n",
      "479936 ; loss 1.09 accuracy:48.16 ;\n",
      "<class 'torch.Tensor'> tensor(234434) 234434\n",
      "486336 ; loss 1.09 accuracy:48.2 ;\n",
      "<class 'torch.Tensor'> tensor(237620) 237620\n",
      "492736 ; loss 1.09 accuracy:48.22 ;\n",
      "<class 'torch.Tensor'> tensor(240774) 240774\n",
      "499136 ; loss 1.09 accuracy:48.23 ;\n",
      "<class 'torch.Tensor'> tensor(243900) 243900\n",
      "505536 ; loss 1.09 accuracy:48.24 ;\n",
      "<class 'torch.Tensor'> tensor(247022) 247022\n",
      "511936 ; loss 1.09 accuracy:48.25 ;\n",
      "<class 'torch.Tensor'> tensor(249945) 249945\n",
      "518336 ; loss 1.09 accuracy:48.21 ;\n",
      "<class 'torch.Tensor'> tensor(252853) 252853\n",
      "524736 ; loss 1.09 accuracy:48.18 ;\n",
      "<class 'torch.Tensor'> tensor(255604) 255604\n",
      "531136 ; loss 1.09 accuracy:48.12 ;\n",
      "<class 'torch.Tensor'> tensor(258284) 258284\n",
      "537536 ; loss 1.09 accuracy:48.04 ;\n",
      "<class 'torch.Tensor'> tensor(261111) 261111\n",
      "543936 ; loss 1.09 accuracy:48.0 ;\n",
      "results : epoch 4 ; mean accuracy train : 47.99\n",
      "\n",
      "VALIDATION : Epoch 4\n",
      "togrep : results : epoch 4 ; mean accuracy valid :              48.23\n",
      "Shrinking lr by : 5. New lr = 0.01940598\n",
      "\n",
      "TRAINING : Epoch 5\n",
      "Learning rate : 0.0192119202\n",
      "<class 'torch.Tensor'> tensor(3065) 3065\n",
      "6336 ; loss 1.09 accuracy:47.89 ;\n",
      "<class 'torch.Tensor'> tensor(6115) 6115\n",
      "12736 ; loss 1.09 accuracy:47.77 ;\n",
      "<class 'torch.Tensor'> tensor(9225) 9225\n",
      "19136 ; loss 1.09 accuracy:48.05 ;\n",
      "<class 'torch.Tensor'> tensor(12361) 12361\n",
      "25536 ; loss 1.09 accuracy:48.29 ;\n",
      "<class 'torch.Tensor'> tensor(15500) 15500\n",
      "31936 ; loss 1.09 accuracy:48.44 ;\n",
      "<class 'torch.Tensor'> tensor(18599) 18599\n",
      "38336 ; loss 1.09 accuracy:48.43 ;\n",
      "<class 'torch.Tensor'> tensor(21781) 21781\n",
      "44736 ; loss 1.09 accuracy:48.62 ;\n",
      "<class 'torch.Tensor'> tensor(24871) 24871\n",
      "51136 ; loss 1.09 accuracy:48.58 ;\n",
      "<class 'torch.Tensor'> tensor(28055) 28055\n",
      "57536 ; loss 1.09 accuracy:48.71 ;\n",
      "<class 'torch.Tensor'> tensor(31222) 31222\n",
      "63936 ; loss 1.09 accuracy:48.78 ;\n",
      "<class 'torch.Tensor'> tensor(34480) 34480\n",
      "70336 ; loss 1.09 accuracy:48.98 ;\n",
      "<class 'torch.Tensor'> tensor(37681) 37681\n",
      "76736 ; loss 1.09 accuracy:49.06 ;\n",
      "<class 'torch.Tensor'> tensor(40921) 40921\n",
      "83136 ; loss 1.09 accuracy:49.18 ;\n",
      "<class 'torch.Tensor'> tensor(44150) 44150\n",
      "89536 ; loss 1.09 accuracy:49.27 ;\n",
      "<class 'torch.Tensor'> tensor(47448) 47448\n",
      "95936 ; loss 1.09 accuracy:49.42 ;\n",
      "<class 'torch.Tensor'> tensor(50691) 50691\n",
      "102336 ; loss 1.09 accuracy:49.5 ;\n",
      "<class 'torch.Tensor'> tensor(53945) 53945\n",
      "108736 ; loss 1.09 accuracy:49.58 ;\n",
      "<class 'torch.Tensor'> tensor(57230) 57230\n",
      "115136 ; loss 1.09 accuracy:49.68 ;\n",
      "<class 'torch.Tensor'> tensor(60413) 60413\n",
      "121536 ; loss 1.09 accuracy:49.68 ;\n",
      "<class 'torch.Tensor'> tensor(63613) 63613\n",
      "127936 ; loss 1.09 accuracy:49.7 ;\n",
      "<class 'torch.Tensor'> tensor(66797) 66797\n",
      "134336 ; loss 1.09 accuracy:49.7 ;\n",
      "<class 'torch.Tensor'> tensor(70009) 70009\n",
      "140736 ; loss 1.09 accuracy:49.72 ;\n",
      "<class 'torch.Tensor'> tensor(73172) 73172\n",
      "147136 ; loss 1.09 accuracy:49.71 ;\n",
      "<class 'torch.Tensor'> tensor(76339) 76339\n",
      "153536 ; loss 1.09 accuracy:49.7 ;\n",
      "<class 'torch.Tensor'> tensor(79507) 79507\n",
      "159936 ; loss 1.09 accuracy:49.69 ;\n",
      "<class 'torch.Tensor'> tensor(82666) 82666\n",
      "166336 ; loss 1.09 accuracy:49.68 ;\n",
      "<class 'torch.Tensor'> tensor(85801) 85801\n",
      "172736 ; loss 1.09 accuracy:49.65 ;\n",
      "<class 'torch.Tensor'> tensor(89015) 89015\n",
      "179136 ; loss 1.09 accuracy:49.67 ;\n",
      "<class 'torch.Tensor'> tensor(92173) 92173\n",
      "185536 ; loss 1.09 accuracy:49.66 ;\n",
      "<class 'torch.Tensor'> tensor(95340) 95340\n",
      "191936 ; loss 1.09 accuracy:49.66 ;\n",
      "<class 'torch.Tensor'> tensor(98489) 98489\n",
      "198336 ; loss 1.09 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(101695) 101695\n",
      "204736 ; loss 1.09 accuracy:49.66 ;\n",
      "<class 'torch.Tensor'> tensor(104896) 104896\n",
      "211136 ; loss 1.09 accuracy:49.67 ;\n",
      "<class 'torch.Tensor'> tensor(108099) 108099\n",
      "217536 ; loss 1.09 accuracy:49.68 ;\n",
      "<class 'torch.Tensor'> tensor(111332) 111332\n",
      "223936 ; loss 1.09 accuracy:49.7 ;\n",
      "<class 'torch.Tensor'> tensor(114586) 114586\n",
      "230336 ; loss 1.09 accuracy:49.73 ;\n",
      "<class 'torch.Tensor'> tensor(117845) 117845\n",
      "236736 ; loss 1.09 accuracy:49.77 ;\n",
      "<class 'torch.Tensor'> tensor(121088) 121088\n",
      "243136 ; loss 1.09 accuracy:49.79 ;\n",
      "<class 'torch.Tensor'> tensor(124318) 124318\n",
      "249536 ; loss 1.09 accuracy:49.81 ;\n",
      "<class 'torch.Tensor'> tensor(127615) 127615\n",
      "255936 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(130783) 130783\n",
      "262336 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(134047) 134047\n",
      "268736 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(137283) 137283\n",
      "275136 ; loss 1.09 accuracy:49.88 ;\n",
      "<class 'torch.Tensor'> tensor(140387) 140387\n",
      "281536 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(143591) 143591\n",
      "287936 ; loss 1.09 accuracy:49.86 ;\n",
      "<class 'torch.Tensor'> tensor(146745) 146745\n",
      "294336 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(149872) 149872\n",
      "300736 ; loss 1.09 accuracy:49.82 ;\n",
      "<class 'torch.Tensor'> tensor(152994) 152994\n",
      "307136 ; loss 1.09 accuracy:49.8 ;\n",
      "<class 'torch.Tensor'> tensor(156107) 156107\n",
      "313536 ; loss 1.09 accuracy:49.78 ;\n",
      "<class 'torch.Tensor'> tensor(159238) 159238\n",
      "319936 ; loss 1.09 accuracy:49.76 ;\n",
      "<class 'torch.Tensor'> tensor(162430) 162430\n",
      "326336 ; loss 1.09 accuracy:49.76 ;\n",
      "<class 'torch.Tensor'> tensor(165676) 165676\n",
      "332736 ; loss 1.09 accuracy:49.78 ;\n",
      "<class 'torch.Tensor'> tensor(168827) 168827\n",
      "339136 ; loss 1.09 accuracy:49.77 ;\n",
      "<class 'torch.Tensor'> tensor(172065) 172065\n",
      "345536 ; loss 1.09 accuracy:49.79 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(175294) 175294\n",
      "351936 ; loss 1.09 accuracy:49.8 ;\n",
      "<class 'torch.Tensor'> tensor(178537) 178537\n",
      "358336 ; loss 1.09 accuracy:49.82 ;\n",
      "<class 'torch.Tensor'> tensor(181730) 181730\n",
      "364736 ; loss 1.09 accuracy:49.82 ;\n",
      "<class 'torch.Tensor'> tensor(184934) 184934\n",
      "371136 ; loss 1.09 accuracy:49.82 ;\n",
      "<class 'torch.Tensor'> tensor(188113) 188113\n",
      "377536 ; loss 1.09 accuracy:49.82 ;\n",
      "<class 'torch.Tensor'> tensor(191281) 191281\n",
      "383936 ; loss 1.09 accuracy:49.81 ;\n",
      "<class 'torch.Tensor'> tensor(194581) 194581\n",
      "390336 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(197809) 197809\n",
      "396736 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(200998) 200998\n",
      "403136 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(204226) 204226\n",
      "409536 ; loss 1.09 accuracy:49.86 ;\n",
      "<class 'torch.Tensor'> tensor(207345) 207345\n",
      "415936 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(210534) 210534\n",
      "422336 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(213698) 213698\n",
      "428736 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(216868) 216868\n",
      "435136 ; loss 1.09 accuracy:49.83 ;\n",
      "<class 'torch.Tensor'> tensor(220093) 220093\n",
      "441536 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(223299) 223299\n",
      "447936 ; loss 1.09 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(226578) 226578\n",
      "454336 ; loss 1.09 accuracy:49.86 ;\n",
      "<class 'torch.Tensor'> tensor(229762) 229762\n",
      "460736 ; loss 1.09 accuracy:49.86 ;\n",
      "<class 'torch.Tensor'> tensor(232997) 232997\n",
      "467136 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(236190) 236190\n",
      "473536 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(239403) 239403\n",
      "479936 ; loss 1.09 accuracy:49.88 ;\n",
      "<class 'torch.Tensor'> tensor(242574) 242574\n",
      "486336 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(245749) 245749\n",
      "492736 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(248928) 248928\n",
      "499136 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(252106) 252106\n",
      "505536 ; loss 1.09 accuracy:49.86 ;\n",
      "<class 'torch.Tensor'> tensor(255245) 255245\n",
      "511936 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(258484) 258484\n",
      "518336 ; loss 1.09 accuracy:49.86 ;\n",
      "<class 'torch.Tensor'> tensor(261699) 261699\n",
      "524736 ; loss 1.09 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(264817) 264817\n",
      "531136 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(268010) 268010\n",
      "537536 ; loss 1.09 accuracy:49.85 ;\n",
      "<class 'torch.Tensor'> tensor(271193) 271193\n",
      "543936 ; loss 1.09 accuracy:49.85 ;\n",
      "results : epoch 5 ; mean accuracy train : 49.85\n",
      "\n",
      "VALIDATION : Epoch 5\n",
      "togrep : results : epoch 5 ; mean accuracy valid :              49.93\n",
      "Shrinking lr by : 5. New lr = 0.0038423840399999997\n",
      "\n",
      "TRAINING : Epoch 6\n",
      "Learning rate : 0.0038039601995999996\n",
      "<class 'torch.Tensor'> tensor(3255) 3255\n",
      "6336 ; loss 1.09 accuracy:50.86 ;\n",
      "<class 'torch.Tensor'> tensor(6409) 6409\n",
      "12736 ; loss 1.09 accuracy:50.07 ;\n",
      "<class 'torch.Tensor'> tensor(9642) 9642\n",
      "19136 ; loss 1.09 accuracy:50.22 ;\n",
      "<class 'torch.Tensor'> tensor(12850) 12850\n",
      "25536 ; loss 1.09 accuracy:50.2 ;\n",
      "<class 'torch.Tensor'> tensor(16133) 16133\n",
      "31936 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(19372) 19372\n",
      "38336 ; loss 1.09 accuracy:50.45 ;\n",
      "<class 'torch.Tensor'> tensor(22578) 22578\n",
      "44736 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(25773) 25773\n",
      "51136 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(28957) 28957\n",
      "57536 ; loss 1.09 accuracy:50.27 ;\n",
      "<class 'torch.Tensor'> tensor(32121) 32121\n",
      "63936 ; loss 1.09 accuracy:50.19 ;\n",
      "<class 'torch.Tensor'> tensor(35309) 35309\n",
      "70336 ; loss 1.09 accuracy:50.15 ;\n",
      "<class 'torch.Tensor'> tensor(38527) 38527\n",
      "76736 ; loss 1.09 accuracy:50.17 ;\n",
      "<class 'torch.Tensor'> tensor(41742) 41742\n",
      "83136 ; loss 1.09 accuracy:50.17 ;\n",
      "<class 'torch.Tensor'> tensor(44979) 44979\n",
      "89536 ; loss 1.09 accuracy:50.2 ;\n",
      "<class 'torch.Tensor'> tensor(48174) 48174\n",
      "95936 ; loss 1.09 accuracy:50.18 ;\n",
      "<class 'torch.Tensor'> tensor(51359) 51359\n",
      "102336 ; loss 1.09 accuracy:50.16 ;\n",
      "<class 'torch.Tensor'> tensor(54504) 54504\n",
      "108736 ; loss 1.09 accuracy:50.1 ;\n",
      "<class 'torch.Tensor'> tensor(57721) 57721\n",
      "115136 ; loss 1.09 accuracy:50.11 ;\n",
      "<class 'torch.Tensor'> tensor(60922) 60922\n",
      "121536 ; loss 1.09 accuracy:50.1 ;\n",
      "<class 'torch.Tensor'> tensor(64135) 64135\n",
      "127936 ; loss 1.09 accuracy:50.11 ;\n",
      "<class 'torch.Tensor'> tensor(67338) 67338\n",
      "134336 ; loss 1.09 accuracy:50.1 ;\n",
      "<class 'torch.Tensor'> tensor(70514) 70514\n",
      "140736 ; loss 1.09 accuracy:50.08 ;\n",
      "<class 'torch.Tensor'> tensor(73680) 73680\n",
      "147136 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(76870) 76870\n",
      "153536 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(80073) 80073\n",
      "159936 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(83302) 83302\n",
      "166336 ; loss 1.09 accuracy:50.06 ;\n",
      "<class 'torch.Tensor'> tensor(86564) 86564\n",
      "172736 ; loss 1.09 accuracy:50.09 ;\n",
      "<class 'torch.Tensor'> tensor(89713) 89713\n",
      "179136 ; loss 1.09 accuracy:50.06 ;\n",
      "<class 'torch.Tensor'> tensor(92882) 92882\n",
      "185536 ; loss 1.09 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(96045) 96045\n",
      "191936 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(99250) 99250\n",
      "198336 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(102440) 102440\n",
      "204736 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(105612) 105612\n",
      "211136 ; loss 1.09 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(108776) 108776\n",
      "217536 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(111985) 111985\n",
      "223936 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(115162) 115162\n",
      "230336 ; loss 1.09 accuracy:49.98 ;\n",
      "<class 'torch.Tensor'> tensor(118438) 118438\n",
      "236736 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(121646) 121646\n",
      "243136 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(124880) 124880\n",
      "249536 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(128121) 128121\n",
      "255936 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(131364) 131364\n",
      "262336 ; loss 1.09 accuracy:50.06 ;\n",
      "<class 'torch.Tensor'> tensor(134519) 134519\n",
      "268736 ; loss 1.09 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(137707) 137707\n",
      "275136 ; loss 1.09 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(140884) 140884\n",
      "281536 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(144086) 144086\n",
      "287936 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(147274) 147274\n",
      "294336 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(150513) 150513\n",
      "300736 ; loss 1.09 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(153750) 153750\n",
      "307136 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(156855) 156855\n",
      "313536 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(160010) 160010\n",
      "319936 ; loss 1.09 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(163174) 163174\n",
      "326336 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(166330) 166330\n",
      "332736 ; loss 1.09 accuracy:49.98 ;\n",
      "<class 'torch.Tensor'> tensor(169580) 169580\n",
      "339136 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(172788) 172788\n",
      "345536 ; loss 1.09 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(176009) 176009\n",
      "351936 ; loss 1.09 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(179165) 179165\n",
      "358336 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(182338) 182338\n",
      "364736 ; loss 1.09 accuracy:49.98 ;\n",
      "<class 'torch.Tensor'> tensor(185508) 185508\n",
      "371136 ; loss 1.09 accuracy:49.98 ;\n",
      "<class 'torch.Tensor'> tensor(188762) 188762\n",
      "377536 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(191979) 191979\n",
      "383936 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(195137) 195137\n",
      "390336 ; loss 1.09 accuracy:49.98 ;\n",
      "<class 'torch.Tensor'> tensor(198370) 198370\n",
      "396736 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(201576) 201576\n",
      "403136 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(204798) 204798\n",
      "409536 ; loss 1.09 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(208004) 208004\n",
      "415936 ; loss 1.09 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(211244) 211244\n",
      "422336 ; loss 1.09 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(214424) 214424\n",
      "428736 ; loss 1.09 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(217643) 217643\n",
      "435136 ; loss 1.09 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(220805) 220805\n",
      "441536 ; loss 1.09 accuracy:50.0 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(223970) 223970\n",
      "447936 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(227156) 227156\n",
      "454336 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(230371) 230371\n",
      "460736 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(233576) 233576\n",
      "467136 ; loss 1.09 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(236848) 236848\n",
      "473536 ; loss 1.09 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(240071) 240071\n",
      "479936 ; loss 1.09 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(243310) 243310\n",
      "486336 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(246571) 246571\n",
      "492736 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(249799) 249799\n",
      "499136 ; loss 1.09 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(253030) 253030\n",
      "505536 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(256275) 256275\n",
      "511936 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(259453) 259453\n",
      "518336 ; loss 1.09 accuracy:50.05 ;\n",
      "<class 'torch.Tensor'> tensor(262556) 262556\n",
      "524736 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(265722) 265722\n",
      "531136 ; loss 1.09 accuracy:50.02 ;\n",
      "<class 'torch.Tensor'> tensor(268948) 268948\n",
      "537536 ; loss 1.09 accuracy:50.03 ;\n",
      "<class 'torch.Tensor'> tensor(272139) 272139\n",
      "543936 ; loss 1.09 accuracy:50.03 ;\n",
      "results : epoch 6 ; mean accuracy train : 50.04\n",
      "\n",
      "VALIDATION : Epoch 6\n",
      "togrep : results : epoch 6 ; mean accuracy valid :              50.7\n",
      "saving model at epoch 6\n",
      "\n",
      "TRAINING : Epoch 7\n",
      "Learning rate : 0.0037659205976039996\n",
      "<class 'torch.Tensor'> tensor(3289) 3289\n",
      "6336 ; loss 1.09 accuracy:51.39 ;\n",
      "<class 'torch.Tensor'> tensor(6510) 6510\n",
      "12736 ; loss 1.09 accuracy:50.86 ;\n",
      "<class 'torch.Tensor'> tensor(9695) 9695\n",
      "19136 ; loss 1.09 accuracy:50.49 ;\n",
      "<class 'torch.Tensor'> tensor(12861) 12861\n",
      "25536 ; loss 1.09 accuracy:50.24 ;\n",
      "<class 'torch.Tensor'> tensor(16067) 16067\n",
      "31936 ; loss 1.09 accuracy:50.21 ;\n",
      "<class 'torch.Tensor'> tensor(19261) 19261\n",
      "38336 ; loss 1.09 accuracy:50.16 ;\n",
      "<class 'torch.Tensor'> tensor(22507) 22507\n",
      "44736 ; loss 1.09 accuracy:50.24 ;\n",
      "<class 'torch.Tensor'> tensor(25706) 25706\n",
      "51136 ; loss 1.09 accuracy:50.21 ;\n",
      "<class 'torch.Tensor'> tensor(28872) 28872\n",
      "57536 ; loss 1.09 accuracy:50.12 ;\n",
      "<class 'torch.Tensor'> tensor(32077) 32077\n",
      "63936 ; loss 1.09 accuracy:50.12 ;\n",
      "<class 'torch.Tensor'> tensor(35320) 35320\n",
      "70336 ; loss 1.09 accuracy:50.17 ;\n",
      "<class 'torch.Tensor'> tensor(38510) 38510\n",
      "76736 ; loss 1.09 accuracy:50.14 ;\n",
      "<class 'torch.Tensor'> tensor(41745) 41745\n",
      "83136 ; loss 1.09 accuracy:50.17 ;\n",
      "<class 'torch.Tensor'> tensor(44958) 44958\n",
      "89536 ; loss 1.09 accuracy:50.18 ;\n",
      "<class 'torch.Tensor'> tensor(48228) 48228\n",
      "95936 ; loss 1.09 accuracy:50.24 ;\n",
      "<class 'torch.Tensor'> tensor(51422) 51422\n",
      "102336 ; loss 1.09 accuracy:50.22 ;\n",
      "<class 'torch.Tensor'> tensor(54728) 54728\n",
      "108736 ; loss 1.09 accuracy:50.3 ;\n",
      "<class 'torch.Tensor'> tensor(57920) 57920\n",
      "115136 ; loss 1.09 accuracy:50.28 ;\n",
      "<class 'torch.Tensor'> tensor(61224) 61224\n",
      "121536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(64427) 64427\n",
      "127936 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(67655) 67655\n",
      "134336 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(70907) 70907\n",
      "140736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(74159) 74159\n",
      "147136 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(77347) 77347\n",
      "153536 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(80596) 80596\n",
      "159936 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(83831) 83831\n",
      "166336 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(87061) 87061\n",
      "172736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(90336) 90336\n",
      "179136 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(93557) 93557\n",
      "185536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(96810) 96810\n",
      "191936 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(100003) 100003\n",
      "198336 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(103224) 103224\n",
      "204736 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(106438) 106438\n",
      "211136 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(109683) 109683\n",
      "217536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(112925) 112925\n",
      "223936 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(116101) 116101\n",
      "230336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(119299) 119299\n",
      "236736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(122499) 122499\n",
      "243136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(125687) 125687\n",
      "249536 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(128982) 128982\n",
      "255936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(132245) 132245\n",
      "262336 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(135418) 135418\n",
      "268736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(138563) 138563\n",
      "275136 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(141831) 141831\n",
      "281536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(145028) 145028\n",
      "287936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(148190) 148190\n",
      "294336 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(151408) 151408\n",
      "300736 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(154622) 154622\n",
      "307136 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(157760) 157760\n",
      "313536 ; loss 1.09 accuracy:50.31 ;\n",
      "<class 'torch.Tensor'> tensor(161037) 161037\n",
      "319936 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(164289) 164289\n",
      "326336 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(167568) 167568\n",
      "332736 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(170807) 170807\n",
      "339136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(174022) 174022\n",
      "345536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(177273) 177273\n",
      "351936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(180520) 180520\n",
      "358336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(183710) 183710\n",
      "364736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(186879) 186879\n",
      "371136 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(190058) 190058\n",
      "377536 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(193210) 193210\n",
      "383936 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(196485) 196485\n",
      "390336 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(199689) 199689\n",
      "396736 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(202895) 202895\n",
      "403136 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(206138) 206138\n",
      "409536 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(209415) 209415\n",
      "415936 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(212662) 212662\n",
      "422336 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(215931) 215931\n",
      "428736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(219182) 219182\n",
      "435136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(222427) 222427\n",
      "441536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(225619) 225619\n",
      "447936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(228795) 228795\n",
      "454336 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(232065) 232065\n",
      "460736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(235319) 235319\n",
      "467136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(238518) 238518\n",
      "473536 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(241723) 241723\n",
      "479936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(244973) 244973\n",
      "486336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(248195) 248195\n",
      "492736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(251430) 251430\n",
      "499136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(254685) 254685\n",
      "505536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(257926) 257926\n",
      "511936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(261118) 261118\n",
      "518336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(264453) 264453\n",
      "524736 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(267702) 267702\n",
      "531136 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(270948) 270948\n",
      "537536 ; loss 1.09 accuracy:50.4 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(274180) 274180\n",
      "543936 ; loss 1.09 accuracy:50.4 ;\n",
      "results : epoch 7 ; mean accuracy train : 50.41\n",
      "\n",
      "VALIDATION : Epoch 7\n",
      "togrep : results : epoch 7 ; mean accuracy valid :              50.57\n",
      "Shrinking lr by : 5. New lr = 0.0007531841195207999\n",
      "\n",
      "TRAINING : Epoch 8\n",
      "Learning rate : 0.0007456522783255919\n",
      "<class 'torch.Tensor'> tensor(3225) 3225\n",
      "6336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(6424) 6424\n",
      "12736 ; loss 1.09 accuracy:50.19 ;\n",
      "<class 'torch.Tensor'> tensor(9653) 9653\n",
      "19136 ; loss 1.09 accuracy:50.28 ;\n",
      "<class 'torch.Tensor'> tensor(12832) 12832\n",
      "25536 ; loss 1.09 accuracy:50.12 ;\n",
      "<class 'torch.Tensor'> tensor(16040) 16040\n",
      "31936 ; loss 1.09 accuracy:50.12 ;\n",
      "<class 'torch.Tensor'> tensor(19237) 19237\n",
      "38336 ; loss 1.09 accuracy:50.1 ;\n",
      "<class 'torch.Tensor'> tensor(22513) 22513\n",
      "44736 ; loss 1.09 accuracy:50.25 ;\n",
      "<class 'torch.Tensor'> tensor(25729) 25729\n",
      "51136 ; loss 1.09 accuracy:50.25 ;\n",
      "<class 'torch.Tensor'> tensor(28982) 28982\n",
      "57536 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(32181) 32181\n",
      "63936 ; loss 1.09 accuracy:50.28 ;\n",
      "<class 'torch.Tensor'> tensor(35358) 35358\n",
      "70336 ; loss 1.09 accuracy:50.22 ;\n",
      "<class 'torch.Tensor'> tensor(38600) 38600\n",
      "76736 ; loss 1.09 accuracy:50.26 ;\n",
      "<class 'torch.Tensor'> tensor(41867) 41867\n",
      "83136 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(45125) 45125\n",
      "89536 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(48385) 48385\n",
      "95936 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(51547) 51547\n",
      "102336 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(54809) 54809\n",
      "108736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(58060) 58060\n",
      "115136 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(61355) 61355\n",
      "121536 ; loss 1.09 accuracy:50.46 ;\n",
      "<class 'torch.Tensor'> tensor(64587) 64587\n",
      "127936 ; loss 1.09 accuracy:50.46 ;\n",
      "<class 'torch.Tensor'> tensor(67773) 67773\n",
      "134336 ; loss 1.09 accuracy:50.43 ;\n",
      "<class 'torch.Tensor'> tensor(70993) 70993\n",
      "140736 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(74225) 74225\n",
      "147136 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(77434) 77434\n",
      "153536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(80681) 80681\n",
      "159936 ; loss 1.09 accuracy:50.43 ;\n",
      "<class 'torch.Tensor'> tensor(83899) 83899\n",
      "166336 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(87156) 87156\n",
      "172736 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(90381) 90381\n",
      "179136 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(93617) 93617\n",
      "185536 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(96813) 96813\n",
      "191936 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(100030) 100030\n",
      "198336 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(103268) 103268\n",
      "204736 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(106475) 106475\n",
      "211136 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(109728) 109728\n",
      "217536 ; loss 1.09 accuracy:50.43 ;\n",
      "<class 'torch.Tensor'> tensor(112936) 112936\n",
      "223936 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(116170) 116170\n",
      "230336 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(119393) 119393\n",
      "236736 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(122560) 122560\n",
      "243136 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(125757) 125757\n",
      "249536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(129046) 129046\n",
      "255936 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(132220) 132220\n",
      "262336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(135364) 135364\n",
      "268736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(138585) 138585\n",
      "275136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(141867) 141867\n",
      "281536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(145043) 145043\n",
      "287936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(148227) 148227\n",
      "294336 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(151487) 151487\n",
      "300736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(154709) 154709\n",
      "307136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(158001) 158001\n",
      "313536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(161180) 161180\n",
      "319936 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(164418) 164418\n",
      "326336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(167630) 167630\n",
      "332736 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(170833) 170833\n",
      "339136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(174082) 174082\n",
      "345536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(177275) 177275\n",
      "351936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(180498) 180498\n",
      "358336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(183767) 183767\n",
      "364736 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(187043) 187043\n",
      "371136 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(190294) 190294\n",
      "377536 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(193545) 193545\n",
      "383936 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(196751) 196751\n",
      "390336 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(199992) 199992\n",
      "396736 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(203246) 203246\n",
      "403136 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(206430) 206430\n",
      "409536 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(209637) 209637\n",
      "415936 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(212875) 212875\n",
      "422336 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(216049) 216049\n",
      "428736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(219258) 219258\n",
      "435136 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(222535) 222535\n",
      "441536 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(225769) 225769\n",
      "447936 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(228939) 228939\n",
      "454336 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(232119) 232119\n",
      "460736 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(235325) 235325\n",
      "467136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(238561) 238561\n",
      "473536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(241767) 241767\n",
      "479936 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(244984) 244984\n",
      "486336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(248271) 248271\n",
      "492736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(251390) 251390\n",
      "499136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(254594) 254594\n",
      "505536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(257826) 257826\n",
      "511936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(261124) 261124\n",
      "518336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(264370) 264370\n",
      "524736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(267599) 267599\n",
      "531136 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(270800) 270800\n",
      "537536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(274029) 274029\n",
      "543936 ; loss 1.09 accuracy:50.37 ;\n",
      "results : epoch 8 ; mean accuracy train : 50.36\n",
      "\n",
      "VALIDATION : Epoch 8\n",
      "togrep : results : epoch 8 ; mean accuracy valid :              50.61\n",
      "Shrinking lr by : 5. New lr = 0.00014913045566511838\n",
      "\n",
      "TRAINING : Epoch 9\n",
      "Learning rate : 0.00014763915110846718\n",
      "<class 'torch.Tensor'> tensor(3159) 3159\n",
      "6336 ; loss 1.09 accuracy:49.36 ;\n",
      "<class 'torch.Tensor'> tensor(6351) 6351\n",
      "12736 ; loss 1.09 accuracy:49.62 ;\n",
      "<class 'torch.Tensor'> tensor(9577) 9577\n",
      "19136 ; loss 1.09 accuracy:49.88 ;\n",
      "<class 'torch.Tensor'> tensor(12822) 12822\n",
      "25536 ; loss 1.09 accuracy:50.09 ;\n",
      "<class 'torch.Tensor'> tensor(16027) 16027\n",
      "31936 ; loss 1.09 accuracy:50.08 ;\n",
      "<class 'torch.Tensor'> tensor(19222) 19222\n",
      "38336 ; loss 1.09 accuracy:50.06 ;\n",
      "<class 'torch.Tensor'> tensor(22460) 22460\n",
      "44736 ; loss 1.09 accuracy:50.13 ;\n",
      "<class 'torch.Tensor'> tensor(25692) 25692\n",
      "51136 ; loss 1.09 accuracy:50.18 ;\n",
      "<class 'torch.Tensor'> tensor(28888) 28888\n",
      "57536 ; loss 1.09 accuracy:50.15 ;\n",
      "<class 'torch.Tensor'> tensor(32082) 32082\n",
      "63936 ; loss 1.09 accuracy:50.13 ;\n",
      "<class 'torch.Tensor'> tensor(35340) 35340\n",
      "70336 ; loss 1.09 accuracy:50.2 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(38566) 38566\n",
      "76736 ; loss 1.09 accuracy:50.22 ;\n",
      "<class 'torch.Tensor'> tensor(41825) 41825\n",
      "83136 ; loss 1.09 accuracy:50.27 ;\n",
      "<class 'torch.Tensor'> tensor(44976) 44976\n",
      "89536 ; loss 1.09 accuracy:50.2 ;\n",
      "<class 'torch.Tensor'> tensor(48186) 48186\n",
      "95936 ; loss 1.09 accuracy:50.19 ;\n",
      "<class 'torch.Tensor'> tensor(51480) 51480\n",
      "102336 ; loss 1.09 accuracy:50.27 ;\n",
      "<class 'torch.Tensor'> tensor(54633) 54633\n",
      "108736 ; loss 1.09 accuracy:50.21 ;\n",
      "<class 'torch.Tensor'> tensor(57849) 57849\n",
      "115136 ; loss 1.09 accuracy:50.22 ;\n",
      "<class 'torch.Tensor'> tensor(61138) 61138\n",
      "121536 ; loss 1.09 accuracy:50.28 ;\n",
      "<class 'torch.Tensor'> tensor(64374) 64374\n",
      "127936 ; loss 1.09 accuracy:50.29 ;\n",
      "<class 'torch.Tensor'> tensor(67593) 67593\n",
      "134336 ; loss 1.09 accuracy:50.29 ;\n",
      "<class 'torch.Tensor'> tensor(70859) 70859\n",
      "140736 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(74171) 74171\n",
      "147136 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(77329) 77329\n",
      "153536 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(80515) 80515\n",
      "159936 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(83750) 83750\n",
      "166336 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(87037) 87037\n",
      "172736 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(90336) 90336\n",
      "179136 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(93540) 93540\n",
      "185536 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(96735) 96735\n",
      "191936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(99915) 99915\n",
      "198336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(103140) 103140\n",
      "204736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(106341) 106341\n",
      "211136 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(109588) 109588\n",
      "217536 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(112843) 112843\n",
      "223936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(116064) 116064\n",
      "230336 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(119258) 119258\n",
      "236736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(122469) 122469\n",
      "243136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(125663) 125663\n",
      "249536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(128845) 128845\n",
      "255936 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(132016) 132016\n",
      "262336 ; loss 1.09 accuracy:50.31 ;\n",
      "<class 'torch.Tensor'> tensor(135275) 135275\n",
      "268736 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(138485) 138485\n",
      "275136 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(141726) 141726\n",
      "281536 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(144924) 144924\n",
      "287936 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(148151) 148151\n",
      "294336 ; loss 1.09 accuracy:50.32 ;\n",
      "<class 'torch.Tensor'> tensor(151345) 151345\n",
      "300736 ; loss 1.09 accuracy:50.31 ;\n",
      "<class 'torch.Tensor'> tensor(154608) 154608\n",
      "307136 ; loss 1.09 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(157888) 157888\n",
      "313536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(161096) 161096\n",
      "319936 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(164376) 164376\n",
      "326336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(167587) 167587\n",
      "332736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(170762) 170762\n",
      "339136 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(173996) 173996\n",
      "345536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(177240) 177240\n",
      "351936 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(180495) 180495\n",
      "358336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(183775) 183775\n",
      "364736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(186974) 186974\n",
      "371136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(190221) 190221\n",
      "377536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(193468) 193468\n",
      "383936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(196690) 196690\n",
      "390336 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(199925) 199925\n",
      "396736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(203101) 203101\n",
      "403136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(206313) 206313\n",
      "409536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(209530) 209530\n",
      "415936 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(212745) 212745\n",
      "422336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(216005) 216005\n",
      "428736 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(219276) 219276\n",
      "435136 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(222485) 222485\n",
      "441536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(225698) 225698\n",
      "447936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(228882) 228882\n",
      "454336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(232078) 232078\n",
      "460736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(235202) 235202\n",
      "467136 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(238488) 238488\n",
      "473536 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(241658) 241658\n",
      "479936 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(244929) 244929\n",
      "486336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(248185) 248185\n",
      "492736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(251439) 251439\n",
      "499136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(254685) 254685\n",
      "505536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(257868) 257868\n",
      "511936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(261127) 261127\n",
      "518336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(264357) 264357\n",
      "524736 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(267590) 267590\n",
      "531136 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(270790) 270790\n",
      "537536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(273938) 273938\n",
      "543936 ; loss 1.09 accuracy:50.36 ;\n",
      "results : epoch 9 ; mean accuracy train : 50.36\n",
      "\n",
      "VALIDATION : Epoch 9\n",
      "togrep : results : epoch 9 ; mean accuracy valid :              50.58\n",
      "Shrinking lr by : 5. New lr = 2.9527830221693436e-05\n",
      "\n",
      "TRAINING : Epoch 10\n",
      "Learning rate : 2.9232551919476502e-05\n",
      "<class 'torch.Tensor'> tensor(3232) 3232\n",
      "6336 ; loss 1.09 accuracy:50.5 ;\n",
      "<class 'torch.Tensor'> tensor(6446) 6446\n",
      "12736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(9684) 9684\n",
      "19136 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(12840) 12840\n",
      "25536 ; loss 1.09 accuracy:50.16 ;\n",
      "<class 'torch.Tensor'> tensor(16066) 16066\n",
      "31936 ; loss 1.09 accuracy:50.21 ;\n",
      "<class 'torch.Tensor'> tensor(19306) 19306\n",
      "38336 ; loss 1.09 accuracy:50.28 ;\n",
      "<class 'torch.Tensor'> tensor(22515) 22515\n",
      "44736 ; loss 1.09 accuracy:50.26 ;\n",
      "<class 'torch.Tensor'> tensor(25746) 25746\n",
      "51136 ; loss 1.09 accuracy:50.29 ;\n",
      "<class 'torch.Tensor'> tensor(28952) 28952\n",
      "57536 ; loss 1.09 accuracy:50.26 ;\n",
      "<class 'torch.Tensor'> tensor(32198) 32198\n",
      "63936 ; loss 1.09 accuracy:50.31 ;\n",
      "<class 'torch.Tensor'> tensor(35381) 35381\n",
      "70336 ; loss 1.09 accuracy:50.26 ;\n",
      "<class 'torch.Tensor'> tensor(38577) 38577\n",
      "76736 ; loss 1.09 accuracy:50.23 ;\n",
      "<class 'torch.Tensor'> tensor(41883) 41883\n",
      "83136 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(45173) 45173\n",
      "89536 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(48458) 48458\n",
      "95936 ; loss 1.09 accuracy:50.48 ;\n",
      "<class 'torch.Tensor'> tensor(51613) 51613\n",
      "102336 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(54875) 54875\n",
      "108736 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(58059) 58059\n",
      "115136 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(61245) 61245\n",
      "121536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(64524) 64524\n",
      "127936 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(67747) 67747\n",
      "134336 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(70954) 70954\n",
      "140736 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(74240) 74240\n",
      "147136 ; loss 1.09 accuracy:50.43 ;\n",
      "<class 'torch.Tensor'> tensor(77378) 77378\n",
      "153536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(80610) 80610\n",
      "159936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(83931) 83931\n",
      "166336 ; loss 1.09 accuracy:50.44 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(87130) 87130\n",
      "172736 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(90397) 90397\n",
      "179136 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(93549) 93549\n",
      "185536 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(96802) 96802\n",
      "191936 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(99979) 99979\n",
      "198336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(103176) 103176\n",
      "204736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(106426) 106426\n",
      "211136 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(109702) 109702\n",
      "217536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(112892) 112892\n",
      "223936 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(116035) 116035\n",
      "230336 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(119214) 119214\n",
      "236736 ; loss 1.09 accuracy:50.34 ;\n",
      "<class 'torch.Tensor'> tensor(122467) 122467\n",
      "243136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(125678) 125678\n",
      "249536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(128958) 128958\n",
      "255936 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(132217) 132217\n",
      "262336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(135437) 135437\n",
      "268736 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(138704) 138704\n",
      "275136 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(141872) 141872\n",
      "281536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(145140) 145140\n",
      "287936 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(148340) 148340\n",
      "294336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(151497) 151497\n",
      "300736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(154789) 154789\n",
      "307136 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(157984) 157984\n",
      "313536 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(161220) 161220\n",
      "319936 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(164455) 164455\n",
      "326336 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(167748) 167748\n",
      "332736 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(170971) 170971\n",
      "339136 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(174232) 174232\n",
      "345536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(177540) 177540\n",
      "351936 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(180776) 180776\n",
      "358336 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(184042) 184042\n",
      "364736 ; loss 1.09 accuracy:50.45 ;\n",
      "<class 'torch.Tensor'> tensor(187206) 187206\n",
      "371136 ; loss 1.09 accuracy:50.43 ;\n",
      "<class 'torch.Tensor'> tensor(190375) 190375\n",
      "377536 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(193671) 193671\n",
      "383936 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(196901) 196901\n",
      "390336 ; loss 1.09 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(200104) 200104\n",
      "396736 ; loss 1.09 accuracy:50.43 ;\n",
      "<class 'torch.Tensor'> tensor(203308) 203308\n",
      "403136 ; loss 1.09 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(206477) 206477\n",
      "409536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(209707) 209707\n",
      "415936 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(212917) 212917\n",
      "422336 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(216115) 216115\n",
      "428736 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(219381) 219381\n",
      "435136 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(222632) 222632\n",
      "441536 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(225832) 225832\n",
      "447936 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(229078) 229078\n",
      "454336 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(232249) 232249\n",
      "460736 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(235494) 235494\n",
      "467136 ; loss 1.09 accuracy:50.41 ;\n",
      "<class 'torch.Tensor'> tensor(238672) 238672\n",
      "473536 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(241903) 241903\n",
      "479936 ; loss 1.09 accuracy:50.4 ;\n",
      "<class 'torch.Tensor'> tensor(245082) 245082\n",
      "486336 ; loss 1.09 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(248260) 248260\n",
      "492736 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(251483) 251483\n",
      "499136 ; loss 1.09 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(254678) 254678\n",
      "505536 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(257862) 257862\n",
      "511936 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(261125) 261125\n",
      "518336 ; loss 1.09 accuracy:50.37 ;\n",
      "<class 'torch.Tensor'> tensor(264288) 264288\n",
      "524736 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(267497) 267497\n",
      "531136 ; loss 1.09 accuracy:50.36 ;\n",
      "<class 'torch.Tensor'> tensor(270704) 270704\n",
      "537536 ; loss 1.09 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(273958) 273958\n",
      "543936 ; loss 1.09 accuracy:50.36 ;\n",
      "results : epoch 10 ; mean accuracy train : 50.36\n",
      "\n",
      "VALIDATION : Epoch 10\n",
      "togrep : results : epoch 10 ; mean accuracy valid :              50.58\n",
      "Shrinking lr by : 5. New lr = 5.8465103838953e-06\n",
      "\n",
      "TEST : Epoch 11\n",
      "\n",
      "VALIDATION : Epoch 1000000.0\n",
      "finalgrep : accuracy valid : 50.58\n",
      "finalgrep : accuracy test : 51.77\n"
     ]
    }
   ],
   "source": [
    "#train_nli.py LSTM\n",
    "! python train_nli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "togrep : []\n",
      "\n",
      "Namespace(batch_size=64, decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='InferSent', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=3, n_enc_layers=1, n_epochs=20, nlipath='/home/dc/InferSent/dataset/SNLI', nonlinear_fc=0, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='infersent.pickle', pool_type='max', seed=1234)\n",
      "** TRAIN DATA : Found 549367 pairs of train sentences.\n",
      "** DEV DATA : Found 9842 pairs of dev sentences.\n",
      "** TEST DATA : Found 9824 pairs of test sentences.\n",
      "Found 38957(/43479) words with glove vectors\n",
      "Vocab size : 38957\n",
      "self.inputdim:16384, self.fc_dim:512\n",
      "<class 'int'> <class 'int'>\n",
      "NLINet(\n",
      "  (encoder): InferSent(\n",
      "    (enc_lstm): LSTM(300, 2048, bidirectional=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=16384, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "TRAINING : Epoch 1\n",
      "Learning rate : 0.1\n",
      "<class 'torch.Tensor'> tensor(2128) 2128\n",
      "6336 ; loss 1.1 accuracy:33.25 ;\n",
      "<class 'torch.Tensor'> tensor(4267) 4267\n",
      "12736 ; loss 1.1 accuracy:33.34 ;\n",
      "<class 'torch.Tensor'> tensor(6449) 6449\n",
      "19136 ; loss 1.1 accuracy:33.59 ;\n",
      "<class 'torch.Tensor'> tensor(8578) 8578\n",
      "25536 ; loss 1.1 accuracy:33.51 ;\n",
      "<class 'torch.Tensor'> tensor(10807) 10807\n",
      "31936 ; loss 1.1 accuracy:33.77 ;\n",
      "<class 'torch.Tensor'> tensor(12943) 12943\n",
      "38336 ; loss 1.1 accuracy:33.71 ;\n",
      "<class 'torch.Tensor'> tensor(15143) 15143\n",
      "44736 ; loss 1.1 accuracy:33.8 ;\n",
      "<class 'torch.Tensor'> tensor(17330) 17330\n",
      "51136 ; loss 1.1 accuracy:33.85 ;\n",
      "<class 'torch.Tensor'> tensor(19503) 19503\n",
      "57536 ; loss 1.1 accuracy:33.86 ;\n",
      "<class 'torch.Tensor'> tensor(21620) 21620\n",
      "63936 ; loss 1.1 accuracy:33.78 ;\n",
      "<class 'torch.Tensor'> tensor(23764) 23764\n",
      "70336 ; loss 1.1 accuracy:33.76 ;\n",
      "<class 'torch.Tensor'> tensor(25949) 25949\n",
      "76736 ; loss 1.1 accuracy:33.79 ;\n",
      "<class 'torch.Tensor'> tensor(28096) 28096\n",
      "83136 ; loss 1.1 accuracy:33.77 ;\n",
      "<class 'torch.Tensor'> tensor(30411) 30411\n",
      "89536 ; loss 1.1 accuracy:33.94 ;\n",
      "<class 'torch.Tensor'> tensor(32665) 32665\n",
      "95936 ; loss 1.1 accuracy:34.03 ;\n",
      "<class 'torch.Tensor'> tensor(34849) 34849\n",
      "102336 ; loss 1.1 accuracy:34.03 ;\n",
      "<class 'torch.Tensor'> tensor(37001) 37001\n",
      "108736 ; loss 1.1 accuracy:34.01 ;\n",
      "<class 'torch.Tensor'> tensor(39162) 39162\n",
      "115136 ; loss 1.1 accuracy:33.99 ;\n",
      "<class 'torch.Tensor'> tensor(41274) 41274\n",
      "121536 ; loss 1.1 accuracy:33.94 ;\n",
      "<class 'torch.Tensor'> tensor(43602) 43602\n",
      "127936 ; loss 1.1 accuracy:34.06 ;\n",
      "<class 'torch.Tensor'> tensor(46113) 46113\n",
      "134336 ; loss 1.1 accuracy:34.31 ;\n",
      "<class 'torch.Tensor'> tensor(48473) 48473\n",
      "140736 ; loss 1.1 accuracy:34.43 ;\n",
      "<class 'torch.Tensor'> tensor(50885) 50885\n",
      "147136 ; loss 1.1 accuracy:34.57 ;\n",
      "<class 'torch.Tensor'> tensor(53362) 53362\n",
      "153536 ; loss 1.1 accuracy:34.74 ;\n",
      "<class 'torch.Tensor'> tensor(55791) 55791\n",
      "159936 ; loss 1.1 accuracy:34.87 ;\n",
      "<class 'torch.Tensor'> tensor(58274) 58274\n",
      "166336 ; loss 1.1 accuracy:35.02 ;\n",
      "<class 'torch.Tensor'> tensor(60747) 60747\n",
      "172736 ; loss 1.1 accuracy:35.15 ;\n",
      "<class 'torch.Tensor'> tensor(63240) 63240\n",
      "179136 ; loss 1.1 accuracy:35.29 ;\n",
      "<class 'torch.Tensor'> tensor(65765) 65765\n",
      "185536 ; loss 1.1 accuracy:35.43 ;\n",
      "<class 'torch.Tensor'> tensor(68177) 68177\n",
      "191936 ; loss 1.1 accuracy:35.51 ;\n",
      "<class 'torch.Tensor'> tensor(70575) 70575\n",
      "198336 ; loss 1.1 accuracy:35.57 ;\n",
      "<class 'torch.Tensor'> tensor(73221) 73221\n",
      "204736 ; loss 1.1 accuracy:35.75 ;\n",
      "<class 'torch.Tensor'> tensor(76069) 76069\n",
      "211136 ; loss 1.1 accuracy:36.02 ;\n",
      "<class 'torch.Tensor'> tensor(78921) 78921\n",
      "217536 ; loss 1.1 accuracy:36.27 ;\n",
      "<class 'torch.Tensor'> tensor(81694) 81694\n",
      "223936 ; loss 1.1 accuracy:36.47 ;\n",
      "<class 'torch.Tensor'> tensor(84516) 84516\n",
      "230336 ; loss 1.1 accuracy:36.68 ;\n",
      "<class 'torch.Tensor'> tensor(87569) 87569\n",
      "236736 ; loss 1.1 accuracy:36.98 ;\n",
      "<class 'torch.Tensor'> tensor(90631) 90631\n",
      "243136 ; loss 1.1 accuracy:37.27 ;\n",
      "<class 'torch.Tensor'> tensor(93188) 93188\n",
      "249536 ; loss 1.1 accuracy:37.33 ;\n",
      "<class 'torch.Tensor'> tensor(95786) 95786\n",
      "255936 ; loss 1.1 accuracy:37.42 ;\n",
      "<class 'torch.Tensor'> tensor(98503) 98503\n",
      "262336 ; loss 1.1 accuracy:37.54 ;\n",
      "<class 'torch.Tensor'> tensor(101414) 101414\n",
      "268736 ; loss 1.1 accuracy:37.73 ;\n",
      "<class 'torch.Tensor'> tensor(104336) 104336\n",
      "275136 ; loss 1.1 accuracy:37.91 ;\n",
      "<class 'torch.Tensor'> tensor(107108) 107108\n",
      "281536 ; loss 1.1 accuracy:38.04 ;\n",
      "<class 'torch.Tensor'> tensor(109833) 109833\n",
      "287936 ; loss 1.1 accuracy:38.14 ;\n",
      "<class 'torch.Tensor'> tensor(112374) 112374\n",
      "294336 ; loss 1.1 accuracy:38.17 ;\n",
      "<class 'torch.Tensor'> tensor(114807) 114807\n",
      "300736 ; loss 1.1 accuracy:38.17 ;\n",
      "<class 'torch.Tensor'> tensor(117090) 117090\n",
      "307136 ; loss 1.1 accuracy:38.12 ;\n",
      "<class 'torch.Tensor'> tensor(119295) 119295\n",
      "313536 ; loss 1.1 accuracy:38.04 ;\n",
      "<class 'torch.Tensor'> tensor(121646) 121646\n",
      "319936 ; loss 1.1 accuracy:38.01 ;\n",
      "<class 'torch.Tensor'> tensor(124127) 124127\n",
      "326336 ; loss 1.1 accuracy:38.03 ;\n",
      "<class 'torch.Tensor'> tensor(126681) 126681\n",
      "332736 ; loss 1.1 accuracy:38.07 ;\n",
      "<class 'torch.Tensor'> tensor(129251) 129251\n",
      "339136 ; loss 1.1 accuracy:38.1 ;\n",
      "<class 'torch.Tensor'> tensor(131608) 131608\n",
      "345536 ; loss 1.1 accuracy:38.08 ;\n",
      "<class 'torch.Tensor'> tensor(134042) 134042\n",
      "351936 ; loss 1.1 accuracy:38.08 ;\n",
      "<class 'torch.Tensor'> tensor(136628) 136628\n",
      "358336 ; loss 1.1 accuracy:38.12 ;\n",
      "<class 'torch.Tensor'> tensor(139232) 139232\n",
      "364736 ; loss 1.1 accuracy:38.17 ;\n",
      "<class 'torch.Tensor'> tensor(141658) 141658\n",
      "371136 ; loss 1.1 accuracy:38.16 ;\n",
      "<class 'torch.Tensor'> tensor(144076) 144076\n",
      "377536 ; loss 1.1 accuracy:38.16 ;\n",
      "<class 'torch.Tensor'> tensor(146393) 146393\n",
      "383936 ; loss 1.1 accuracy:38.12 ;\n",
      "<class 'torch.Tensor'> tensor(148945) 148945\n",
      "390336 ; loss 1.1 accuracy:38.15 ;\n",
      "<class 'torch.Tensor'> tensor(151592) 151592\n",
      "396736 ; loss 1.1 accuracy:38.2 ;\n",
      "<class 'torch.Tensor'> tensor(154559) 154559\n",
      "403136 ; loss 1.1 accuracy:38.33 ;\n",
      "<class 'torch.Tensor'> tensor(157706) 157706\n",
      "409536 ; loss 1.1 accuracy:38.5 ;\n",
      "<class 'torch.Tensor'> tensor(160944) 160944\n",
      "415936 ; loss 1.1 accuracy:38.69 ;\n",
      "<class 'torch.Tensor'> tensor(163828) 163828\n",
      "422336 ; loss 1.1 accuracy:38.79 ;\n",
      "<class 'torch.Tensor'> tensor(166540) 166540\n",
      "428736 ; loss 1.1 accuracy:38.84 ;\n",
      "<class 'torch.Tensor'> tensor(169321) 169321\n",
      "435136 ; loss 1.1 accuracy:38.91 ;\n",
      "<class 'torch.Tensor'> tensor(172103) 172103\n",
      "441536 ; loss 1.1 accuracy:38.97 ;\n",
      "<class 'torch.Tensor'> tensor(174837) 174837\n",
      "447936 ; loss 1.1 accuracy:39.03 ;\n",
      "<class 'torch.Tensor'> tensor(177597) 177597\n",
      "454336 ; loss 1.1 accuracy:39.08 ;\n",
      "<class 'torch.Tensor'> tensor(180412) 180412\n",
      "460736 ; loss 1.1 accuracy:39.15 ;\n",
      "<class 'torch.Tensor'> tensor(183392) 183392\n",
      "467136 ; loss 1.1 accuracy:39.25 ;\n",
      "<class 'torch.Tensor'> tensor(186292) 186292\n",
      "473536 ; loss 1.1 accuracy:39.34 ;\n",
      "<class 'torch.Tensor'> tensor(189244) 189244\n",
      "479936 ; loss 1.1 accuracy:39.43 ;\n",
      "<class 'torch.Tensor'> tensor(192337) 192337\n",
      "486336 ; loss 1.1 accuracy:39.54 ;\n",
      "<class 'torch.Tensor'> tensor(195262) 195262\n",
      "492736 ; loss 1.1 accuracy:39.62 ;\n",
      "<class 'torch.Tensor'> tensor(198325) 198325\n",
      "499136 ; loss 1.09 accuracy:39.73 ;\n",
      "<class 'torch.Tensor'> tensor(201443) 201443\n",
      "505536 ; loss 1.1 accuracy:39.84 ;\n",
      "<class 'torch.Tensor'> tensor(204490) 204490\n",
      "511936 ; loss 1.1 accuracy:39.94 ;\n",
      "<class 'torch.Tensor'> tensor(207432) 207432\n",
      "518336 ; loss 1.09 accuracy:40.01 ;\n",
      "<class 'torch.Tensor'> tensor(210472) 210472\n",
      "524736 ; loss 1.1 accuracy:40.11 ;\n",
      "<class 'torch.Tensor'> tensor(213616) 213616\n",
      "531136 ; loss 1.09 accuracy:40.21 ;\n",
      "<class 'torch.Tensor'> tensor(216633) 216633\n",
      "537536 ; loss 1.1 accuracy:40.3 ;\n",
      "<class 'torch.Tensor'> tensor(219641) 219641\n",
      "543936 ; loss 1.09 accuracy:40.38 ;\n",
      "results : epoch 1 ; mean accuracy train : 40.44\n",
      "\n",
      "VALIDATION : Epoch 1\n",
      "togrep : results : epoch 1 ; mean accuracy valid :              48.02\n",
      "saving model at epoch 1\n",
      "\n",
      "TRAINING : Epoch 2\n",
      "Learning rate : 0.099\n",
      "<class 'torch.Tensor'> tensor(3062) 3062\n",
      "6336 ; loss 1.09 accuracy:47.84 ;\n",
      "<class 'torch.Tensor'> tensor(6182) 6182\n",
      "12736 ; loss 1.09 accuracy:48.3 ;\n",
      "<class 'torch.Tensor'> tensor(9210) 9210\n",
      "19136 ; loss 1.09 accuracy:47.97 ;\n",
      "<class 'torch.Tensor'> tensor(12111) 12111\n",
      "25536 ; loss 1.09 accuracy:47.31 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(15325) 15325\n",
      "31936 ; loss 1.09 accuracy:47.89 ;\n",
      "<class 'torch.Tensor'> tensor(18545) 18545\n",
      "38336 ; loss 1.09 accuracy:48.29 ;\n",
      "<class 'torch.Tensor'> tensor(21858) 21858\n",
      "44736 ; loss 1.09 accuracy:48.79 ;\n",
      "<class 'torch.Tensor'> tensor(25116) 25116\n",
      "51136 ; loss 1.09 accuracy:49.05 ;\n",
      "<class 'torch.Tensor'> tensor(28424) 28424\n",
      "57536 ; loss 1.09 accuracy:49.35 ;\n",
      "<class 'torch.Tensor'> tensor(31699) 31699\n",
      "63936 ; loss 1.09 accuracy:49.53 ;\n",
      "<class 'torch.Tensor'> tensor(34743) 34743\n",
      "70336 ; loss 1.09 accuracy:49.35 ;\n",
      "<class 'torch.Tensor'> tensor(37406) 37406\n",
      "76736 ; loss 1.09 accuracy:48.71 ;\n",
      "<class 'torch.Tensor'> tensor(39982) 39982\n",
      "83136 ; loss 1.09 accuracy:48.06 ;\n",
      "<class 'torch.Tensor'> tensor(42810) 42810\n",
      "89536 ; loss 1.09 accuracy:47.78 ;\n",
      "<class 'torch.Tensor'> tensor(45709) 45709\n",
      "95936 ; loss 1.09 accuracy:47.61 ;\n",
      "<class 'torch.Tensor'> tensor(48689) 48689\n",
      "102336 ; loss 1.09 accuracy:47.55 ;\n",
      "<class 'torch.Tensor'> tensor(51906) 51906\n",
      "108736 ; loss 1.09 accuracy:47.71 ;\n",
      "<class 'torch.Tensor'> tensor(55055) 55055\n",
      "115136 ; loss 1.09 accuracy:47.79 ;\n",
      "<class 'torch.Tensor'> tensor(58307) 58307\n",
      "121536 ; loss 1.09 accuracy:47.95 ;\n",
      "<class 'torch.Tensor'> tensor(61421) 61421\n",
      "127936 ; loss 1.09 accuracy:47.99 ;\n",
      "<class 'torch.Tensor'> tensor(64736) 64736\n",
      "134336 ; loss 1.09 accuracy:48.17 ;\n",
      "<class 'torch.Tensor'> tensor(67966) 67966\n",
      "140736 ; loss 1.09 accuracy:48.27 ;\n",
      "<class 'torch.Tensor'> tensor(71117) 71117\n",
      "147136 ; loss 1.09 accuracy:48.31 ;\n",
      "<class 'torch.Tensor'> tensor(74079) 74079\n",
      "153536 ; loss 1.09 accuracy:48.23 ;\n",
      "<class 'torch.Tensor'> tensor(77217) 77217\n",
      "159936 ; loss 1.09 accuracy:48.26 ;\n",
      "<class 'torch.Tensor'> tensor(80336) 80336\n",
      "166336 ; loss 1.09 accuracy:48.28 ;\n",
      "<class 'torch.Tensor'> tensor(83548) 83548\n",
      "172736 ; loss 1.09 accuracy:48.35 ;\n",
      "<class 'torch.Tensor'> tensor(86784) 86784\n",
      "179136 ; loss 1.09 accuracy:48.43 ;\n",
      "<class 'torch.Tensor'> tensor(90083) 90083\n",
      "185536 ; loss 1.09 accuracy:48.54 ;\n",
      "<class 'torch.Tensor'> tensor(93337) 93337\n",
      "191936 ; loss 1.09 accuracy:48.61 ;\n",
      "<class 'torch.Tensor'> tensor(96662) 96662\n",
      "198336 ; loss 1.09 accuracy:48.72 ;\n",
      "<class 'torch.Tensor'> tensor(99995) 99995\n",
      "204736 ; loss 1.09 accuracy:48.83 ;\n",
      "<class 'torch.Tensor'> tensor(103305) 103305\n",
      "211136 ; loss 1.09 accuracy:48.91 ;\n",
      "<class 'torch.Tensor'> tensor(106505) 106505\n",
      "217536 ; loss 1.09 accuracy:48.95 ;\n",
      "<class 'torch.Tensor'> tensor(109710) 109710\n",
      "223936 ; loss 1.09 accuracy:48.98 ;\n",
      "<class 'torch.Tensor'> tensor(112832) 112832\n",
      "230336 ; loss 1.09 accuracy:48.97 ;\n",
      "<class 'torch.Tensor'> tensor(115983) 115983\n",
      "236736 ; loss 1.09 accuracy:48.98 ;\n",
      "<class 'torch.Tensor'> tensor(118958) 118958\n",
      "243136 ; loss 1.09 accuracy:48.91 ;\n",
      "<class 'torch.Tensor'> tensor(122018) 122018\n",
      "249536 ; loss 1.09 accuracy:48.89 ;\n",
      "<class 'torch.Tensor'> tensor(125059) 125059\n",
      "255936 ; loss 1.09 accuracy:48.85 ;\n",
      "<class 'torch.Tensor'> tensor(128006) 128006\n",
      "262336 ; loss 1.09 accuracy:48.78 ;\n",
      "<class 'torch.Tensor'> tensor(131035) 131035\n",
      "268736 ; loss 1.09 accuracy:48.75 ;\n",
      "<class 'torch.Tensor'> tensor(134128) 134128\n",
      "275136 ; loss 1.09 accuracy:48.74 ;\n",
      "<class 'torch.Tensor'> tensor(137249) 137249\n",
      "281536 ; loss 1.09 accuracy:48.74 ;\n",
      "<class 'torch.Tensor'> tensor(140402) 140402\n",
      "287936 ; loss 1.09 accuracy:48.75 ;\n",
      "<class 'torch.Tensor'> tensor(143585) 143585\n",
      "294336 ; loss 1.09 accuracy:48.77 ;\n",
      "<class 'torch.Tensor'> tensor(146817) 146817\n",
      "300736 ; loss 1.09 accuracy:48.81 ;\n",
      "<class 'torch.Tensor'> tensor(150001) 150001\n",
      "307136 ; loss 1.09 accuracy:48.83 ;\n",
      "<class 'torch.Tensor'> tensor(153064) 153064\n",
      "313536 ; loss 1.09 accuracy:48.81 ;\n",
      "<class 'torch.Tensor'> tensor(156151) 156151\n",
      "319936 ; loss 1.09 accuracy:48.8 ;\n",
      "<class 'torch.Tensor'> tensor(159286) 159286\n",
      "326336 ; loss 1.09 accuracy:48.8 ;\n",
      "<class 'torch.Tensor'> tensor(162415) 162415\n",
      "332736 ; loss 1.09 accuracy:48.8 ;\n",
      "<class 'torch.Tensor'> tensor(165601) 165601\n",
      "339136 ; loss 1.09 accuracy:48.82 ;\n",
      "<class 'torch.Tensor'> tensor(168699) 168699\n",
      "345536 ; loss 1.09 accuracy:48.81 ;\n",
      "<class 'torch.Tensor'> tensor(171843) 171843\n",
      "351936 ; loss 1.09 accuracy:48.82 ;\n",
      "<class 'torch.Tensor'> tensor(175096) 175096\n",
      "358336 ; loss 1.09 accuracy:48.85 ;\n",
      "<class 'torch.Tensor'> tensor(178347) 178347\n",
      "364736 ; loss 1.09 accuracy:48.89 ;\n",
      "<class 'torch.Tensor'> tensor(181588) 181588\n",
      "371136 ; loss 1.09 accuracy:48.92 ;\n",
      "<class 'torch.Tensor'> tensor(184825) 184825\n",
      "377536 ; loss 1.09 accuracy:48.95 ;\n",
      "<class 'torch.Tensor'> tensor(187892) 187892\n",
      "383936 ; loss 1.09 accuracy:48.93 ;\n",
      "<class 'torch.Tensor'> tensor(190954) 190954\n",
      "390336 ; loss 1.09 accuracy:48.91 ;\n",
      "<class 'torch.Tensor'> tensor(194006) 194006\n",
      "396736 ; loss 1.09 accuracy:48.89 ;\n",
      "<class 'torch.Tensor'> tensor(197023) 197023\n",
      "403136 ; loss 1.09 accuracy:48.86 ;\n",
      "<class 'torch.Tensor'> tensor(200035) 200035\n",
      "409536 ; loss 1.09 accuracy:48.84 ;\n",
      "<class 'torch.Tensor'> tensor(203078) 203078\n",
      "415936 ; loss 1.09 accuracy:48.82 ;\n",
      "<class 'torch.Tensor'> tensor(206117) 206117\n",
      "422336 ; loss 1.09 accuracy:48.8 ;\n",
      "<class 'torch.Tensor'> tensor(209244) 209244\n",
      "428736 ; loss 1.09 accuracy:48.8 ;\n",
      "<class 'torch.Tensor'> tensor(212330) 212330\n",
      "435136 ; loss 1.09 accuracy:48.79 ;\n",
      "<class 'torch.Tensor'> tensor(215265) 215265\n",
      "441536 ; loss 1.09 accuracy:48.75 ;\n",
      "<class 'torch.Tensor'> tensor(218098) 218098\n",
      "447936 ; loss 1.09 accuracy:48.68 ;\n",
      "<class 'torch.Tensor'> tensor(220896) 220896\n",
      "454336 ; loss 1.09 accuracy:48.61 ;\n",
      "<class 'torch.Tensor'> tensor(223861) 223861\n",
      "460736 ; loss 1.09 accuracy:48.58 ;\n",
      "<class 'torch.Tensor'> tensor(226844) 226844\n",
      "467136 ; loss 1.09 accuracy:48.55 ;\n",
      "<class 'torch.Tensor'> tensor(229900) 229900\n",
      "473536 ; loss 1.09 accuracy:48.54 ;\n",
      "<class 'torch.Tensor'> tensor(233048) 233048\n",
      "479936 ; loss 1.09 accuracy:48.55 ;\n",
      "<class 'torch.Tensor'> tensor(236235) 236235\n",
      "486336 ; loss 1.09 accuracy:48.57 ;\n",
      "<class 'torch.Tensor'> tensor(239496) 239496\n",
      "492736 ; loss 1.09 accuracy:48.6 ;\n",
      "<class 'torch.Tensor'> tensor(242784) 242784\n",
      "499136 ; loss 1.09 accuracy:48.63 ;\n",
      "<class 'torch.Tensor'> tensor(246062) 246062\n",
      "505536 ; loss 1.09 accuracy:48.67 ;\n",
      "<class 'torch.Tensor'> tensor(249193) 249193\n",
      "511936 ; loss 1.09 accuracy:48.67 ;\n",
      "<class 'torch.Tensor'> tensor(252320) 252320\n",
      "518336 ; loss 1.09 accuracy:48.67 ;\n",
      "<class 'torch.Tensor'> tensor(255499) 255499\n",
      "524736 ; loss 1.09 accuracy:48.69 ;\n",
      "<class 'torch.Tensor'> tensor(258676) 258676\n",
      "531136 ; loss 1.09 accuracy:48.7 ;\n",
      "<class 'torch.Tensor'> tensor(261788) 261788\n",
      "537536 ; loss 1.09 accuracy:48.7 ;\n",
      "<class 'torch.Tensor'> tensor(264912) 264912\n",
      "543936 ; loss 1.09 accuracy:48.7 ;\n",
      "results : epoch 2 ; mean accuracy train : 48.7\n",
      "\n",
      "VALIDATION : Epoch 2\n",
      "togrep : results : epoch 2 ; mean accuracy valid :              49.88\n",
      "saving model at epoch 2\n",
      "\n",
      "TRAINING : Epoch 3\n",
      "Learning rate : 0.09801\n",
      "<class 'torch.Tensor'> tensor(3173) 3173\n",
      "6336 ; loss 1.09 accuracy:49.58 ;\n",
      "<class 'torch.Tensor'> tensor(6310) 6310\n",
      "12736 ; loss 1.09 accuracy:49.3 ;\n",
      "<class 'torch.Tensor'> tensor(9487) 9487\n",
      "19136 ; loss 1.09 accuracy:49.41 ;\n",
      "<class 'torch.Tensor'> tensor(12662) 12662\n",
      "25536 ; loss 1.09 accuracy:49.46 ;\n",
      "<class 'torch.Tensor'> tensor(15838) 15838\n",
      "31936 ; loss 1.09 accuracy:49.49 ;\n",
      "<class 'torch.Tensor'> tensor(19009) 19009\n",
      "38336 ; loss 1.09 accuracy:49.5 ;\n",
      "<class 'torch.Tensor'> tensor(22310) 22310\n",
      "44736 ; loss 1.09 accuracy:49.8 ;\n",
      "<class 'torch.Tensor'> tensor(25576) 25576\n",
      "51136 ; loss 1.09 accuracy:49.95 ;\n",
      "<class 'torch.Tensor'> tensor(28822) 28822\n",
      "57536 ; loss 1.08 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(32156) 32156\n",
      "63936 ; loss 1.08 accuracy:50.24 ;\n",
      "<class 'torch.Tensor'> tensor(35409) 35409\n",
      "70336 ; loss 1.08 accuracy:50.3 ;\n",
      "<class 'torch.Tensor'> tensor(38724) 38724\n",
      "76736 ; loss 1.08 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(42019) 42019\n",
      "83136 ; loss 1.08 accuracy:50.5 ;\n",
      "<class 'torch.Tensor'> tensor(45293) 45293\n",
      "89536 ; loss 1.08 accuracy:50.55 ;\n",
      "<class 'torch.Tensor'> tensor(48430) 48430\n",
      "95936 ; loss 1.08 accuracy:50.45 ;\n",
      "<class 'torch.Tensor'> tensor(51652) 51652\n",
      "102336 ; loss 1.08 accuracy:50.44 ;\n",
      "<class 'torch.Tensor'> tensor(54756) 54756\n",
      "108736 ; loss 1.08 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(57907) 57907\n",
      "115136 ; loss 1.08 accuracy:50.27 ;\n",
      "<class 'torch.Tensor'> tensor(61114) 61114\n",
      "121536 ; loss 1.08 accuracy:50.26 ;\n",
      "<class 'torch.Tensor'> tensor(64186) 64186\n",
      "127936 ; loss 1.08 accuracy:50.15 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(67305) 67305\n",
      "134336 ; loss 1.08 accuracy:50.08 ;\n",
      "<class 'torch.Tensor'> tensor(70418) 70418\n",
      "140736 ; loss 1.08 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(73589) 73589\n",
      "147136 ; loss 1.08 accuracy:49.99 ;\n",
      "<class 'torch.Tensor'> tensor(76740) 76740\n",
      "153536 ; loss 1.08 accuracy:49.96 ;\n",
      "<class 'torch.Tensor'> tensor(79883) 79883\n",
      "159936 ; loss 1.08 accuracy:49.93 ;\n",
      "<class 'torch.Tensor'> tensor(82989) 82989\n",
      "166336 ; loss 1.08 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(86083) 86083\n",
      "172736 ; loss 1.08 accuracy:49.82 ;\n",
      "<class 'torch.Tensor'> tensor(89154) 89154\n",
      "179136 ; loss 1.08 accuracy:49.75 ;\n",
      "<class 'torch.Tensor'> tensor(92193) 92193\n",
      "185536 ; loss 1.08 accuracy:49.67 ;\n",
      "<class 'torch.Tensor'> tensor(95217) 95217\n",
      "191936 ; loss 1.08 accuracy:49.59 ;\n",
      "<class 'torch.Tensor'> tensor(98279) 98279\n",
      "198336 ; loss 1.08 accuracy:49.54 ;\n",
      "<class 'torch.Tensor'> tensor(101504) 101504\n",
      "204736 ; loss 1.08 accuracy:49.56 ;\n",
      "<class 'torch.Tensor'> tensor(104683) 104683\n",
      "211136 ; loss 1.08 accuracy:49.57 ;\n",
      "<class 'torch.Tensor'> tensor(107962) 107962\n",
      "217536 ; loss 1.08 accuracy:49.61 ;\n",
      "<class 'torch.Tensor'> tensor(111208) 111208\n",
      "223936 ; loss 1.08 accuracy:49.65 ;\n",
      "<class 'torch.Tensor'> tensor(114377) 114377\n",
      "230336 ; loss 1.08 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(117577) 117577\n",
      "236736 ; loss 1.08 accuracy:49.65 ;\n",
      "<class 'torch.Tensor'> tensor(120692) 120692\n",
      "243136 ; loss 1.08 accuracy:49.63 ;\n",
      "<class 'torch.Tensor'> tensor(123857) 123857\n",
      "249536 ; loss 1.08 accuracy:49.62 ;\n",
      "<class 'torch.Tensor'> tensor(127140) 127140\n",
      "255936 ; loss 1.08 accuracy:49.66 ;\n",
      "<class 'torch.Tensor'> tensor(130251) 130251\n",
      "262336 ; loss 1.08 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(133455) 133455\n",
      "268736 ; loss 1.08 accuracy:49.65 ;\n",
      "<class 'torch.Tensor'> tensor(136615) 136615\n",
      "275136 ; loss 1.08 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(139780) 139780\n",
      "281536 ; loss 1.08 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(142895) 142895\n",
      "287936 ; loss 1.08 accuracy:49.62 ;\n",
      "<class 'torch.Tensor'> tensor(146093) 146093\n",
      "294336 ; loss 1.08 accuracy:49.62 ;\n",
      "<class 'torch.Tensor'> tensor(149312) 149312\n",
      "300736 ; loss 1.07 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(152453) 152453\n",
      "307136 ; loss 1.07 accuracy:49.63 ;\n",
      "<class 'torch.Tensor'> tensor(155448) 155448\n",
      "313536 ; loss 1.07 accuracy:49.57 ;\n",
      "<class 'torch.Tensor'> tensor(158537) 158537\n",
      "319936 ; loss 1.07 accuracy:49.54 ;\n",
      "<class 'torch.Tensor'> tensor(161688) 161688\n",
      "326336 ; loss 1.07 accuracy:49.54 ;\n",
      "<class 'torch.Tensor'> tensor(164873) 164873\n",
      "332736 ; loss 1.07 accuracy:49.54 ;\n",
      "<class 'torch.Tensor'> tensor(167945) 167945\n",
      "339136 ; loss 1.07 accuracy:49.51 ;\n",
      "<class 'torch.Tensor'> tensor(171026) 171026\n",
      "345536 ; loss 1.07 accuracy:49.49 ;\n",
      "<class 'torch.Tensor'> tensor(174204) 174204\n",
      "351936 ; loss 1.07 accuracy:49.49 ;\n",
      "<class 'torch.Tensor'> tensor(177309) 177309\n",
      "358336 ; loss 1.07 accuracy:49.47 ;\n",
      "<class 'torch.Tensor'> tensor(180464) 180464\n",
      "364736 ; loss 1.07 accuracy:49.47 ;\n",
      "<class 'torch.Tensor'> tensor(183524) 183524\n",
      "371136 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(186561) 186561\n",
      "377536 ; loss 1.07 accuracy:49.41 ;\n",
      "<class 'torch.Tensor'> tensor(189762) 189762\n",
      "383936 ; loss 1.07 accuracy:49.42 ;\n",
      "<class 'torch.Tensor'> tensor(192917) 192917\n",
      "390336 ; loss 1.07 accuracy:49.42 ;\n",
      "<class 'torch.Tensor'> tensor(196087) 196087\n",
      "396736 ; loss 1.07 accuracy:49.42 ;\n",
      "<class 'torch.Tensor'> tensor(199333) 199333\n",
      "403136 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(202526) 202526\n",
      "409536 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(205701) 205701\n",
      "415936 ; loss 1.07 accuracy:49.45 ;\n",
      "<class 'torch.Tensor'> tensor(208822) 208822\n",
      "422336 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(212004) 212004\n",
      "428736 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(215171) 215171\n",
      "435136 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(218319) 218319\n",
      "441536 ; loss 1.07 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(221388) 221388\n",
      "447936 ; loss 1.07 accuracy:49.42 ;\n",
      "<class 'torch.Tensor'> tensor(224520) 224520\n",
      "454336 ; loss 1.07 accuracy:49.41 ;\n",
      "<class 'torch.Tensor'> tensor(227792) 227792\n",
      "460736 ; loss 1.06 accuracy:49.43 ;\n",
      "<class 'torch.Tensor'> tensor(231013) 231013\n",
      "467136 ; loss 1.06 accuracy:49.45 ;\n",
      "<class 'torch.Tensor'> tensor(234179) 234179\n",
      "473536 ; loss 1.07 accuracy:49.45 ;\n",
      "<class 'torch.Tensor'> tensor(237370) 237370\n",
      "479936 ; loss 1.06 accuracy:49.45 ;\n",
      "<class 'torch.Tensor'> tensor(240480) 240480\n",
      "486336 ; loss 1.06 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(243671) 243671\n",
      "492736 ; loss 1.06 accuracy:49.45 ;\n",
      "<class 'torch.Tensor'> tensor(246794) 246794\n",
      "499136 ; loss 1.06 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(249955) 249955\n",
      "505536 ; loss 1.06 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(253092) 253092\n",
      "511936 ; loss 1.06 accuracy:49.43 ;\n",
      "<class 'torch.Tensor'> tensor(256233) 256233\n",
      "518336 ; loss 1.06 accuracy:49.43 ;\n",
      "<class 'torch.Tensor'> tensor(259386) 259386\n",
      "524736 ; loss 1.06 accuracy:49.43 ;\n",
      "<class 'torch.Tensor'> tensor(262600) 262600\n",
      "531136 ; loss 1.05 accuracy:49.44 ;\n",
      "<class 'torch.Tensor'> tensor(265723) 265723\n",
      "537536 ; loss 1.06 accuracy:49.43 ;\n",
      "<class 'torch.Tensor'> tensor(268873) 268873\n",
      "543936 ; loss 1.06 accuracy:49.43 ;\n",
      "results : epoch 3 ; mean accuracy train : 49.43\n",
      "\n",
      "VALIDATION : Epoch 3\n",
      "togrep : results : epoch 3 ; mean accuracy valid :              50.15\n",
      "saving model at epoch 3\n",
      "\n",
      "TRAINING : Epoch 4\n",
      "Learning rate : 0.0970299\n",
      "<class 'torch.Tensor'> tensor(3196) 3196\n",
      "6336 ; loss 1.06 accuracy:49.94 ;\n",
      "<class 'torch.Tensor'> tensor(6304) 6304\n",
      "12736 ; loss 1.06 accuracy:49.25 ;\n",
      "<class 'torch.Tensor'> tensor(9517) 9517\n",
      "19136 ; loss 1.05 accuracy:49.57 ;\n",
      "<class 'torch.Tensor'> tensor(12687) 12687\n",
      "25536 ; loss 1.05 accuracy:49.56 ;\n",
      "<class 'torch.Tensor'> tensor(15801) 15801\n",
      "31936 ; loss 1.06 accuracy:49.38 ;\n",
      "<class 'torch.Tensor'> tensor(18963) 18963\n",
      "38336 ; loss 1.05 accuracy:49.38 ;\n",
      "<class 'torch.Tensor'> tensor(22160) 22160\n",
      "44736 ; loss 1.05 accuracy:49.46 ;\n",
      "<class 'torch.Tensor'> tensor(25353) 25353\n",
      "51136 ; loss 1.05 accuracy:49.52 ;\n",
      "<class 'torch.Tensor'> tensor(28591) 28591\n",
      "57536 ; loss 1.05 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(31837) 31837\n",
      "63936 ; loss 1.05 accuracy:49.75 ;\n",
      "<class 'torch.Tensor'> tensor(34998) 34998\n",
      "70336 ; loss 1.05 accuracy:49.71 ;\n",
      "<class 'torch.Tensor'> tensor(38233) 38233\n",
      "76736 ; loss 1.05 accuracy:49.78 ;\n",
      "<class 'torch.Tensor'> tensor(41384) 41384\n",
      "83136 ; loss 1.05 accuracy:49.74 ;\n",
      "<class 'torch.Tensor'> tensor(44479) 44479\n",
      "89536 ; loss 1.05 accuracy:49.64 ;\n",
      "<class 'torch.Tensor'> tensor(47668) 47668\n",
      "95936 ; loss 1.05 accuracy:49.65 ;\n",
      "<class 'torch.Tensor'> tensor(50957) 50957\n",
      "102336 ; loss 1.05 accuracy:49.76 ;\n",
      "<class 'torch.Tensor'> tensor(54174) 54174\n",
      "108736 ; loss 1.04 accuracy:49.79 ;\n",
      "<class 'torch.Tensor'> tensor(57361) 57361\n",
      "115136 ; loss 1.04 accuracy:49.79 ;\n",
      "<class 'torch.Tensor'> tensor(60483) 60483\n",
      "121536 ; loss 1.05 accuracy:49.74 ;\n",
      "<class 'torch.Tensor'> tensor(63656) 63656\n",
      "127936 ; loss 1.04 accuracy:49.73 ;\n",
      "<class 'torch.Tensor'> tensor(66874) 66874\n",
      "134336 ; loss 1.04 accuracy:49.76 ;\n",
      "<class 'torch.Tensor'> tensor(70092) 70092\n",
      "140736 ; loss 1.04 accuracy:49.78 ;\n",
      "<class 'torch.Tensor'> tensor(73275) 73275\n",
      "147136 ; loss 1.05 accuracy:49.78 ;\n",
      "<class 'torch.Tensor'> tensor(76440) 76440\n",
      "153536 ; loss 1.04 accuracy:49.77 ;\n",
      "<class 'torch.Tensor'> tensor(79659) 79659\n",
      "159936 ; loss 1.04 accuracy:49.79 ;\n",
      "<class 'torch.Tensor'> tensor(82846) 82846\n",
      "166336 ; loss 1.04 accuracy:49.79 ;\n",
      "<class 'torch.Tensor'> tensor(86015) 86015\n",
      "172736 ; loss 1.04 accuracy:49.78 ;\n",
      "<class 'torch.Tensor'> tensor(89250) 89250\n",
      "179136 ; loss 1.04 accuracy:49.8 ;\n",
      "<class 'torch.Tensor'> tensor(92412) 92412\n",
      "185536 ; loss 1.04 accuracy:49.79 ;\n",
      "<class 'torch.Tensor'> tensor(95607) 95607\n",
      "191936 ; loss 1.04 accuracy:49.8 ;\n",
      "<class 'torch.Tensor'> tensor(98873) 98873\n",
      "198336 ; loss 1.03 accuracy:49.84 ;\n",
      "<class 'torch.Tensor'> tensor(102125) 102125\n",
      "204736 ; loss 1.03 accuracy:49.87 ;\n",
      "<class 'torch.Tensor'> tensor(105344) 105344\n",
      "211136 ; loss 1.03 accuracy:49.88 ;\n",
      "<class 'torch.Tensor'> tensor(108596) 108596\n",
      "217536 ; loss 1.03 accuracy:49.91 ;\n",
      "<class 'torch.Tensor'> tensor(111833) 111833\n",
      "223936 ; loss 1.03 accuracy:49.93 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(115051) 115051\n",
      "230336 ; loss 1.03 accuracy:49.94 ;\n",
      "<class 'torch.Tensor'> tensor(118399) 118399\n",
      "236736 ; loss 1.02 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(121624) 121624\n",
      "243136 ; loss 1.03 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(124795) 124795\n",
      "249536 ; loss 1.03 accuracy:50.0 ;\n",
      "<class 'torch.Tensor'> tensor(127937) 127937\n",
      "255936 ; loss 1.03 accuracy:49.98 ;\n",
      "<class 'torch.Tensor'> tensor(131229) 131229\n",
      "262336 ; loss 1.02 accuracy:50.01 ;\n",
      "<class 'torch.Tensor'> tensor(134496) 134496\n",
      "268736 ; loss 1.02 accuracy:50.04 ;\n",
      "<class 'torch.Tensor'> tensor(137757) 137757\n",
      "275136 ; loss 1.02 accuracy:50.06 ;\n",
      "<class 'torch.Tensor'> tensor(141034) 141034\n",
      "281536 ; loss 1.02 accuracy:50.08 ;\n",
      "<class 'torch.Tensor'> tensor(144281) 144281\n",
      "287936 ; loss 1.03 accuracy:50.1 ;\n",
      "<class 'torch.Tensor'> tensor(147531) 147531\n",
      "294336 ; loss 1.03 accuracy:50.11 ;\n",
      "<class 'torch.Tensor'> tensor(150779) 150779\n",
      "300736 ; loss 1.02 accuracy:50.13 ;\n",
      "<class 'torch.Tensor'> tensor(153985) 153985\n",
      "307136 ; loss 1.02 accuracy:50.13 ;\n",
      "<class 'torch.Tensor'> tensor(157224) 157224\n",
      "313536 ; loss 1.02 accuracy:50.14 ;\n",
      "<class 'torch.Tensor'> tensor(160525) 160525\n",
      "319936 ; loss 1.02 accuracy:50.16 ;\n",
      "<class 'torch.Tensor'> tensor(163790) 163790\n",
      "326336 ; loss 1.02 accuracy:50.18 ;\n",
      "<class 'torch.Tensor'> tensor(167127) 167127\n",
      "332736 ; loss 1.02 accuracy:50.22 ;\n",
      "<class 'torch.Tensor'> tensor(170407) 170407\n",
      "339136 ; loss 1.02 accuracy:50.24 ;\n",
      "<class 'torch.Tensor'> tensor(173667) 173667\n",
      "345536 ; loss 1.01 accuracy:50.25 ;\n",
      "<class 'torch.Tensor'> tensor(176948) 176948\n",
      "351936 ; loss 1.02 accuracy:50.27 ;\n",
      "<class 'torch.Tensor'> tensor(180320) 180320\n",
      "358336 ; loss 1.01 accuracy:50.31 ;\n",
      "<class 'torch.Tensor'> tensor(183597) 183597\n",
      "364736 ; loss 1.01 accuracy:50.33 ;\n",
      "<class 'torch.Tensor'> tensor(186915) 186915\n",
      "371136 ; loss 1.01 accuracy:50.35 ;\n",
      "<class 'torch.Tensor'> tensor(190231) 190231\n",
      "377536 ; loss 1.01 accuracy:50.38 ;\n",
      "<class 'torch.Tensor'> tensor(193512) 193512\n",
      "383936 ; loss 1.01 accuracy:50.39 ;\n",
      "<class 'torch.Tensor'> tensor(196842) 196842\n",
      "390336 ; loss 1.01 accuracy:50.42 ;\n",
      "<class 'torch.Tensor'> tensor(200166) 200166\n",
      "396736 ; loss 1.01 accuracy:50.45 ;\n",
      "<class 'torch.Tensor'> tensor(203452) 203452\n",
      "403136 ; loss 1.01 accuracy:50.46 ;\n",
      "<class 'torch.Tensor'> tensor(206854) 206854\n",
      "409536 ; loss 1.01 accuracy:50.5 ;\n",
      "<class 'torch.Tensor'> tensor(210204) 210204\n",
      "415936 ; loss 1.01 accuracy:50.53 ;\n",
      "<class 'torch.Tensor'> tensor(213545) 213545\n",
      "422336 ; loss 1.01 accuracy:50.56 ;\n",
      "<class 'torch.Tensor'> tensor(216962) 216962\n",
      "428736 ; loss 1.0 accuracy:50.6 ;\n",
      "<class 'torch.Tensor'> tensor(220346) 220346\n",
      "435136 ; loss 1.0 accuracy:50.63 ;\n",
      "<class 'torch.Tensor'> tensor(223693) 223693\n",
      "441536 ; loss 1.0 accuracy:50.66 ;\n",
      "<class 'torch.Tensor'> tensor(227017) 227017\n",
      "447936 ; loss 1.0 accuracy:50.67 ;\n",
      "<class 'torch.Tensor'> tensor(230364) 230364\n",
      "454336 ; loss 1.0 accuracy:50.7 ;\n",
      "<class 'torch.Tensor'> tensor(233712) 233712\n",
      "460736 ; loss 0.99 accuracy:50.72 ;\n",
      "<class 'torch.Tensor'> tensor(237087) 237087\n",
      "467136 ; loss 0.99 accuracy:50.75 ;\n",
      "<class 'torch.Tensor'> tensor(240353) 240353\n",
      "473536 ; loss 1.0 accuracy:50.75 ;\n",
      "<class 'torch.Tensor'> tensor(243710) 243710\n",
      "479936 ; loss 1.0 accuracy:50.77 ;\n",
      "<class 'torch.Tensor'> tensor(247224) 247224\n",
      "486336 ; loss 0.99 accuracy:50.83 ;\n",
      "<class 'torch.Tensor'> tensor(250546) 250546\n",
      "492736 ; loss 1.0 accuracy:50.84 ;\n",
      "<class 'torch.Tensor'> tensor(253907) 253907\n",
      "499136 ; loss 0.99 accuracy:50.86 ;\n",
      "<class 'torch.Tensor'> tensor(257293) 257293\n",
      "505536 ; loss 0.99 accuracy:50.89 ;\n",
      "<class 'torch.Tensor'> tensor(260736) 260736\n",
      "511936 ; loss 0.99 accuracy:50.92 ;\n",
      "<class 'torch.Tensor'> tensor(264101) 264101\n",
      "518336 ; loss 1.0 accuracy:50.95 ;\n",
      "<class 'torch.Tensor'> tensor(267572) 267572\n",
      "524736 ; loss 0.98 accuracy:50.99 ;\n",
      "<class 'torch.Tensor'> tensor(270950) 270950\n",
      "531136 ; loss 0.99 accuracy:51.01 ;\n",
      "<class 'torch.Tensor'> tensor(274342) 274342\n",
      "537536 ; loss 0.99 accuracy:51.03 ;\n",
      "<class 'torch.Tensor'> tensor(277814) 277814\n",
      "543936 ; loss 0.98 accuracy:51.07 ;\n",
      "results : epoch 4 ; mean accuracy train : 51.1\n",
      "\n",
      "VALIDATION : Epoch 4\n",
      "togrep : results : epoch 4 ; mean accuracy valid :              54.04\n",
      "saving model at epoch 4\n",
      "\n",
      "TRAINING : Epoch 5\n",
      "Learning rate : 0.096059601\n",
      "<class 'torch.Tensor'> tensor(3396) 3396\n",
      "6336 ; loss 0.98 accuracy:53.06 ;\n",
      "<class 'torch.Tensor'> tensor(6769) 6769\n",
      "12736 ; loss 0.99 accuracy:52.88 ;\n",
      "<class 'torch.Tensor'> tensor(10228) 10228\n",
      "19136 ; loss 0.98 accuracy:53.27 ;\n",
      "<class 'torch.Tensor'> tensor(13685) 13685\n",
      "25536 ; loss 0.98 accuracy:53.46 ;\n",
      "<class 'torch.Tensor'> tensor(17111) 17111\n",
      "31936 ; loss 0.98 accuracy:53.47 ;\n",
      "<class 'torch.Tensor'> tensor(20601) 20601\n",
      "38336 ; loss 0.98 accuracy:53.65 ;\n",
      "<class 'torch.Tensor'> tensor(24054) 24054\n",
      "44736 ; loss 0.98 accuracy:53.69 ;\n",
      "<class 'torch.Tensor'> tensor(27514) 27514\n",
      "51136 ; loss 0.98 accuracy:53.74 ;\n",
      "<class 'torch.Tensor'> tensor(31001) 31001\n",
      "57536 ; loss 0.98 accuracy:53.82 ;\n",
      "<class 'torch.Tensor'> tensor(34405) 34405\n",
      "63936 ; loss 0.98 accuracy:53.76 ;\n",
      "<class 'torch.Tensor'> tensor(37916) 37916\n",
      "70336 ; loss 0.97 accuracy:53.86 ;\n",
      "<class 'torch.Tensor'> tensor(41428) 41428\n",
      "76736 ; loss 0.97 accuracy:53.94 ;\n",
      "<class 'torch.Tensor'> tensor(44943) 44943\n",
      "83136 ; loss 0.97 accuracy:54.02 ;\n",
      "<class 'torch.Tensor'> tensor(48458) 48458\n",
      "89536 ; loss 0.97 accuracy:54.08 ;\n",
      "<class 'torch.Tensor'> tensor(51939) 51939\n",
      "95936 ; loss 0.97 accuracy:54.1 ;\n",
      "<class 'torch.Tensor'> tensor(55442) 55442\n",
      "102336 ; loss 0.97 accuracy:54.14 ;\n",
      "<class 'torch.Tensor'> tensor(58955) 58955\n",
      "108736 ; loss 0.96 accuracy:54.19 ;\n",
      "<class 'torch.Tensor'> tensor(62512) 62512\n",
      "115136 ; loss 0.96 accuracy:54.26 ;\n",
      "<class 'torch.Tensor'> tensor(66035) 66035\n",
      "121536 ; loss 0.96 accuracy:54.31 ;\n",
      "<class 'torch.Tensor'> tensor(69536) 69536\n",
      "127936 ; loss 0.96 accuracy:54.33 ;\n",
      "<class 'torch.Tensor'> tensor(72998) 72998\n",
      "134336 ; loss 0.97 accuracy:54.31 ;\n",
      "<class 'torch.Tensor'> tensor(76614) 76614\n",
      "140736 ; loss 0.96 accuracy:54.41 ;\n",
      "<class 'torch.Tensor'> tensor(80122) 80122\n",
      "147136 ; loss 0.96 accuracy:54.43 ;\n",
      "<class 'torch.Tensor'> tensor(83674) 83674\n",
      "153536 ; loss 0.96 accuracy:54.48 ;\n",
      "<class 'torch.Tensor'> tensor(87243) 87243\n",
      "159936 ; loss 0.96 accuracy:54.53 ;\n",
      "<class 'torch.Tensor'> tensor(90882) 90882\n",
      "166336 ; loss 0.95 accuracy:54.62 ;\n",
      "<class 'torch.Tensor'> tensor(94432) 94432\n",
      "172736 ; loss 0.96 accuracy:54.65 ;\n",
      "<class 'torch.Tensor'> tensor(98012) 98012\n",
      "179136 ; loss 0.95 accuracy:54.69 ;\n",
      "<class 'torch.Tensor'> tensor(101557) 101557\n",
      "185536 ; loss 0.95 accuracy:54.72 ;\n",
      "<class 'torch.Tensor'> tensor(105152) 105152\n",
      "191936 ; loss 0.95 accuracy:54.77 ;\n",
      "<class 'torch.Tensor'> tensor(108650) 108650\n",
      "198336 ; loss 0.96 accuracy:54.76 ;\n",
      "<class 'torch.Tensor'> tensor(112277) 112277\n",
      "204736 ; loss 0.95 accuracy:54.82 ;\n",
      "<class 'torch.Tensor'> tensor(115903) 115903\n",
      "211136 ; loss 0.95 accuracy:54.88 ;\n",
      "<class 'torch.Tensor'> tensor(119531) 119531\n",
      "217536 ; loss 0.95 accuracy:54.93 ;\n",
      "<class 'torch.Tensor'> tensor(123159) 123159\n",
      "223936 ; loss 0.94 accuracy:54.98 ;\n",
      "<class 'torch.Tensor'> tensor(126766) 126766\n",
      "230336 ; loss 0.95 accuracy:55.02 ;\n",
      "<class 'torch.Tensor'> tensor(130400) 130400\n",
      "236736 ; loss 0.94 accuracy:55.07 ;\n",
      "<class 'torch.Tensor'> tensor(134045) 134045\n",
      "243136 ; loss 0.94 accuracy:55.12 ;\n",
      "<class 'torch.Tensor'> tensor(137691) 137691\n",
      "249536 ; loss 0.94 accuracy:55.16 ;\n",
      "<class 'torch.Tensor'> tensor(141343) 141343\n",
      "255936 ; loss 0.94 accuracy:55.21 ;\n",
      "<class 'torch.Tensor'> tensor(144967) 144967\n",
      "262336 ; loss 0.94 accuracy:55.25 ;\n",
      "<class 'torch.Tensor'> tensor(148611) 148611\n",
      "268736 ; loss 0.94 accuracy:55.29 ;\n",
      "<class 'torch.Tensor'> tensor(152278) 152278\n",
      "275136 ; loss 0.94 accuracy:55.33 ;\n",
      "<class 'torch.Tensor'> tensor(155895) 155895\n",
      "281536 ; loss 0.94 accuracy:55.36 ;\n",
      "<class 'torch.Tensor'> tensor(159595) 159595\n",
      "287936 ; loss 0.93 accuracy:55.41 ;\n",
      "<class 'torch.Tensor'> tensor(163237) 163237\n",
      "294336 ; loss 0.94 accuracy:55.45 ;\n",
      "<class 'torch.Tensor'> tensor(166886) 166886\n",
      "300736 ; loss 0.93 accuracy:55.48 ;\n",
      "<class 'torch.Tensor'> tensor(170631) 170631\n",
      "307136 ; loss 0.93 accuracy:55.54 ;\n",
      "<class 'torch.Tensor'> tensor(174274) 174274\n",
      "313536 ; loss 0.94 accuracy:55.57 ;\n",
      "<class 'torch.Tensor'> tensor(178000) 178000\n",
      "319936 ; loss 0.93 accuracy:55.62 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(181695) 181695\n",
      "326336 ; loss 0.93 accuracy:55.67 ;\n",
      "<class 'torch.Tensor'> tensor(185353) 185353\n",
      "332736 ; loss 0.93 accuracy:55.7 ;\n",
      "<class 'torch.Tensor'> tensor(189031) 189031\n",
      "339136 ; loss 0.93 accuracy:55.73 ;\n",
      "<class 'torch.Tensor'> tensor(192711) 192711\n",
      "345536 ; loss 0.93 accuracy:55.76 ;\n",
      "<class 'torch.Tensor'> tensor(196459) 196459\n",
      "351936 ; loss 0.93 accuracy:55.81 ;\n",
      "<class 'torch.Tensor'> tensor(200190) 200190\n",
      "358336 ; loss 0.92 accuracy:55.86 ;\n",
      "<class 'torch.Tensor'> tensor(203936) 203936\n",
      "364736 ; loss 0.92 accuracy:55.9 ;\n",
      "<class 'torch.Tensor'> tensor(207641) 207641\n",
      "371136 ; loss 0.92 accuracy:55.94 ;\n",
      "<class 'torch.Tensor'> tensor(211415) 211415\n",
      "377536 ; loss 0.92 accuracy:55.99 ;\n",
      "<class 'torch.Tensor'> tensor(215071) 215071\n",
      "383936 ; loss 0.93 accuracy:56.01 ;\n",
      "<class 'torch.Tensor'> tensor(218851) 218851\n",
      "390336 ; loss 0.92 accuracy:56.06 ;\n",
      "<class 'torch.Tensor'> tensor(222572) 222572\n",
      "396736 ; loss 0.91 accuracy:56.09 ;\n",
      "<class 'torch.Tensor'> tensor(226367) 226367\n",
      "403136 ; loss 0.91 accuracy:56.14 ;\n",
      "<class 'torch.Tensor'> tensor(230119) 230119\n",
      "409536 ; loss 0.92 accuracy:56.18 ;\n",
      "<class 'torch.Tensor'> tensor(233888) 233888\n",
      "415936 ; loss 0.92 accuracy:56.22 ;\n",
      "<class 'torch.Tensor'> tensor(237669) 237669\n",
      "422336 ; loss 0.91 accuracy:56.27 ;\n",
      "<class 'torch.Tensor'> tensor(241443) 241443\n",
      "428736 ; loss 0.92 accuracy:56.31 ;\n",
      "<class 'torch.Tensor'> tensor(245168) 245168\n",
      "435136 ; loss 0.92 accuracy:56.33 ;\n",
      "<class 'torch.Tensor'> tensor(249017) 249017\n",
      "441536 ; loss 0.9 accuracy:56.39 ;\n",
      "<class 'torch.Tensor'> tensor(252877) 252877\n",
      "447936 ; loss 0.91 accuracy:56.45 ;\n",
      "<class 'torch.Tensor'> tensor(256739) 256739\n",
      "454336 ; loss 0.9 accuracy:56.5 ;\n",
      "<class 'torch.Tensor'> tensor(260509) 260509\n",
      "460736 ; loss 0.91 accuracy:56.53 ;\n",
      "<class 'torch.Tensor'> tensor(264318) 264318\n",
      "467136 ; loss 0.9 accuracy:56.57 ;\n",
      "<class 'torch.Tensor'> tensor(268165) 268165\n",
      "473536 ; loss 0.9 accuracy:56.62 ;\n",
      "<class 'torch.Tensor'> tensor(272032) 272032\n",
      "479936 ; loss 0.9 accuracy:56.67 ;\n",
      "<class 'torch.Tensor'> tensor(275837) 275837\n",
      "486336 ; loss 0.9 accuracy:56.71 ;\n",
      "<class 'torch.Tensor'> tensor(279664) 279664\n",
      "492736 ; loss 0.9 accuracy:56.75 ;\n",
      "<class 'torch.Tensor'> tensor(283439) 283439\n",
      "499136 ; loss 0.9 accuracy:56.78 ;\n",
      "<class 'torch.Tensor'> tensor(287229) 287229\n",
      "505536 ; loss 0.9 accuracy:56.81 ;\n",
      "<class 'torch.Tensor'> tensor(291091) 291091\n",
      "511936 ; loss 0.89 accuracy:56.85 ;\n",
      "<class 'torch.Tensor'> tensor(294893) 294893\n",
      "518336 ; loss 0.9 accuracy:56.89 ;\n",
      "<class 'torch.Tensor'> tensor(298797) 298797\n",
      "524736 ; loss 0.88 accuracy:56.94 ;\n",
      "<class 'torch.Tensor'> tensor(302630) 302630\n",
      "531136 ; loss 0.89 accuracy:56.97 ;\n",
      "<class 'torch.Tensor'> tensor(306480) 306480\n",
      "537536 ; loss 0.88 accuracy:57.01 ;\n",
      "<class 'torch.Tensor'> tensor(310374) 310374\n",
      "543936 ; loss 0.89 accuracy:57.05 ;\n",
      "results : epoch 5 ; mean accuracy train : 57.09\n",
      "\n",
      "VALIDATION : Epoch 5\n",
      "togrep : results : epoch 5 ; mean accuracy valid :              62.32\n",
      "saving model at epoch 5\n",
      "\n",
      "TRAINING : Epoch 6\n",
      "Learning rate : 0.09509900499\n",
      "<class 'torch.Tensor'> tensor(3925) 3925\n",
      "6336 ; loss 0.88 accuracy:61.33 ;\n",
      "<class 'torch.Tensor'> tensor(7739) 7739\n",
      "12736 ; loss 0.89 accuracy:60.46 ;\n",
      "<class 'torch.Tensor'> tensor(11593) 11593\n",
      "19136 ; loss 0.88 accuracy:60.38 ;\n",
      "<class 'torch.Tensor'> tensor(15497) 15497\n",
      "25536 ; loss 0.88 accuracy:60.54 ;\n",
      "<class 'torch.Tensor'> tensor(19476) 19476\n",
      "31936 ; loss 0.88 accuracy:60.86 ;\n",
      "<class 'torch.Tensor'> tensor(23347) 23347\n",
      "38336 ; loss 0.88 accuracy:60.8 ;\n",
      "<class 'torch.Tensor'> tensor(27251) 27251\n",
      "44736 ; loss 0.88 accuracy:60.83 ;\n",
      "<class 'torch.Tensor'> tensor(31153) 31153\n",
      "51136 ; loss 0.88 accuracy:60.85 ;\n",
      "<class 'torch.Tensor'> tensor(35000) 35000\n",
      "57536 ; loss 0.88 accuracy:60.76 ;\n",
      "<class 'torch.Tensor'> tensor(38918) 38918\n",
      "63936 ; loss 0.88 accuracy:60.81 ;\n",
      "<class 'torch.Tensor'> tensor(42844) 42844\n",
      "70336 ; loss 0.87 accuracy:60.86 ;\n",
      "<class 'torch.Tensor'> tensor(46745) 46745\n",
      "76736 ; loss 0.87 accuracy:60.87 ;\n",
      "<class 'torch.Tensor'> tensor(50686) 50686\n",
      "83136 ; loss 0.87 accuracy:60.92 ;\n",
      "<class 'torch.Tensor'> tensor(54646) 54646\n",
      "89536 ; loss 0.87 accuracy:60.99 ;\n",
      "<class 'torch.Tensor'> tensor(58530) 58530\n",
      "95936 ; loss 0.88 accuracy:60.97 ;\n",
      "<class 'torch.Tensor'> tensor(62418) 62418\n",
      "102336 ; loss 0.87 accuracy:60.96 ;\n",
      "<class 'torch.Tensor'> tensor(66308) 66308\n",
      "108736 ; loss 0.87 accuracy:60.94 ;\n",
      "<class 'torch.Tensor'> tensor(70295) 70295\n",
      "115136 ; loss 0.86 accuracy:61.02 ;\n",
      "<class 'torch.Tensor'> tensor(74291) 74291\n",
      "121536 ; loss 0.86 accuracy:61.09 ;\n",
      "<class 'torch.Tensor'> tensor(78257) 78257\n",
      "127936 ; loss 0.86 accuracy:61.14 ;\n",
      "<class 'torch.Tensor'> tensor(82248) 82248\n",
      "134336 ; loss 0.86 accuracy:61.2 ;\n",
      "<class 'torch.Tensor'> tensor(86230) 86230\n",
      "140736 ; loss 0.85 accuracy:61.24 ;\n",
      "<class 'torch.Tensor'> tensor(90153) 90153\n",
      "147136 ; loss 0.87 accuracy:61.25 ;\n",
      "<class 'torch.Tensor'> tensor(94157) 94157\n",
      "153536 ; loss 0.86 accuracy:61.3 ;\n",
      "<class 'torch.Tensor'> tensor(98090) 98090\n",
      "159936 ; loss 0.85 accuracy:61.31 ;\n",
      "<class 'torch.Tensor'> tensor(102117) 102117\n",
      "166336 ; loss 0.85 accuracy:61.37 ;\n",
      "<class 'torch.Tensor'> tensor(106108) 106108\n",
      "172736 ; loss 0.85 accuracy:61.41 ;\n",
      "<class 'torch.Tensor'> tensor(110064) 110064\n",
      "179136 ; loss 0.86 accuracy:61.42 ;\n",
      "<class 'torch.Tensor'> tensor(114040) 114040\n",
      "185536 ; loss 0.85 accuracy:61.44 ;\n",
      "<class 'torch.Tensor'> tensor(117992) 117992\n",
      "191936 ; loss 0.86 accuracy:61.45 ;\n",
      "<class 'torch.Tensor'> tensor(121970) 121970\n",
      "198336 ; loss 0.86 accuracy:61.48 ;\n",
      "<class 'torch.Tensor'> tensor(125961) 125961\n",
      "204736 ; loss 0.84 accuracy:61.5 ;\n",
      "<class 'torch.Tensor'> tensor(129940) 129940\n",
      "211136 ; loss 0.85 accuracy:61.52 ;\n",
      "<class 'torch.Tensor'> tensor(133963) 133963\n",
      "217536 ; loss 0.84 accuracy:61.56 ;\n",
      "<class 'torch.Tensor'> tensor(137983) 137983\n",
      "223936 ; loss 0.84 accuracy:61.6 ;\n",
      "<class 'torch.Tensor'> tensor(141963) 141963\n",
      "230336 ; loss 0.85 accuracy:61.62 ;\n",
      "<class 'torch.Tensor'> tensor(146011) 146011\n",
      "236736 ; loss 0.84 accuracy:61.66 ;\n",
      "<class 'torch.Tensor'> tensor(150009) 150009\n",
      "243136 ; loss 0.85 accuracy:61.68 ;\n",
      "<class 'torch.Tensor'> tensor(154085) 154085\n",
      "249536 ; loss 0.83 accuracy:61.73 ;\n",
      "<class 'torch.Tensor'> tensor(158141) 158141\n",
      "255936 ; loss 0.84 accuracy:61.77 ;\n",
      "<class 'torch.Tensor'> tensor(162227) 162227\n",
      "262336 ; loss 0.83 accuracy:61.82 ;\n",
      "<class 'torch.Tensor'> tensor(166267) 166267\n",
      "268736 ; loss 0.83 accuracy:61.86 ;\n",
      "<class 'torch.Tensor'> tensor(170267) 170267\n",
      "275136 ; loss 0.84 accuracy:61.87 ;\n",
      "<class 'torch.Tensor'> tensor(174265) 174265\n",
      "281536 ; loss 0.85 accuracy:61.88 ;\n",
      "<class 'torch.Tensor'> tensor(178373) 178373\n",
      "287936 ; loss 0.83 accuracy:61.94 ;\n",
      "<class 'torch.Tensor'> tensor(182425) 182425\n",
      "294336 ; loss 0.83 accuracy:61.97 ;\n",
      "<class 'torch.Tensor'> tensor(186502) 186502\n",
      "300736 ; loss 0.83 accuracy:62.0 ;\n",
      "<class 'torch.Tensor'> tensor(190603) 190603\n",
      "307136 ; loss 0.83 accuracy:62.05 ;\n",
      "<class 'torch.Tensor'> tensor(194632) 194632\n",
      "313536 ; loss 0.84 accuracy:62.06 ;\n",
      "<class 'torch.Tensor'> tensor(198699) 198699\n",
      "319936 ; loss 0.83 accuracy:62.09 ;\n",
      "<class 'torch.Tensor'> tensor(202812) 202812\n",
      "326336 ; loss 0.82 accuracy:62.14 ;\n",
      "<class 'torch.Tensor'> tensor(206860) 206860\n",
      "332736 ; loss 0.83 accuracy:62.16 ;\n",
      "<class 'torch.Tensor'> tensor(210914) 210914\n",
      "339136 ; loss 0.83 accuracy:62.18 ;\n",
      "<class 'torch.Tensor'> tensor(215014) 215014\n",
      "345536 ; loss 0.82 accuracy:62.21 ;\n",
      "<class 'torch.Tensor'> tensor(219152) 219152\n",
      "351936 ; loss 0.82 accuracy:62.26 ;\n",
      "<class 'torch.Tensor'> tensor(223213) 223213\n",
      "358336 ; loss 0.82 accuracy:62.28 ;\n",
      "<class 'torch.Tensor'> tensor(227282) 227282\n",
      "364736 ; loss 0.83 accuracy:62.3 ;\n",
      "<class 'torch.Tensor'> tensor(231362) 231362\n",
      "371136 ; loss 0.82 accuracy:62.33 ;\n",
      "<class 'torch.Tensor'> tensor(235479) 235479\n",
      "377536 ; loss 0.82 accuracy:62.36 ;\n",
      "<class 'torch.Tensor'> tensor(239618) 239618\n",
      "383936 ; loss 0.82 accuracy:62.4 ;\n",
      "<class 'torch.Tensor'> tensor(243679) 243679\n",
      "390336 ; loss 0.83 accuracy:62.42 ;\n",
      "<class 'torch.Tensor'> tensor(247831) 247831\n",
      "396736 ; loss 0.81 accuracy:62.46 ;\n",
      "<class 'torch.Tensor'> tensor(251992) 251992\n",
      "403136 ; loss 0.81 accuracy:62.5 ;\n",
      "<class 'torch.Tensor'> tensor(256089) 256089\n",
      "409536 ; loss 0.82 accuracy:62.52 ;\n",
      "<class 'torch.Tensor'> tensor(260247) 260247\n",
      "415936 ; loss 0.81 accuracy:62.56 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(264413) 264413\n",
      "422336 ; loss 0.8 accuracy:62.6 ;\n",
      "<class 'torch.Tensor'> tensor(268588) 268588\n",
      "428736 ; loss 0.81 accuracy:62.64 ;\n",
      "<class 'torch.Tensor'> tensor(272695) 272695\n",
      "435136 ; loss 0.81 accuracy:62.66 ;\n",
      "<class 'torch.Tensor'> tensor(276817) 276817\n",
      "441536 ; loss 0.8 accuracy:62.69 ;\n",
      "<class 'torch.Tensor'> tensor(280989) 280989\n",
      "447936 ; loss 0.81 accuracy:62.72 ;\n",
      "<class 'torch.Tensor'> tensor(285166) 285166\n",
      "454336 ; loss 0.8 accuracy:62.76 ;\n",
      "<class 'torch.Tensor'> tensor(289293) 289293\n",
      "460736 ; loss 0.8 accuracy:62.78 ;\n",
      "<class 'torch.Tensor'> tensor(293430) 293430\n",
      "467136 ; loss 0.81 accuracy:62.81 ;\n",
      "<class 'torch.Tensor'> tensor(297647) 297647\n",
      "473536 ; loss 0.8 accuracy:62.85 ;\n",
      "<class 'torch.Tensor'> tensor(301839) 301839\n",
      "479936 ; loss 0.8 accuracy:62.88 ;\n",
      "<class 'torch.Tensor'> tensor(306008) 306008\n",
      "486336 ; loss 0.8 accuracy:62.91 ;\n",
      "<class 'torch.Tensor'> tensor(310169) 310169\n",
      "492736 ; loss 0.8 accuracy:62.94 ;\n",
      "<class 'torch.Tensor'> tensor(314302) 314302\n",
      "499136 ; loss 0.8 accuracy:62.96 ;\n",
      "<class 'torch.Tensor'> tensor(318474) 318474\n",
      "505536 ; loss 0.79 accuracy:62.99 ;\n",
      "<class 'torch.Tensor'> tensor(322633) 322633\n",
      "511936 ; loss 0.8 accuracy:63.01 ;\n",
      "<class 'torch.Tensor'> tensor(326833) 326833\n",
      "518336 ; loss 0.8 accuracy:63.05 ;\n",
      "<class 'torch.Tensor'> tensor(330955) 330955\n",
      "524736 ; loss 0.8 accuracy:63.06 ;\n",
      "<class 'torch.Tensor'> tensor(335104) 335104\n",
      "531136 ; loss 0.8 accuracy:63.08 ;\n",
      "<class 'torch.Tensor'> tensor(339325) 339325\n",
      "537536 ; loss 0.79 accuracy:63.12 ;\n",
      "<class 'torch.Tensor'> tensor(343472) 343472\n",
      "543936 ; loss 0.8 accuracy:63.14 ;\n",
      "results : epoch 6 ; mean accuracy train : 63.17\n",
      "\n",
      "VALIDATION : Epoch 6\n",
      "togrep : results : epoch 6 ; mean accuracy valid :              67.12\n",
      "saving model at epoch 6\n",
      "\n",
      "TRAINING : Epoch 7\n",
      "Learning rate : 0.0941480149401\n",
      "<class 'torch.Tensor'> tensor(4215) 4215\n",
      "6336 ; loss 0.79 accuracy:65.86 ;\n",
      "<class 'torch.Tensor'> tensor(8408) 8408\n",
      "12736 ; loss 0.79 accuracy:65.69 ;\n",
      "<class 'torch.Tensor'> tensor(12575) 12575\n",
      "19136 ; loss 0.79 accuracy:65.49 ;\n",
      "<class 'torch.Tensor'> tensor(16724) 16724\n",
      "25536 ; loss 0.8 accuracy:65.33 ;\n",
      "<class 'torch.Tensor'> tensor(20955) 20955\n",
      "31936 ; loss 0.79 accuracy:65.48 ;\n",
      "<class 'torch.Tensor'> tensor(25162) 25162\n",
      "38336 ; loss 0.79 accuracy:65.53 ;\n",
      "<class 'torch.Tensor'> tensor(29374) 29374\n",
      "44736 ; loss 0.79 accuracy:65.57 ;\n",
      "<class 'torch.Tensor'> tensor(33570) 33570\n",
      "51136 ; loss 0.79 accuracy:65.57 ;\n",
      "<class 'torch.Tensor'> tensor(37799) 37799\n",
      "57536 ; loss 0.79 accuracy:65.62 ;\n",
      "<class 'torch.Tensor'> tensor(42013) 42013\n",
      "63936 ; loss 0.79 accuracy:65.65 ;\n",
      "<class 'torch.Tensor'> tensor(46257) 46257\n",
      "70336 ; loss 0.79 accuracy:65.71 ;\n",
      "<class 'torch.Tensor'> tensor(50381) 50381\n",
      "76736 ; loss 0.8 accuracy:65.6 ;\n",
      "<class 'torch.Tensor'> tensor(54639) 54639\n",
      "83136 ; loss 0.78 accuracy:65.67 ;\n",
      "<class 'torch.Tensor'> tensor(58894) 58894\n",
      "89536 ; loss 0.78 accuracy:65.73 ;\n",
      "<class 'torch.Tensor'> tensor(63140) 63140\n",
      "95936 ; loss 0.77 accuracy:65.77 ;\n",
      "<class 'torch.Tensor'> tensor(67421) 67421\n",
      "102336 ; loss 0.77 accuracy:65.84 ;\n",
      "<class 'torch.Tensor'> tensor(71709) 71709\n",
      "108736 ; loss 0.76 accuracy:65.91 ;\n",
      "<class 'torch.Tensor'> tensor(75949) 75949\n",
      "115136 ; loss 0.78 accuracy:65.93 ;\n",
      "<class 'torch.Tensor'> tensor(80245) 80245\n",
      "121536 ; loss 0.78 accuracy:65.99 ;\n",
      "<class 'torch.Tensor'> tensor(84454) 84454\n",
      "127936 ; loss 0.78 accuracy:65.98 ;\n",
      "<class 'torch.Tensor'> tensor(88685) 88685\n",
      "134336 ; loss 0.79 accuracy:65.99 ;\n",
      "<class 'torch.Tensor'> tensor(92960) 92960\n",
      "140736 ; loss 0.78 accuracy:66.02 ;\n",
      "<class 'torch.Tensor'> tensor(97197) 97197\n",
      "147136 ; loss 0.78 accuracy:66.03 ;\n",
      "<class 'torch.Tensor'> tensor(101454) 101454\n",
      "153536 ; loss 0.78 accuracy:66.05 ;\n",
      "<class 'torch.Tensor'> tensor(105714) 105714\n",
      "159936 ; loss 0.76 accuracy:66.07 ;\n",
      "<class 'torch.Tensor'> tensor(109983) 109983\n",
      "166336 ; loss 0.77 accuracy:66.1 ;\n",
      "<class 'torch.Tensor'> tensor(114235) 114235\n",
      "172736 ; loss 0.77 accuracy:66.11 ;\n",
      "<class 'torch.Tensor'> tensor(118529) 118529\n",
      "179136 ; loss 0.76 accuracy:66.14 ;\n",
      "<class 'torch.Tensor'> tensor(122774) 122774\n",
      "185536 ; loss 0.78 accuracy:66.15 ;\n",
      "<class 'torch.Tensor'> tensor(127052) 127052\n",
      "191936 ; loss 0.77 accuracy:66.17 ;\n",
      "<class 'torch.Tensor'> tensor(131254) 131254\n",
      "198336 ; loss 0.78 accuracy:66.16 ;\n",
      "<class 'torch.Tensor'> tensor(135582) 135582\n",
      "204736 ; loss 0.76 accuracy:66.2 ;\n",
      "<class 'torch.Tensor'> tensor(139868) 139868\n",
      "211136 ; loss 0.77 accuracy:66.23 ;\n",
      "<class 'torch.Tensor'> tensor(144192) 144192\n",
      "217536 ; loss 0.76 accuracy:66.26 ;\n",
      "<class 'torch.Tensor'> tensor(148462) 148462\n",
      "223936 ; loss 0.77 accuracy:66.28 ;\n",
      "<class 'torch.Tensor'> tensor(152726) 152726\n",
      "230336 ; loss 0.78 accuracy:66.29 ;\n",
      "<class 'torch.Tensor'> tensor(156996) 156996\n",
      "236736 ; loss 0.77 accuracy:66.3 ;\n",
      "<class 'torch.Tensor'> tensor(161303) 161303\n",
      "243136 ; loss 0.77 accuracy:66.33 ;\n",
      "<class 'torch.Tensor'> tensor(165608) 165608\n",
      "249536 ; loss 0.76 accuracy:66.35 ;\n",
      "<class 'torch.Tensor'> tensor(169914) 169914\n",
      "255936 ; loss 0.76 accuracy:66.37 ;\n",
      "<class 'torch.Tensor'> tensor(174260) 174260\n",
      "262336 ; loss 0.75 accuracy:66.41 ;\n",
      "<class 'torch.Tensor'> tensor(178573) 178573\n",
      "268736 ; loss 0.76 accuracy:66.43 ;\n",
      "<class 'torch.Tensor'> tensor(182883) 182883\n",
      "275136 ; loss 0.76 accuracy:66.45 ;\n",
      "<class 'torch.Tensor'> tensor(187212) 187212\n",
      "281536 ; loss 0.75 accuracy:66.48 ;\n",
      "<class 'torch.Tensor'> tensor(191470) 191470\n",
      "287936 ; loss 0.76 accuracy:66.48 ;\n",
      "<class 'torch.Tensor'> tensor(195833) 195833\n",
      "294336 ; loss 0.76 accuracy:66.52 ;\n",
      "<class 'torch.Tensor'> tensor(200132) 200132\n",
      "300736 ; loss 0.77 accuracy:66.53 ;\n",
      "<class 'torch.Tensor'> tensor(204458) 204458\n",
      "307136 ; loss 0.76 accuracy:66.56 ;\n",
      "<class 'torch.Tensor'> tensor(208679) 208679\n",
      "313536 ; loss 0.78 accuracy:66.54 ;\n",
      "<class 'torch.Tensor'> tensor(213003) 213003\n",
      "319936 ; loss 0.75 accuracy:66.56 ;\n",
      "<class 'torch.Tensor'> tensor(217327) 217327\n",
      "326336 ; loss 0.75 accuracy:66.58 ;\n",
      "<class 'torch.Tensor'> tensor(221697) 221697\n",
      "332736 ; loss 0.75 accuracy:66.62 ;\n",
      "<class 'torch.Tensor'> tensor(226034) 226034\n",
      "339136 ; loss 0.75 accuracy:66.64 ;\n",
      "<class 'torch.Tensor'> tensor(230392) 230392\n",
      "345536 ; loss 0.75 accuracy:66.66 ;\n",
      "<class 'torch.Tensor'> tensor(234708) 234708\n",
      "351936 ; loss 0.76 accuracy:66.68 ;\n",
      "<class 'torch.Tensor'> tensor(239012) 239012\n",
      "358336 ; loss 0.76 accuracy:66.69 ;\n",
      "<class 'torch.Tensor'> tensor(243287) 243287\n",
      "364736 ; loss 0.77 accuracy:66.69 ;\n",
      "<class 'torch.Tensor'> tensor(247632) 247632\n",
      "371136 ; loss 0.75 accuracy:66.71 ;\n",
      "<class 'torch.Tensor'> tensor(251969) 251969\n",
      "377536 ; loss 0.75 accuracy:66.73 ;\n",
      "<class 'torch.Tensor'> tensor(256315) 256315\n",
      "383936 ; loss 0.76 accuracy:66.75 ;\n",
      "<class 'torch.Tensor'> tensor(260633) 260633\n",
      "390336 ; loss 0.74 accuracy:66.76 ;\n",
      "<class 'torch.Tensor'> tensor(264993) 264993\n",
      "396736 ; loss 0.75 accuracy:66.78 ;\n",
      "<class 'torch.Tensor'> tensor(269330) 269330\n",
      "403136 ; loss 0.76 accuracy:66.8 ;\n",
      "<class 'torch.Tensor'> tensor(273717) 273717\n",
      "409536 ; loss 0.74 accuracy:66.83 ;\n",
      "<class 'torch.Tensor'> tensor(278064) 278064\n",
      "415936 ; loss 0.74 accuracy:66.84 ;\n",
      "<class 'torch.Tensor'> tensor(282423) 282423\n",
      "422336 ; loss 0.74 accuracy:66.86 ;\n",
      "<class 'torch.Tensor'> tensor(286780) 286780\n",
      "428736 ; loss 0.75 accuracy:66.88 ;\n",
      "<class 'torch.Tensor'> tensor(291109) 291109\n",
      "435136 ; loss 0.75 accuracy:66.89 ;\n",
      "<class 'torch.Tensor'> tensor(295473) 295473\n",
      "441536 ; loss 0.74 accuracy:66.91 ;\n",
      "<class 'torch.Tensor'> tensor(299815) 299815\n",
      "447936 ; loss 0.75 accuracy:66.92 ;\n",
      "<class 'torch.Tensor'> tensor(304103) 304103\n",
      "454336 ; loss 0.75 accuracy:66.92 ;\n",
      "<class 'torch.Tensor'> tensor(308514) 308514\n",
      "460736 ; loss 0.73 accuracy:66.95 ;\n",
      "<class 'torch.Tensor'> tensor(312914) 312914\n",
      "467136 ; loss 0.74 accuracy:66.98 ;\n",
      "<class 'torch.Tensor'> tensor(317247) 317247\n",
      "473536 ; loss 0.74 accuracy:66.99 ;\n",
      "<class 'torch.Tensor'> tensor(321648) 321648\n",
      "479936 ; loss 0.73 accuracy:67.01 ;\n",
      "<class 'torch.Tensor'> tensor(326012) 326012\n",
      "486336 ; loss 0.73 accuracy:67.03 ;\n",
      "<class 'torch.Tensor'> tensor(330393) 330393\n",
      "492736 ; loss 0.74 accuracy:67.04 ;\n",
      "<class 'torch.Tensor'> tensor(334754) 334754\n",
      "499136 ; loss 0.73 accuracy:67.06 ;\n",
      "<class 'torch.Tensor'> tensor(339124) 339124\n",
      "505536 ; loss 0.75 accuracy:67.07 ;\n",
      "<class 'torch.Tensor'> tensor(343541) 343541\n",
      "511936 ; loss 0.74 accuracy:67.1 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(347925) 347925\n",
      "518336 ; loss 0.73 accuracy:67.12 ;\n",
      "<class 'torch.Tensor'> tensor(352342) 352342\n",
      "524736 ; loss 0.73 accuracy:67.14 ;\n",
      "<class 'torch.Tensor'> tensor(356782) 356782\n",
      "531136 ; loss 0.72 accuracy:67.17 ;\n",
      "<class 'torch.Tensor'> tensor(361214) 361214\n",
      "537536 ; loss 0.72 accuracy:67.19 ;\n",
      "<class 'torch.Tensor'> tensor(365556) 365556\n",
      "543936 ; loss 0.75 accuracy:67.2 ;\n",
      "results : epoch 7 ; mean accuracy train : 67.22\n",
      "\n",
      "VALIDATION : Epoch 7\n",
      "togrep : results : epoch 7 ; mean accuracy valid :              70.34\n",
      "saving model at epoch 7\n",
      "\n",
      "TRAINING : Epoch 8\n",
      "Learning rate : 0.093206534790699\n",
      "<class 'torch.Tensor'> tensor(4438) 4438\n",
      "6336 ; loss 0.73 accuracy:69.34 ;\n",
      "<class 'torch.Tensor'> tensor(8873) 8873\n",
      "12736 ; loss 0.73 accuracy:69.32 ;\n",
      "<class 'torch.Tensor'> tensor(13246) 13246\n",
      "19136 ; loss 0.74 accuracy:68.99 ;\n",
      "<class 'torch.Tensor'> tensor(17635) 17635\n",
      "25536 ; loss 0.74 accuracy:68.89 ;\n",
      "<class 'torch.Tensor'> tensor(22031) 22031\n",
      "31936 ; loss 0.73 accuracy:68.85 ;\n",
      "<class 'torch.Tensor'> tensor(26440) 26440\n",
      "38336 ; loss 0.73 accuracy:68.85 ;\n",
      "<class 'torch.Tensor'> tensor(30845) 30845\n",
      "44736 ; loss 0.73 accuracy:68.85 ;\n",
      "<class 'torch.Tensor'> tensor(35312) 35312\n",
      "51136 ; loss 0.72 accuracy:68.97 ;\n",
      "<class 'torch.Tensor'> tensor(39737) 39737\n",
      "57536 ; loss 0.74 accuracy:68.99 ;\n",
      "<class 'torch.Tensor'> tensor(44129) 44129\n",
      "63936 ; loss 0.73 accuracy:68.95 ;\n",
      "<class 'torch.Tensor'> tensor(48560) 48560\n",
      "70336 ; loss 0.74 accuracy:68.98 ;\n",
      "<class 'torch.Tensor'> tensor(52936) 52936\n",
      "76736 ; loss 0.73 accuracy:68.93 ;\n",
      "<class 'torch.Tensor'> tensor(57332) 57332\n",
      "83136 ; loss 0.73 accuracy:68.91 ;\n",
      "<class 'torch.Tensor'> tensor(61783) 61783\n",
      "89536 ; loss 0.71 accuracy:68.95 ;\n",
      "<class 'torch.Tensor'> tensor(66257) 66257\n",
      "95936 ; loss 0.72 accuracy:69.02 ;\n",
      "<class 'torch.Tensor'> tensor(70629) 70629\n",
      "102336 ; loss 0.74 accuracy:68.97 ;\n",
      "<class 'torch.Tensor'> tensor(75098) 75098\n",
      "108736 ; loss 0.71 accuracy:69.02 ;\n",
      "<class 'torch.Tensor'> tensor(79592) 79592\n",
      "115136 ; loss 0.71 accuracy:69.09 ;\n",
      "<class 'torch.Tensor'> tensor(84038) 84038\n",
      "121536 ; loss 0.71 accuracy:69.11 ;\n",
      "<class 'torch.Tensor'> tensor(88513) 88513\n",
      "127936 ; loss 0.71 accuracy:69.15 ;\n",
      "<class 'torch.Tensor'> tensor(92984) 92984\n",
      "134336 ; loss 0.71 accuracy:69.18 ;\n",
      "<class 'torch.Tensor'> tensor(97464) 97464\n",
      "140736 ; loss 0.71 accuracy:69.22 ;\n",
      "<class 'torch.Tensor'> tensor(101862) 101862\n",
      "147136 ; loss 0.73 accuracy:69.2 ;\n",
      "<class 'torch.Tensor'> tensor(106324) 106324\n",
      "153536 ; loss 0.71 accuracy:69.22 ;\n",
      "<class 'torch.Tensor'> tensor(110827) 110827\n",
      "159936 ; loss 0.71 accuracy:69.27 ;\n",
      "<class 'torch.Tensor'> tensor(115299) 115299\n",
      "166336 ; loss 0.72 accuracy:69.29 ;\n",
      "<class 'torch.Tensor'> tensor(119775) 119775\n",
      "172736 ; loss 0.71 accuracy:69.31 ;\n",
      "<class 'torch.Tensor'> tensor(124255) 124255\n",
      "179136 ; loss 0.7 accuracy:69.34 ;\n",
      "<class 'torch.Tensor'> tensor(128733) 128733\n",
      "185536 ; loss 0.71 accuracy:69.36 ;\n",
      "<class 'torch.Tensor'> tensor(133205) 133205\n",
      "191936 ; loss 0.72 accuracy:69.38 ;\n",
      "<class 'torch.Tensor'> tensor(137654) 137654\n",
      "198336 ; loss 0.71 accuracy:69.38 ;\n",
      "<class 'torch.Tensor'> tensor(142098) 142098\n",
      "204736 ; loss 0.71 accuracy:69.38 ;\n",
      "<class 'torch.Tensor'> tensor(146551) 146551\n",
      "211136 ; loss 0.71 accuracy:69.39 ;\n",
      "<class 'torch.Tensor'> tensor(150981) 150981\n",
      "217536 ; loss 0.72 accuracy:69.38 ;\n",
      "<class 'torch.Tensor'> tensor(155444) 155444\n",
      "223936 ; loss 0.71 accuracy:69.39 ;\n",
      "<class 'torch.Tensor'> tensor(159929) 159929\n",
      "230336 ; loss 0.71 accuracy:69.41 ;\n",
      "<class 'torch.Tensor'> tensor(164380) 164380\n",
      "236736 ; loss 0.72 accuracy:69.42 ;\n",
      "<class 'torch.Tensor'> tensor(168850) 168850\n",
      "243136 ; loss 0.71 accuracy:69.43 ;\n",
      "<class 'torch.Tensor'> tensor(173322) 173322\n",
      "249536 ; loss 0.71 accuracy:69.44 ;\n",
      "<class 'torch.Tensor'> tensor(177821) 177821\n",
      "255936 ; loss 0.7 accuracy:69.46 ;\n",
      "<class 'torch.Tensor'> tensor(182340) 182340\n",
      "262336 ; loss 0.7 accuracy:69.49 ;\n",
      "<class 'torch.Tensor'> tensor(186829) 186829\n",
      "268736 ; loss 0.7 accuracy:69.5 ;\n",
      "<class 'torch.Tensor'> tensor(191333) 191333\n",
      "275136 ; loss 0.7 accuracy:69.53 ;\n",
      "<class 'torch.Tensor'> tensor(195826) 195826\n",
      "281536 ; loss 0.7 accuracy:69.54 ;\n",
      "<class 'torch.Tensor'> tensor(200301) 200301\n",
      "287936 ; loss 0.72 accuracy:69.55 ;\n",
      "<class 'torch.Tensor'> tensor(204792) 204792\n",
      "294336 ; loss 0.72 accuracy:69.56 ;\n",
      "<class 'torch.Tensor'> tensor(209253) 209253\n",
      "300736 ; loss 0.71 accuracy:69.57 ;\n",
      "<class 'torch.Tensor'> tensor(213756) 213756\n",
      "307136 ; loss 0.7 accuracy:69.58 ;\n",
      "<class 'torch.Tensor'> tensor(218258) 218258\n",
      "313536 ; loss 0.7 accuracy:69.6 ;\n",
      "<class 'torch.Tensor'> tensor(222695) 222695\n",
      "319936 ; loss 0.72 accuracy:69.59 ;\n",
      "<class 'torch.Tensor'> tensor(227165) 227165\n",
      "326336 ; loss 0.71 accuracy:69.6 ;\n",
      "<class 'torch.Tensor'> tensor(231609) 231609\n",
      "332736 ; loss 0.71 accuracy:69.59 ;\n",
      "<class 'torch.Tensor'> tensor(236090) 236090\n",
      "339136 ; loss 0.71 accuracy:69.6 ;\n",
      "<class 'torch.Tensor'> tensor(240595) 240595\n",
      "345536 ; loss 0.7 accuracy:69.62 ;\n",
      "<class 'torch.Tensor'> tensor(244984) 244984\n",
      "351936 ; loss 0.72 accuracy:69.6 ;\n",
      "<class 'torch.Tensor'> tensor(249514) 249514\n",
      "358336 ; loss 0.7 accuracy:69.62 ;\n",
      "<class 'torch.Tensor'> tensor(254026) 254026\n",
      "364736 ; loss 0.7 accuracy:69.63 ;\n",
      "<class 'torch.Tensor'> tensor(258530) 258530\n",
      "371136 ; loss 0.69 accuracy:69.65 ;\n",
      "<class 'torch.Tensor'> tensor(263041) 263041\n",
      "377536 ; loss 0.7 accuracy:69.66 ;\n",
      "<class 'torch.Tensor'> tensor(267587) 267587\n",
      "383936 ; loss 0.7 accuracy:69.68 ;\n",
      "<class 'torch.Tensor'> tensor(272162) 272162\n",
      "390336 ; loss 0.69 accuracy:69.71 ;\n",
      "<class 'torch.Tensor'> tensor(276606) 276606\n",
      "396736 ; loss 0.71 accuracy:69.71 ;\n",
      "<class 'torch.Tensor'> tensor(281095) 281095\n",
      "403136 ; loss 0.7 accuracy:69.72 ;\n",
      "<class 'torch.Tensor'> tensor(285633) 285633\n",
      "409536 ; loss 0.7 accuracy:69.73 ;\n",
      "<class 'torch.Tensor'> tensor(290189) 290189\n",
      "415936 ; loss 0.7 accuracy:69.76 ;\n",
      "<class 'torch.Tensor'> tensor(294646) 294646\n",
      "422336 ; loss 0.7 accuracy:69.76 ;\n",
      "<class 'torch.Tensor'> tensor(299179) 299179\n",
      "428736 ; loss 0.71 accuracy:69.77 ;\n",
      "<class 'torch.Tensor'> tensor(303693) 303693\n",
      "435136 ; loss 0.7 accuracy:69.78 ;\n",
      "<class 'torch.Tensor'> tensor(308243) 308243\n",
      "441536 ; loss 0.7 accuracy:69.8 ;\n",
      "<class 'torch.Tensor'> tensor(312726) 312726\n",
      "447936 ; loss 0.7 accuracy:69.8 ;\n",
      "<class 'torch.Tensor'> tensor(317226) 317226\n",
      "454336 ; loss 0.7 accuracy:69.81 ;\n",
      "<class 'torch.Tensor'> tensor(321722) 321722\n",
      "460736 ; loss 0.7 accuracy:69.82 ;\n",
      "<class 'torch.Tensor'> tensor(326234) 326234\n",
      "467136 ; loss 0.7 accuracy:69.83 ;\n",
      "<class 'torch.Tensor'> tensor(330712) 330712\n",
      "473536 ; loss 0.7 accuracy:69.83 ;\n",
      "<class 'torch.Tensor'> tensor(335257) 335257\n",
      "479936 ; loss 0.69 accuracy:69.85 ;\n",
      "<class 'torch.Tensor'> tensor(339751) 339751\n",
      "486336 ; loss 0.71 accuracy:69.85 ;\n",
      "<class 'torch.Tensor'> tensor(344232) 344232\n",
      "492736 ; loss 0.69 accuracy:69.85 ;\n",
      "<class 'torch.Tensor'> tensor(348787) 348787\n",
      "499136 ; loss 0.69 accuracy:69.87 ;\n",
      "<class 'torch.Tensor'> tensor(353289) 353289\n",
      "505536 ; loss 0.7 accuracy:69.88 ;\n",
      "<class 'torch.Tensor'> tensor(357846) 357846\n",
      "511936 ; loss 0.69 accuracy:69.89 ;\n",
      "<class 'torch.Tensor'> tensor(362412) 362412\n",
      "518336 ; loss 0.69 accuracy:69.91 ;\n",
      "<class 'torch.Tensor'> tensor(366938) 366938\n",
      "524736 ; loss 0.7 accuracy:69.92 ;\n",
      "<class 'torch.Tensor'> tensor(371616) 371616\n",
      "531136 ; loss 0.68 accuracy:69.96 ;\n",
      "<class 'torch.Tensor'> tensor(376203) 376203\n",
      "537536 ; loss 0.68 accuracy:69.98 ;\n",
      "<class 'torch.Tensor'> tensor(380790) 380790\n",
      "543936 ; loss 0.68 accuracy:70.0 ;\n",
      "results : epoch 8 ; mean accuracy train : 70.0\n",
      "\n",
      "VALIDATION : Epoch 8\n",
      "togrep : results : epoch 8 ; mean accuracy valid :              72.54\n",
      "saving model at epoch 8\n",
      "\n",
      "TRAINING : Epoch 9\n",
      "Learning rate : 0.09227446944279201\n",
      "<class 'torch.Tensor'> tensor(4601) 4601\n",
      "6336 ; loss 0.68 accuracy:71.89 ;\n",
      "<class 'torch.Tensor'> tensor(9141) 9141\n",
      "12736 ; loss 0.7 accuracy:71.41 ;\n",
      "<class 'torch.Tensor'> tensor(13729) 13729\n",
      "19136 ; loss 0.68 accuracy:71.51 ;\n",
      "<class 'torch.Tensor'> tensor(18296) 18296\n",
      "25536 ; loss 0.68 accuracy:71.47 ;\n",
      "<class 'torch.Tensor'> tensor(22865) 22865\n",
      "31936 ; loss 0.68 accuracy:71.45 ;\n",
      "<class 'torch.Tensor'> tensor(27419) 27419\n",
      "38336 ; loss 0.68 accuracy:71.4 ;\n",
      "<class 'torch.Tensor'> tensor(32016) 32016\n",
      "44736 ; loss 0.68 accuracy:71.46 ;\n",
      "<class 'torch.Tensor'> tensor(36577) 36577\n",
      "51136 ; loss 0.69 accuracy:71.44 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(41085) 41085\n",
      "57536 ; loss 0.69 accuracy:71.33 ;\n",
      "<class 'torch.Tensor'> tensor(45635) 45635\n",
      "63936 ; loss 0.68 accuracy:71.3 ;\n",
      "<class 'torch.Tensor'> tensor(50286) 50286\n",
      "70336 ; loss 0.68 accuracy:71.43 ;\n",
      "<class 'torch.Tensor'> tensor(54831) 54831\n",
      "76736 ; loss 0.69 accuracy:71.39 ;\n",
      "<class 'torch.Tensor'> tensor(59421) 59421\n",
      "83136 ; loss 0.69 accuracy:71.42 ;\n",
      "<class 'torch.Tensor'> tensor(64054) 64054\n",
      "89536 ; loss 0.67 accuracy:71.49 ;\n",
      "<class 'torch.Tensor'> tensor(68659) 68659\n",
      "95936 ; loss 0.68 accuracy:71.52 ;\n",
      "<class 'torch.Tensor'> tensor(73252) 73252\n",
      "102336 ; loss 0.68 accuracy:71.54 ;\n",
      "<class 'torch.Tensor'> tensor(77840) 77840\n",
      "108736 ; loss 0.68 accuracy:71.54 ;\n",
      "<class 'torch.Tensor'> tensor(82387) 82387\n",
      "115136 ; loss 0.68 accuracy:71.52 ;\n",
      "<class 'torch.Tensor'> tensor(86974) 86974\n",
      "121536 ; loss 0.68 accuracy:71.52 ;\n",
      "<class 'torch.Tensor'> tensor(91531) 91531\n",
      "127936 ; loss 0.68 accuracy:71.51 ;\n",
      "<class 'torch.Tensor'> tensor(96161) 96161\n",
      "134336 ; loss 0.68 accuracy:71.55 ;\n",
      "<class 'torch.Tensor'> tensor(100771) 100771\n",
      "140736 ; loss 0.67 accuracy:71.57 ;\n",
      "<class 'torch.Tensor'> tensor(105383) 105383\n",
      "147136 ; loss 0.67 accuracy:71.59 ;\n",
      "<class 'torch.Tensor'> tensor(109994) 109994\n",
      "153536 ; loss 0.67 accuracy:71.61 ;\n",
      "<class 'torch.Tensor'> tensor(114599) 114599\n",
      "159936 ; loss 0.68 accuracy:71.62 ;\n",
      "<class 'torch.Tensor'> tensor(119181) 119181\n",
      "166336 ; loss 0.67 accuracy:71.62 ;\n",
      "<class 'torch.Tensor'> tensor(123771) 123771\n",
      "172736 ; loss 0.67 accuracy:71.63 ;\n",
      "<class 'torch.Tensor'> tensor(128368) 128368\n",
      "179136 ; loss 0.67 accuracy:71.63 ;\n",
      "<class 'torch.Tensor'> tensor(132923) 132923\n",
      "185536 ; loss 0.68 accuracy:71.62 ;\n",
      "<class 'torch.Tensor'> tensor(137502) 137502\n",
      "191936 ; loss 0.68 accuracy:71.62 ;\n",
      "<class 'torch.Tensor'> tensor(142068) 142068\n",
      "198336 ; loss 0.69 accuracy:71.61 ;\n",
      "<class 'torch.Tensor'> tensor(146694) 146694\n",
      "204736 ; loss 0.67 accuracy:71.63 ;\n",
      "<class 'torch.Tensor'> tensor(151297) 151297\n",
      "211136 ; loss 0.67 accuracy:71.64 ;\n",
      "<class 'torch.Tensor'> tensor(155893) 155893\n",
      "217536 ; loss 0.68 accuracy:71.64 ;\n",
      "<class 'torch.Tensor'> tensor(160484) 160484\n",
      "223936 ; loss 0.68 accuracy:71.64 ;\n",
      "<class 'torch.Tensor'> tensor(165112) 165112\n",
      "230336 ; loss 0.67 accuracy:71.66 ;\n",
      "<class 'torch.Tensor'> tensor(169730) 169730\n",
      "236736 ; loss 0.67 accuracy:71.68 ;\n",
      "<class 'torch.Tensor'> tensor(174332) 174332\n",
      "243136 ; loss 0.67 accuracy:71.68 ;\n",
      "<class 'torch.Tensor'> tensor(178917) 178917\n",
      "249536 ; loss 0.68 accuracy:71.68 ;\n",
      "<class 'torch.Tensor'> tensor(183539) 183539\n",
      "255936 ; loss 0.66 accuracy:71.69 ;\n",
      "<class 'torch.Tensor'> tensor(188171) 188171\n",
      "262336 ; loss 0.67 accuracy:71.71 ;\n",
      "<class 'torch.Tensor'> tensor(192807) 192807\n",
      "268736 ; loss 0.67 accuracy:71.73 ;\n",
      "<class 'torch.Tensor'> tensor(197383) 197383\n",
      "275136 ; loss 0.68 accuracy:71.72 ;\n",
      "<class 'torch.Tensor'> tensor(201964) 201964\n",
      "281536 ; loss 0.67 accuracy:71.72 ;\n",
      "<class 'torch.Tensor'> tensor(206643) 206643\n",
      "287936 ; loss 0.65 accuracy:71.75 ;\n",
      "<class 'torch.Tensor'> tensor(211242) 211242\n",
      "294336 ; loss 0.68 accuracy:71.75 ;\n",
      "<class 'torch.Tensor'> tensor(215842) 215842\n",
      "300736 ; loss 0.68 accuracy:71.76 ;\n",
      "<class 'torch.Tensor'> tensor(220409) 220409\n",
      "307136 ; loss 0.67 accuracy:71.75 ;\n",
      "<class 'torch.Tensor'> tensor(225024) 225024\n",
      "313536 ; loss 0.66 accuracy:71.76 ;\n",
      "<class 'torch.Tensor'> tensor(229657) 229657\n",
      "319936 ; loss 0.67 accuracy:71.77 ;\n",
      "<class 'torch.Tensor'> tensor(234230) 234230\n",
      "326336 ; loss 0.68 accuracy:71.76 ;\n",
      "<class 'torch.Tensor'> tensor(238865) 238865\n",
      "332736 ; loss 0.67 accuracy:71.77 ;\n",
      "<class 'torch.Tensor'> tensor(243477) 243477\n",
      "339136 ; loss 0.68 accuracy:71.78 ;\n",
      "<class 'torch.Tensor'> tensor(248101) 248101\n",
      "345536 ; loss 0.66 accuracy:71.79 ;\n",
      "<class 'torch.Tensor'> tensor(252710) 252710\n",
      "351936 ; loss 0.66 accuracy:71.79 ;\n",
      "<class 'torch.Tensor'> tensor(257308) 257308\n",
      "358336 ; loss 0.67 accuracy:71.79 ;\n",
      "<class 'torch.Tensor'> tensor(261964) 261964\n",
      "364736 ; loss 0.66 accuracy:71.81 ;\n",
      "<class 'torch.Tensor'> tensor(266706) 266706\n",
      "371136 ; loss 0.64 accuracy:71.85 ;\n",
      "<class 'torch.Tensor'> tensor(271300) 271300\n",
      "377536 ; loss 0.66 accuracy:71.85 ;\n",
      "<class 'torch.Tensor'> tensor(275965) 275965\n",
      "383936 ; loss 0.66 accuracy:71.87 ;\n",
      "<class 'torch.Tensor'> tensor(280549) 280549\n",
      "390336 ; loss 0.66 accuracy:71.86 ;\n",
      "<class 'torch.Tensor'> tensor(285164) 285164\n",
      "396736 ; loss 0.67 accuracy:71.87 ;\n",
      "<class 'torch.Tensor'> tensor(289830) 289830\n",
      "403136 ; loss 0.66 accuracy:71.88 ;\n",
      "<class 'torch.Tensor'> tensor(294456) 294456\n",
      "409536 ; loss 0.66 accuracy:71.89 ;\n",
      "<class 'torch.Tensor'> tensor(299082) 299082\n",
      "415936 ; loss 0.66 accuracy:71.89 ;\n",
      "<class 'torch.Tensor'> tensor(303741) 303741\n",
      "422336 ; loss 0.66 accuracy:71.91 ;\n",
      "<class 'torch.Tensor'> tensor(308415) 308415\n",
      "428736 ; loss 0.65 accuracy:71.93 ;\n",
      "<class 'torch.Tensor'> tensor(313078) 313078\n",
      "435136 ; loss 0.66 accuracy:71.94 ;\n",
      "<class 'torch.Tensor'> tensor(317729) 317729\n",
      "441536 ; loss 0.65 accuracy:71.95 ;\n",
      "<class 'torch.Tensor'> tensor(322325) 322325\n",
      "447936 ; loss 0.68 accuracy:71.95 ;\n",
      "<class 'torch.Tensor'> tensor(326900) 326900\n",
      "454336 ; loss 0.67 accuracy:71.94 ;\n",
      "<class 'torch.Tensor'> tensor(331521) 331521\n",
      "460736 ; loss 0.66 accuracy:71.94 ;\n",
      "<class 'torch.Tensor'> tensor(336177) 336177\n",
      "467136 ; loss 0.66 accuracy:71.96 ;\n",
      "<class 'torch.Tensor'> tensor(340820) 340820\n",
      "473536 ; loss 0.66 accuracy:71.96 ;\n",
      "<class 'torch.Tensor'> tensor(345458) 345458\n",
      "479936 ; loss 0.66 accuracy:71.97 ;\n",
      "<class 'torch.Tensor'> tensor(350185) 350185\n",
      "486336 ; loss 0.64 accuracy:72.0 ;\n",
      "<class 'torch.Tensor'> tensor(354835) 354835\n",
      "492736 ; loss 0.66 accuracy:72.0 ;\n",
      "<class 'torch.Tensor'> tensor(359508) 359508\n",
      "499136 ; loss 0.65 accuracy:72.02 ;\n",
      "<class 'torch.Tensor'> tensor(364129) 364129\n",
      "505536 ; loss 0.66 accuracy:72.02 ;\n",
      "<class 'torch.Tensor'> tensor(368850) 368850\n",
      "511936 ; loss 0.65 accuracy:72.04 ;\n",
      "<class 'torch.Tensor'> tensor(373546) 373546\n",
      "518336 ; loss 0.65 accuracy:72.06 ;\n",
      "<class 'torch.Tensor'> tensor(378152) 378152\n",
      "524736 ; loss 0.67 accuracy:72.06 ;\n",
      "<class 'torch.Tensor'> tensor(382852) 382852\n",
      "531136 ; loss 0.65 accuracy:72.07 ;\n",
      "<class 'torch.Tensor'> tensor(387465) 387465\n",
      "537536 ; loss 0.67 accuracy:72.07 ;\n",
      "<class 'torch.Tensor'> tensor(392130) 392130\n",
      "543936 ; loss 0.65 accuracy:72.08 ;\n",
      "results : epoch 9 ; mean accuracy train : 72.1\n",
      "\n",
      "VALIDATION : Epoch 9\n",
      "togrep : results : epoch 9 ; mean accuracy valid :              73.95\n",
      "saving model at epoch 9\n",
      "\n",
      "TRAINING : Epoch 10\n",
      "Learning rate : 0.09135172474836409\n",
      "<class 'torch.Tensor'> tensor(4722) 4722\n",
      "6336 ; loss 0.64 accuracy:73.78 ;\n",
      "<class 'torch.Tensor'> tensor(9422) 9422\n",
      "12736 ; loss 0.64 accuracy:73.61 ;\n",
      "<class 'torch.Tensor'> tensor(14111) 14111\n",
      "19136 ; loss 0.65 accuracy:73.49 ;\n",
      "<class 'torch.Tensor'> tensor(18791) 18791\n",
      "25536 ; loss 0.66 accuracy:73.4 ;\n",
      "<class 'torch.Tensor'> tensor(23486) 23486\n",
      "31936 ; loss 0.65 accuracy:73.39 ;\n",
      "<class 'torch.Tensor'> tensor(28212) 28212\n",
      "38336 ; loss 0.64 accuracy:73.47 ;\n",
      "<class 'torch.Tensor'> tensor(32919) 32919\n",
      "44736 ; loss 0.64 accuracy:73.48 ;\n",
      "<class 'torch.Tensor'> tensor(37598) 37598\n",
      "51136 ; loss 0.65 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(42298) 42298\n",
      "57536 ; loss 0.65 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(46964) 46964\n",
      "63936 ; loss 0.64 accuracy:73.38 ;\n",
      "<class 'torch.Tensor'> tensor(51659) 51659\n",
      "70336 ; loss 0.65 accuracy:73.38 ;\n",
      "<class 'torch.Tensor'> tensor(56370) 56370\n",
      "76736 ; loss 0.64 accuracy:73.4 ;\n",
      "<class 'torch.Tensor'> tensor(61134) 61134\n",
      "83136 ; loss 0.63 accuracy:73.48 ;\n",
      "<class 'torch.Tensor'> tensor(65829) 65829\n",
      "89536 ; loss 0.64 accuracy:73.47 ;\n",
      "<class 'torch.Tensor'> tensor(70527) 70527\n",
      "95936 ; loss 0.64 accuracy:73.47 ;\n",
      "<class 'torch.Tensor'> tensor(75175) 75175\n",
      "102336 ; loss 0.66 accuracy:73.41 ;\n",
      "<class 'torch.Tensor'> tensor(79880) 79880\n",
      "108736 ; loss 0.64 accuracy:73.42 ;\n",
      "<class 'torch.Tensor'> tensor(84515) 84515\n",
      "115136 ; loss 0.66 accuracy:73.36 ;\n",
      "<class 'torch.Tensor'> tensor(89201) 89201\n",
      "121536 ; loss 0.66 accuracy:73.36 ;\n",
      "<class 'torch.Tensor'> tensor(93931) 93931\n",
      "127936 ; loss 0.64 accuracy:73.38 ;\n",
      "<class 'torch.Tensor'> tensor(98629) 98629\n",
      "134336 ; loss 0.65 accuracy:73.38 ;\n",
      "<class 'torch.Tensor'> tensor(103346) 103346\n",
      "140736 ; loss 0.65 accuracy:73.4 ;\n",
      "<class 'torch.Tensor'> tensor(108049) 108049\n",
      "147136 ; loss 0.64 accuracy:73.4 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(112716) 112716\n",
      "153536 ; loss 0.66 accuracy:73.38 ;\n",
      "<class 'torch.Tensor'> tensor(117453) 117453\n",
      "159936 ; loss 0.64 accuracy:73.41 ;\n",
      "<class 'torch.Tensor'> tensor(122154) 122154\n",
      "166336 ; loss 0.64 accuracy:73.41 ;\n",
      "<class 'torch.Tensor'> tensor(126901) 126901\n",
      "172736 ; loss 0.64 accuracy:73.44 ;\n",
      "<class 'torch.Tensor'> tensor(131578) 131578\n",
      "179136 ; loss 0.64 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(136165) 136165\n",
      "185536 ; loss 0.67 accuracy:73.36 ;\n",
      "<class 'torch.Tensor'> tensor(140882) 140882\n",
      "191936 ; loss 0.64 accuracy:73.38 ;\n",
      "<class 'torch.Tensor'> tensor(145629) 145629\n",
      "198336 ; loss 0.63 accuracy:73.4 ;\n",
      "<class 'torch.Tensor'> tensor(150312) 150312\n",
      "204736 ; loss 0.66 accuracy:73.39 ;\n",
      "<class 'torch.Tensor'> tensor(155023) 155023\n",
      "211136 ; loss 0.64 accuracy:73.4 ;\n",
      "<class 'torch.Tensor'> tensor(159783) 159783\n",
      "217536 ; loss 0.63 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(164480) 164480\n",
      "223936 ; loss 0.64 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(169132) 169132\n",
      "230336 ; loss 0.65 accuracy:73.41 ;\n",
      "<class 'torch.Tensor'> tensor(173888) 173888\n",
      "236736 ; loss 0.64 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(178593) 178593\n",
      "243136 ; loss 0.63 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(183269) 183269\n",
      "249536 ; loss 0.65 accuracy:73.43 ;\n",
      "<class 'torch.Tensor'> tensor(188018) 188018\n",
      "255936 ; loss 0.63 accuracy:73.44 ;\n",
      "<class 'torch.Tensor'> tensor(192733) 192733\n",
      "262336 ; loss 0.64 accuracy:73.45 ;\n",
      "<class 'torch.Tensor'> tensor(197462) 197462\n",
      "268736 ; loss 0.64 accuracy:73.46 ;\n",
      "<class 'torch.Tensor'> tensor(202200) 202200\n",
      "275136 ; loss 0.63 accuracy:73.47 ;\n",
      "<class 'torch.Tensor'> tensor(206909) 206909\n",
      "281536 ; loss 0.64 accuracy:73.48 ;\n",
      "<class 'torch.Tensor'> tensor(211696) 211696\n",
      "287936 ; loss 0.63 accuracy:73.51 ;\n",
      "<class 'torch.Tensor'> tensor(216456) 216456\n",
      "294336 ; loss 0.63 accuracy:73.52 ;\n",
      "<class 'torch.Tensor'> tensor(221150) 221150\n",
      "300736 ; loss 0.66 accuracy:73.52 ;\n",
      "<class 'torch.Tensor'> tensor(225921) 225921\n",
      "307136 ; loss 0.63 accuracy:73.54 ;\n",
      "<class 'torch.Tensor'> tensor(230574) 230574\n",
      "313536 ; loss 0.64 accuracy:73.52 ;\n",
      "<class 'torch.Tensor'> tensor(235342) 235342\n",
      "319936 ; loss 0.63 accuracy:73.54 ;\n",
      "<class 'torch.Tensor'> tensor(240038) 240038\n",
      "326336 ; loss 0.64 accuracy:73.54 ;\n",
      "<class 'torch.Tensor'> tensor(244852) 244852\n",
      "332736 ; loss 0.62 accuracy:73.57 ;\n",
      "<class 'torch.Tensor'> tensor(249664) 249664\n",
      "339136 ; loss 0.61 accuracy:73.6 ;\n",
      "<class 'torch.Tensor'> tensor(254371) 254371\n",
      "345536 ; loss 0.64 accuracy:73.6 ;\n",
      "<class 'torch.Tensor'> tensor(259067) 259067\n",
      "351936 ; loss 0.63 accuracy:73.6 ;\n",
      "<class 'torch.Tensor'> tensor(263762) 263762\n",
      "358336 ; loss 0.63 accuracy:73.59 ;\n",
      "<class 'torch.Tensor'> tensor(268518) 268518\n",
      "364736 ; loss 0.63 accuracy:73.61 ;\n",
      "<class 'torch.Tensor'> tensor(273234) 273234\n",
      "371136 ; loss 0.64 accuracy:73.61 ;\n",
      "<class 'torch.Tensor'> tensor(277972) 277972\n",
      "377536 ; loss 0.63 accuracy:73.62 ;\n",
      "<class 'torch.Tensor'> tensor(282728) 282728\n",
      "383936 ; loss 0.62 accuracy:73.63 ;\n",
      "<class 'torch.Tensor'> tensor(287426) 287426\n",
      "390336 ; loss 0.64 accuracy:73.62 ;\n",
      "<class 'torch.Tensor'> tensor(292205) 292205\n",
      "396736 ; loss 0.63 accuracy:73.64 ;\n",
      "<class 'torch.Tensor'> tensor(296925) 296925\n",
      "403136 ; loss 0.64 accuracy:73.64 ;\n",
      "<class 'torch.Tensor'> tensor(301706) 301706\n",
      "409536 ; loss 0.62 accuracy:73.66 ;\n",
      "<class 'torch.Tensor'> tensor(306477) 306477\n",
      "415936 ; loss 0.63 accuracy:73.67 ;\n",
      "<class 'torch.Tensor'> tensor(311231) 311231\n",
      "422336 ; loss 0.62 accuracy:73.68 ;\n",
      "<class 'torch.Tensor'> tensor(315994) 315994\n",
      "428736 ; loss 0.62 accuracy:73.69 ;\n",
      "<class 'torch.Tensor'> tensor(320708) 320708\n",
      "435136 ; loss 0.64 accuracy:73.69 ;\n",
      "<class 'torch.Tensor'> tensor(325454) 325454\n",
      "441536 ; loss 0.63 accuracy:73.7 ;\n",
      "<class 'torch.Tensor'> tensor(330236) 330236\n",
      "447936 ; loss 0.62 accuracy:73.71 ;\n",
      "<class 'torch.Tensor'> tensor(335020) 335020\n",
      "454336 ; loss 0.62 accuracy:73.73 ;\n",
      "<class 'torch.Tensor'> tensor(339764) 339764\n",
      "460736 ; loss 0.63 accuracy:73.73 ;\n",
      "<class 'torch.Tensor'> tensor(344523) 344523\n",
      "467136 ; loss 0.62 accuracy:73.74 ;\n",
      "<class 'torch.Tensor'> tensor(349233) 349233\n",
      "473536 ; loss 0.64 accuracy:73.74 ;\n",
      "<class 'torch.Tensor'> tensor(353985) 353985\n",
      "479936 ; loss 0.62 accuracy:73.75 ;\n",
      "<class 'torch.Tensor'> tensor(358793) 358793\n",
      "486336 ; loss 0.62 accuracy:73.77 ;\n",
      "<class 'torch.Tensor'> tensor(363478) 363478\n",
      "492736 ; loss 0.66 accuracy:73.76 ;\n",
      "<class 'torch.Tensor'> tensor(368246) 368246\n",
      "499136 ; loss 0.62 accuracy:73.77 ;\n",
      "<class 'torch.Tensor'> tensor(373061) 373061\n",
      "505536 ; loss 0.62 accuracy:73.79 ;\n",
      "<class 'torch.Tensor'> tensor(377843) 377843\n",
      "511936 ; loss 0.63 accuracy:73.8 ;\n",
      "<class 'torch.Tensor'> tensor(382594) 382594\n",
      "518336 ; loss 0.63 accuracy:73.8 ;\n",
      "<class 'torch.Tensor'> tensor(387343) 387343\n",
      "524736 ; loss 0.64 accuracy:73.81 ;\n",
      "<class 'torch.Tensor'> tensor(392094) 392094\n",
      "531136 ; loss 0.63 accuracy:73.81 ;\n",
      "<class 'torch.Tensor'> tensor(396867) 396867\n",
      "537536 ; loss 0.63 accuracy:73.82 ;\n",
      "<class 'torch.Tensor'> tensor(401648) 401648\n",
      "543936 ; loss 0.62 accuracy:73.83 ;\n",
      "results : epoch 10 ; mean accuracy train : 73.84\n",
      "\n",
      "VALIDATION : Epoch 10\n",
      "togrep : results : epoch 10 ; mean accuracy valid :              75.02\n",
      "saving model at epoch 10\n",
      "\n",
      "TRAINING : Epoch 11\n",
      "Learning rate : 0.09043820750088044\n",
      "<class 'torch.Tensor'> tensor(4782) 4782\n",
      "6336 ; loss 0.62 accuracy:74.72 ;\n",
      "<class 'torch.Tensor'> tensor(9565) 9565\n",
      "12736 ; loss 0.62 accuracy:74.73 ;\n",
      "<class 'torch.Tensor'> tensor(14353) 14353\n",
      "19136 ; loss 0.62 accuracy:74.76 ;\n",
      "<class 'torch.Tensor'> tensor(19164) 19164\n",
      "25536 ; loss 0.62 accuracy:74.86 ;\n",
      "<class 'torch.Tensor'> tensor(23955) 23955\n",
      "31936 ; loss 0.61 accuracy:74.86 ;\n",
      "<class 'torch.Tensor'> tensor(28759) 28759\n",
      "38336 ; loss 0.62 accuracy:74.89 ;\n",
      "<class 'torch.Tensor'> tensor(33541) 33541\n",
      "44736 ; loss 0.62 accuracy:74.87 ;\n",
      "<class 'torch.Tensor'> tensor(38352) 38352\n",
      "51136 ; loss 0.61 accuracy:74.91 ;\n",
      "<class 'torch.Tensor'> tensor(43140) 43140\n",
      "57536 ; loss 0.62 accuracy:74.9 ;\n",
      "<class 'torch.Tensor'> tensor(47892) 47892\n",
      "63936 ; loss 0.62 accuracy:74.83 ;\n",
      "<class 'torch.Tensor'> tensor(52700) 52700\n",
      "70336 ; loss 0.61 accuracy:74.86 ;\n",
      "<class 'torch.Tensor'> tensor(57428) 57428\n",
      "76736 ; loss 0.63 accuracy:74.78 ;\n",
      "<class 'torch.Tensor'> tensor(62222) 62222\n",
      "83136 ; loss 0.61 accuracy:74.79 ;\n",
      "<class 'torch.Tensor'> tensor(67025) 67025\n",
      "89536 ; loss 0.61 accuracy:74.8 ;\n",
      "<class 'torch.Tensor'> tensor(71826) 71826\n",
      "95936 ; loss 0.61 accuracy:74.82 ;\n",
      "<class 'torch.Tensor'> tensor(76628) 76628\n",
      "102336 ; loss 0.61 accuracy:74.83 ;\n",
      "<class 'torch.Tensor'> tensor(81436) 81436\n",
      "108736 ; loss 0.62 accuracy:74.85 ;\n",
      "<class 'torch.Tensor'> tensor(86218) 86218\n",
      "115136 ; loss 0.62 accuracy:74.84 ;\n",
      "<class 'torch.Tensor'> tensor(90952) 90952\n",
      "121536 ; loss 0.63 accuracy:74.8 ;\n",
      "<class 'torch.Tensor'> tensor(95793) 95793\n",
      "127936 ; loss 0.6 accuracy:74.84 ;\n",
      "<class 'torch.Tensor'> tensor(100639) 100639\n",
      "134336 ; loss 0.61 accuracy:74.88 ;\n",
      "<class 'torch.Tensor'> tensor(105380) 105380\n",
      "140736 ; loss 0.63 accuracy:74.84 ;\n",
      "<class 'torch.Tensor'> tensor(110200) 110200\n",
      "147136 ; loss 0.61 accuracy:74.86 ;\n",
      "<class 'torch.Tensor'> tensor(114959) 114959\n",
      "153536 ; loss 0.62 accuracy:74.84 ;\n",
      "<class 'torch.Tensor'> tensor(119728) 119728\n",
      "159936 ; loss 0.62 accuracy:74.83 ;\n",
      "<class 'torch.Tensor'> tensor(124593) 124593\n",
      "166336 ; loss 0.6 accuracy:74.88 ;\n",
      "<class 'torch.Tensor'> tensor(129409) 129409\n",
      "172736 ; loss 0.6 accuracy:74.89 ;\n",
      "<class 'torch.Tensor'> tensor(134200) 134200\n",
      "179136 ; loss 0.6 accuracy:74.89 ;\n",
      "<class 'torch.Tensor'> tensor(138978) 138978\n",
      "185536 ; loss 0.62 accuracy:74.88 ;\n",
      "<class 'torch.Tensor'> tensor(143802) 143802\n",
      "191936 ; loss 0.61 accuracy:74.9 ;\n",
      "<class 'torch.Tensor'> tensor(148633) 148633\n",
      "198336 ; loss 0.6 accuracy:74.92 ;\n",
      "<class 'torch.Tensor'> tensor(153461) 153461\n",
      "204736 ; loss 0.6 accuracy:74.93 ;\n",
      "<class 'torch.Tensor'> tensor(158240) 158240\n",
      "211136 ; loss 0.61 accuracy:74.92 ;\n",
      "<class 'torch.Tensor'> tensor(163049) 163049\n",
      "217536 ; loss 0.6 accuracy:74.93 ;\n",
      "<class 'torch.Tensor'> tensor(167820) 167820\n",
      "223936 ; loss 0.62 accuracy:74.92 ;\n",
      "<class 'torch.Tensor'> tensor(172638) 172638\n",
      "230336 ; loss 0.61 accuracy:74.93 ;\n",
      "<class 'torch.Tensor'> tensor(177409) 177409\n",
      "236736 ; loss 0.62 accuracy:74.92 ;\n",
      "<class 'torch.Tensor'> tensor(182198) 182198\n",
      "243136 ; loss 0.61 accuracy:74.92 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(187029) 187029\n",
      "249536 ; loss 0.6 accuracy:74.93 ;\n",
      "<class 'torch.Tensor'> tensor(191841) 191841\n",
      "255936 ; loss 0.61 accuracy:74.94 ;\n",
      "<class 'torch.Tensor'> tensor(196665) 196665\n",
      "262336 ; loss 0.61 accuracy:74.95 ;\n",
      "<class 'torch.Tensor'> tensor(201463) 201463\n",
      "268736 ; loss 0.61 accuracy:74.95 ;\n",
      "<class 'torch.Tensor'> tensor(206289) 206289\n",
      "275136 ; loss 0.61 accuracy:74.96 ;\n",
      "<class 'torch.Tensor'> tensor(211100) 211100\n",
      "281536 ; loss 0.6 accuracy:74.96 ;\n",
      "<class 'torch.Tensor'> tensor(215912) 215912\n",
      "287936 ; loss 0.6 accuracy:74.97 ;\n",
      "<class 'torch.Tensor'> tensor(220749) 220749\n",
      "294336 ; loss 0.61 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(225548) 225548\n",
      "300736 ; loss 0.61 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(230305) 230305\n",
      "307136 ; loss 0.63 accuracy:74.97 ;\n",
      "<class 'torch.Tensor'> tensor(235144) 235144\n",
      "313536 ; loss 0.6 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(239932) 239932\n",
      "319936 ; loss 0.61 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(244737) 244737\n",
      "326336 ; loss 0.62 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(249540) 249540\n",
      "332736 ; loss 0.61 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(254367) 254367\n",
      "339136 ; loss 0.61 accuracy:74.99 ;\n",
      "<class 'torch.Tensor'> tensor(259144) 259144\n",
      "345536 ; loss 0.62 accuracy:74.98 ;\n",
      "<class 'torch.Tensor'> tensor(264002) 264002\n",
      "351936 ; loss 0.6 accuracy:75.0 ;\n",
      "<class 'torch.Tensor'> tensor(268807) 268807\n",
      "358336 ; loss 0.61 accuracy:75.0 ;\n",
      "<class 'torch.Tensor'> tensor(273638) 273638\n",
      "364736 ; loss 0.6 accuracy:75.01 ;\n",
      "<class 'torch.Tensor'> tensor(278545) 278545\n",
      "371136 ; loss 0.6 accuracy:75.04 ;\n",
      "<class 'torch.Tensor'> tensor(283313) 283313\n",
      "377536 ; loss 0.62 accuracy:75.03 ;\n",
      "<class 'torch.Tensor'> tensor(288139) 288139\n",
      "383936 ; loss 0.6 accuracy:75.04 ;\n",
      "<class 'torch.Tensor'> tensor(292950) 292950\n",
      "390336 ; loss 0.61 accuracy:75.04 ;\n",
      "<class 'torch.Tensor'> tensor(297778) 297778\n",
      "396736 ; loss 0.61 accuracy:75.04 ;\n",
      "<class 'torch.Tensor'> tensor(302618) 302618\n",
      "403136 ; loss 0.6 accuracy:75.05 ;\n",
      "<class 'torch.Tensor'> tensor(307464) 307464\n",
      "409536 ; loss 0.61 accuracy:75.06 ;\n",
      "<class 'torch.Tensor'> tensor(312312) 312312\n",
      "415936 ; loss 0.6 accuracy:75.08 ;\n",
      "<class 'torch.Tensor'> tensor(317124) 317124\n",
      "422336 ; loss 0.61 accuracy:75.08 ;\n",
      "<class 'torch.Tensor'> tensor(321927) 321927\n",
      "428736 ; loss 0.61 accuracy:75.08 ;\n",
      "<class 'torch.Tensor'> tensor(326775) 326775\n",
      "435136 ; loss 0.59 accuracy:75.09 ;\n",
      "<class 'torch.Tensor'> tensor(331600) 331600\n",
      "441536 ; loss 0.61 accuracy:75.09 ;\n",
      "<class 'torch.Tensor'> tensor(336457) 336457\n",
      "447936 ; loss 0.6 accuracy:75.1 ;\n",
      "<class 'torch.Tensor'> tensor(341346) 341346\n",
      "454336 ; loss 0.59 accuracy:75.12 ;\n",
      "<class 'torch.Tensor'> tensor(346194) 346194\n",
      "460736 ; loss 0.6 accuracy:75.13 ;\n",
      "<class 'torch.Tensor'> tensor(351009) 351009\n",
      "467136 ; loss 0.61 accuracy:75.13 ;\n",
      "<class 'torch.Tensor'> tensor(355864) 355864\n",
      "473536 ; loss 0.6 accuracy:75.14 ;\n",
      "<class 'torch.Tensor'> tensor(360758) 360758\n",
      "479936 ; loss 0.58 accuracy:75.16 ;\n",
      "<class 'torch.Tensor'> tensor(365575) 365575\n",
      "486336 ; loss 0.61 accuracy:75.16 ;\n",
      "<class 'torch.Tensor'> tensor(370385) 370385\n",
      "492736 ; loss 0.61 accuracy:75.16 ;\n",
      "<class 'torch.Tensor'> tensor(375214) 375214\n",
      "499136 ; loss 0.59 accuracy:75.16 ;\n",
      "<class 'torch.Tensor'> tensor(380019) 380019\n",
      "505536 ; loss 0.61 accuracy:75.16 ;\n",
      "<class 'torch.Tensor'> tensor(384852) 384852\n",
      "511936 ; loss 0.6 accuracy:75.17 ;\n",
      "<class 'torch.Tensor'> tensor(389734) 389734\n",
      "518336 ; loss 0.59 accuracy:75.18 ;\n",
      "<class 'torch.Tensor'> tensor(394555) 394555\n",
      "524736 ; loss 0.61 accuracy:75.18 ;\n",
      "<class 'torch.Tensor'> tensor(399397) 399397\n",
      "531136 ; loss 0.6 accuracy:75.19 ;\n",
      "<class 'torch.Tensor'> tensor(404274) 404274\n",
      "537536 ; loss 0.6 accuracy:75.2 ;\n",
      "<class 'torch.Tensor'> tensor(409095) 409095\n",
      "543936 ; loss 0.6 accuracy:75.2 ;\n",
      "results : epoch 11 ; mean accuracy train : 75.21\n",
      "\n",
      "VALIDATION : Epoch 11\n",
      "togrep : results : epoch 11 ; mean accuracy valid :              76.97\n",
      "saving model at epoch 11\n",
      "\n",
      "TRAINING : Epoch 12\n",
      "Learning rate : 0.08953382542587164\n",
      "<class 'torch.Tensor'> tensor(4843) 4843\n",
      "6336 ; loss 0.6 accuracy:75.67 ;\n",
      "<class 'torch.Tensor'> tensor(9753) 9753\n",
      "12736 ; loss 0.58 accuracy:76.2 ;\n",
      "<class 'torch.Tensor'> tensor(14599) 14599\n",
      "19136 ; loss 0.59 accuracy:76.04 ;\n",
      "<class 'torch.Tensor'> tensor(19456) 19456\n",
      "25536 ; loss 0.59 accuracy:76.0 ;\n",
      "<class 'torch.Tensor'> tensor(24336) 24336\n",
      "31936 ; loss 0.59 accuracy:76.05 ;\n",
      "<class 'torch.Tensor'> tensor(29196) 29196\n",
      "38336 ; loss 0.6 accuracy:76.03 ;\n",
      "<class 'torch.Tensor'> tensor(34099) 34099\n",
      "44736 ; loss 0.59 accuracy:76.11 ;\n",
      "<class 'torch.Tensor'> tensor(38995) 38995\n",
      "51136 ; loss 0.58 accuracy:76.16 ;\n",
      "<class 'torch.Tensor'> tensor(43904) 43904\n",
      "57536 ; loss 0.58 accuracy:76.22 ;\n",
      "<class 'torch.Tensor'> tensor(48767) 48767\n",
      "63936 ; loss 0.6 accuracy:76.2 ;\n",
      "<class 'torch.Tensor'> tensor(53675) 53675\n",
      "70336 ; loss 0.58 accuracy:76.24 ;\n",
      "<class 'torch.Tensor'> tensor(58489) 58489\n",
      "76736 ; loss 0.6 accuracy:76.16 ;\n",
      "<class 'torch.Tensor'> tensor(63377) 63377\n",
      "83136 ; loss 0.59 accuracy:76.17 ;\n",
      "<class 'torch.Tensor'> tensor(68332) 68332\n",
      "89536 ; loss 0.58 accuracy:76.26 ;\n",
      "<class 'torch.Tensor'> tensor(73192) 73192\n",
      "95936 ; loss 0.6 accuracy:76.24 ;\n",
      "<class 'torch.Tensor'> tensor(78038) 78038\n",
      "102336 ; loss 0.61 accuracy:76.21 ;\n",
      "<class 'torch.Tensor'> tensor(82962) 82962\n",
      "108736 ; loss 0.58 accuracy:76.25 ;\n",
      "<class 'torch.Tensor'> tensor(87866) 87866\n",
      "115136 ; loss 0.58 accuracy:76.27 ;\n",
      "<class 'torch.Tensor'> tensor(92696) 92696\n",
      "121536 ; loss 0.6 accuracy:76.23 ;\n",
      "<class 'torch.Tensor'> tensor(97552) 97552\n",
      "127936 ; loss 0.58 accuracy:76.21 ;\n",
      "<class 'torch.Tensor'> tensor(102411) 102411\n",
      "134336 ; loss 0.59 accuracy:76.2 ;\n",
      "<class 'torch.Tensor'> tensor(107239) 107239\n",
      "140736 ; loss 0.59 accuracy:76.16 ;\n",
      "<class 'torch.Tensor'> tensor(112136) 112136\n",
      "147136 ; loss 0.58 accuracy:76.18 ;\n",
      "<class 'torch.Tensor'> tensor(117014) 117014\n",
      "153536 ; loss 0.59 accuracy:76.18 ;\n",
      "<class 'torch.Tensor'> tensor(121864) 121864\n",
      "159936 ; loss 0.6 accuracy:76.17 ;\n",
      "<class 'torch.Tensor'> tensor(126735) 126735\n",
      "166336 ; loss 0.6 accuracy:76.16 ;\n",
      "<class 'torch.Tensor'> tensor(131524) 131524\n",
      "172736 ; loss 0.6 accuracy:76.11 ;\n",
      "<class 'torch.Tensor'> tensor(136375) 136375\n",
      "179136 ; loss 0.6 accuracy:76.1 ;\n",
      "<class 'torch.Tensor'> tensor(141273) 141273\n",
      "185536 ; loss 0.58 accuracy:76.12 ;\n",
      "<class 'torch.Tensor'> tensor(146227) 146227\n",
      "191936 ; loss 0.58 accuracy:76.16 ;\n",
      "<class 'torch.Tensor'> tensor(151124) 151124\n",
      "198336 ; loss 0.58 accuracy:76.17 ;\n",
      "<class 'torch.Tensor'> tensor(156006) 156006\n",
      "204736 ; loss 0.58 accuracy:76.17 ;\n",
      "<class 'torch.Tensor'> tensor(160904) 160904\n",
      "211136 ; loss 0.58 accuracy:76.19 ;\n",
      "<class 'torch.Tensor'> tensor(165802) 165802\n",
      "217536 ; loss 0.59 accuracy:76.2 ;\n",
      "<class 'torch.Tensor'> tensor(170673) 170673\n",
      "223936 ; loss 0.59 accuracy:76.19 ;\n",
      "<class 'torch.Tensor'> tensor(175533) 175533\n",
      "230336 ; loss 0.6 accuracy:76.19 ;\n",
      "<class 'torch.Tensor'> tensor(180451) 180451\n",
      "236736 ; loss 0.58 accuracy:76.2 ;\n",
      "<class 'torch.Tensor'> tensor(185352) 185352\n",
      "243136 ; loss 0.59 accuracy:76.21 ;\n",
      "<class 'torch.Tensor'> tensor(190249) 190249\n",
      "249536 ; loss 0.58 accuracy:76.22 ;\n",
      "<class 'torch.Tensor'> tensor(195084) 195084\n",
      "255936 ; loss 0.6 accuracy:76.2 ;\n",
      "<class 'torch.Tensor'> tensor(200019) 200019\n",
      "262336 ; loss 0.57 accuracy:76.23 ;\n",
      "<class 'torch.Tensor'> tensor(204963) 204963\n",
      "268736 ; loss 0.57 accuracy:76.25 ;\n",
      "<class 'torch.Tensor'> tensor(209899) 209899\n",
      "275136 ; loss 0.57 accuracy:76.27 ;\n",
      "<class 'torch.Tensor'> tensor(214827) 214827\n",
      "281536 ; loss 0.58 accuracy:76.29 ;\n",
      "<class 'torch.Tensor'> tensor(219754) 219754\n",
      "287936 ; loss 0.57 accuracy:76.3 ;\n",
      "<class 'torch.Tensor'> tensor(224658) 224658\n",
      "294336 ; loss 0.58 accuracy:76.31 ;\n",
      "<class 'torch.Tensor'> tensor(229558) 229558\n",
      "300736 ; loss 0.57 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(234439) 234439\n",
      "307136 ; loss 0.59 accuracy:76.31 ;\n",
      "<class 'torch.Tensor'> tensor(239276) 239276\n",
      "313536 ; loss 0.59 accuracy:76.3 ;\n",
      "<class 'torch.Tensor'> tensor(244090) 244090\n",
      "319936 ; loss 0.59 accuracy:76.28 ;\n",
      "<class 'torch.Tensor'> tensor(248925) 248925\n",
      "326336 ; loss 0.59 accuracy:76.26 ;\n",
      "<class 'torch.Tensor'> tensor(253804) 253804\n",
      "332736 ; loss 0.58 accuracy:76.26 ;\n",
      "<class 'torch.Tensor'> tensor(258667) 258667\n",
      "339136 ; loss 0.59 accuracy:76.26 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(263549) 263549\n",
      "345536 ; loss 0.59 accuracy:76.26 ;\n",
      "<class 'torch.Tensor'> tensor(268477) 268477\n",
      "351936 ; loss 0.58 accuracy:76.27 ;\n",
      "<class 'torch.Tensor'> tensor(273332) 273332\n",
      "358336 ; loss 0.58 accuracy:76.26 ;\n",
      "<class 'torch.Tensor'> tensor(278250) 278250\n",
      "364736 ; loss 0.59 accuracy:76.27 ;\n",
      "<class 'torch.Tensor'> tensor(283156) 283156\n",
      "371136 ; loss 0.59 accuracy:76.28 ;\n",
      "<class 'torch.Tensor'> tensor(288021) 288021\n",
      "377536 ; loss 0.59 accuracy:76.28 ;\n",
      "<class 'torch.Tensor'> tensor(292918) 292918\n",
      "383936 ; loss 0.58 accuracy:76.28 ;\n",
      "<class 'torch.Tensor'> tensor(297799) 297799\n",
      "390336 ; loss 0.59 accuracy:76.28 ;\n",
      "<class 'torch.Tensor'> tensor(302668) 302668\n",
      "396736 ; loss 0.58 accuracy:76.28 ;\n",
      "<class 'torch.Tensor'> tensor(307621) 307621\n",
      "403136 ; loss 0.57 accuracy:76.29 ;\n",
      "<class 'torch.Tensor'> tensor(312598) 312598\n",
      "409536 ; loss 0.56 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(317474) 317474\n",
      "415936 ; loss 0.59 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(322385) 322385\n",
      "422336 ; loss 0.57 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(327271) 327271\n",
      "428736 ; loss 0.58 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(332160) 332160\n",
      "435136 ; loss 0.59 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(337081) 337081\n",
      "441536 ; loss 0.58 accuracy:76.33 ;\n",
      "<class 'torch.Tensor'> tensor(341977) 341977\n",
      "447936 ; loss 0.58 accuracy:76.33 ;\n",
      "<class 'torch.Tensor'> tensor(346811) 346811\n",
      "454336 ; loss 0.59 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(351662) 351662\n",
      "460736 ; loss 0.6 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(356577) 356577\n",
      "467136 ; loss 0.57 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(361440) 361440\n",
      "473536 ; loss 0.58 accuracy:76.32 ;\n",
      "<class 'torch.Tensor'> tensor(366400) 366400\n",
      "479936 ; loss 0.56 accuracy:76.33 ;\n",
      "<class 'torch.Tensor'> tensor(371343) 371343\n",
      "486336 ; loss 0.57 accuracy:76.35 ;\n",
      "<class 'torch.Tensor'> tensor(376186) 376186\n",
      "492736 ; loss 0.6 accuracy:76.34 ;\n",
      "<class 'torch.Tensor'> tensor(381114) 381114\n",
      "499136 ; loss 0.58 accuracy:76.34 ;\n",
      "<class 'torch.Tensor'> tensor(386028) 386028\n",
      "505536 ; loss 0.58 accuracy:76.35 ;\n",
      "<class 'torch.Tensor'> tensor(390909) 390909\n",
      "511936 ; loss 0.58 accuracy:76.35 ;\n",
      "<class 'torch.Tensor'> tensor(395822) 395822\n",
      "518336 ; loss 0.59 accuracy:76.35 ;\n",
      "<class 'torch.Tensor'> tensor(400783) 400783\n",
      "524736 ; loss 0.56 accuracy:76.37 ;\n",
      "<class 'torch.Tensor'> tensor(405695) 405695\n",
      "531136 ; loss 0.58 accuracy:76.37 ;\n",
      "<class 'torch.Tensor'> tensor(410598) 410598\n",
      "537536 ; loss 0.57 accuracy:76.38 ;\n",
      "<class 'torch.Tensor'> tensor(415509) 415509\n",
      "543936 ; loss 0.57 accuracy:76.38 ;\n",
      "results : epoch 12 ; mean accuracy train : 76.38\n",
      "\n",
      "VALIDATION : Epoch 12\n",
      "togrep : results : epoch 12 ; mean accuracy valid :              77.48\n",
      "saving model at epoch 12\n",
      "\n",
      "TRAINING : Epoch 13\n",
      "Learning rate : 0.08863848717161292\n",
      "<class 'torch.Tensor'> tensor(4943) 4943\n",
      "6336 ; loss 0.57 accuracy:77.23 ;\n",
      "<class 'torch.Tensor'> tensor(9854) 9854\n",
      "12736 ; loss 0.59 accuracy:76.98 ;\n",
      "<class 'torch.Tensor'> tensor(14812) 14812\n",
      "19136 ; loss 0.57 accuracy:77.15 ;\n",
      "<class 'torch.Tensor'> tensor(19702) 19702\n",
      "25536 ; loss 0.58 accuracy:76.96 ;\n",
      "<class 'torch.Tensor'> tensor(24663) 24663\n",
      "31936 ; loss 0.56 accuracy:77.07 ;\n",
      "<class 'torch.Tensor'> tensor(29614) 29614\n",
      "38336 ; loss 0.56 accuracy:77.12 ;\n",
      "<class 'torch.Tensor'> tensor(34524) 34524\n",
      "44736 ; loss 0.57 accuracy:77.06 ;\n",
      "<class 'torch.Tensor'> tensor(39469) 39469\n",
      "51136 ; loss 0.56 accuracy:77.09 ;\n",
      "<class 'torch.Tensor'> tensor(44415) 44415\n",
      "57536 ; loss 0.57 accuracy:77.11 ;\n",
      "<class 'torch.Tensor'> tensor(49368) 49368\n",
      "63936 ; loss 0.56 accuracy:77.14 ;\n",
      "<class 'torch.Tensor'> tensor(54354) 54354\n",
      "70336 ; loss 0.55 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(59274) 59274\n",
      "76736 ; loss 0.57 accuracy:77.18 ;\n",
      "<class 'torch.Tensor'> tensor(64239) 64239\n",
      "83136 ; loss 0.57 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(69144) 69144\n",
      "89536 ; loss 0.57 accuracy:77.17 ;\n",
      "<class 'torch.Tensor'> tensor(74084) 74084\n",
      "95936 ; loss 0.58 accuracy:77.17 ;\n",
      "<class 'torch.Tensor'> tensor(79021) 79021\n",
      "102336 ; loss 0.57 accuracy:77.17 ;\n",
      "<class 'torch.Tensor'> tensor(83985) 83985\n",
      "108736 ; loss 0.57 accuracy:77.19 ;\n",
      "<class 'torch.Tensor'> tensor(88849) 88849\n",
      "115136 ; loss 0.58 accuracy:77.13 ;\n",
      "<class 'torch.Tensor'> tensor(93725) 93725\n",
      "121536 ; loss 0.58 accuracy:77.08 ;\n",
      "<class 'torch.Tensor'> tensor(98687) 98687\n",
      "127936 ; loss 0.56 accuracy:77.1 ;\n",
      "<class 'torch.Tensor'> tensor(103665) 103665\n",
      "134336 ; loss 0.56 accuracy:77.13 ;\n",
      "<class 'torch.Tensor'> tensor(108598) 108598\n",
      "140736 ; loss 0.57 accuracy:77.13 ;\n",
      "<class 'torch.Tensor'> tensor(113629) 113629\n",
      "147136 ; loss 0.54 accuracy:77.19 ;\n",
      "<class 'torch.Tensor'> tensor(118600) 118600\n",
      "153536 ; loss 0.57 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(123511) 123511\n",
      "159936 ; loss 0.58 accuracy:77.19 ;\n",
      "<class 'torch.Tensor'> tensor(128464) 128464\n",
      "166336 ; loss 0.56 accuracy:77.2 ;\n",
      "<class 'torch.Tensor'> tensor(133392) 133392\n",
      "172736 ; loss 0.57 accuracy:77.19 ;\n",
      "<class 'torch.Tensor'> tensor(138344) 138344\n",
      "179136 ; loss 0.56 accuracy:77.2 ;\n",
      "<class 'torch.Tensor'> tensor(143321) 143321\n",
      "185536 ; loss 0.56 accuracy:77.22 ;\n",
      "<class 'torch.Tensor'> tensor(148291) 148291\n",
      "191936 ; loss 0.56 accuracy:77.23 ;\n",
      "<class 'torch.Tensor'> tensor(153204) 153204\n",
      "198336 ; loss 0.56 accuracy:77.22 ;\n",
      "<class 'torch.Tensor'> tensor(158119) 158119\n",
      "204736 ; loss 0.58 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(163088) 163088\n",
      "211136 ; loss 0.56 accuracy:77.22 ;\n",
      "<class 'torch.Tensor'> tensor(168043) 168043\n",
      "217536 ; loss 0.56 accuracy:77.23 ;\n",
      "<class 'torch.Tensor'> tensor(172952) 172952\n",
      "223936 ; loss 0.58 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(177861) 177861\n",
      "230336 ; loss 0.59 accuracy:77.2 ;\n",
      "<class 'torch.Tensor'> tensor(182818) 182818\n",
      "236736 ; loss 0.57 accuracy:77.2 ;\n",
      "<class 'torch.Tensor'> tensor(187743) 187743\n",
      "243136 ; loss 0.57 accuracy:77.2 ;\n",
      "<class 'torch.Tensor'> tensor(192718) 192718\n",
      "249536 ; loss 0.56 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(197686) 197686\n",
      "255936 ; loss 0.55 accuracy:77.22 ;\n",
      "<class 'torch.Tensor'> tensor(202593) 202593\n",
      "262336 ; loss 0.57 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(207547) 207547\n",
      "268736 ; loss 0.56 accuracy:77.21 ;\n",
      "<class 'torch.Tensor'> tensor(212533) 212533\n",
      "275136 ; loss 0.55 accuracy:77.23 ;\n",
      "<class 'torch.Tensor'> tensor(217504) 217504\n",
      "281536 ; loss 0.55 accuracy:77.24 ;\n",
      "<class 'torch.Tensor'> tensor(222415) 222415\n",
      "287936 ; loss 0.56 accuracy:77.23 ;\n",
      "<class 'torch.Tensor'> tensor(227410) 227410\n",
      "294336 ; loss 0.56 accuracy:77.25 ;\n",
      "<class 'torch.Tensor'> tensor(232374) 232374\n",
      "300736 ; loss 0.57 accuracy:77.25 ;\n",
      "<class 'torch.Tensor'> tensor(237323) 237323\n",
      "307136 ; loss 0.56 accuracy:77.25 ;\n",
      "<class 'torch.Tensor'> tensor(242347) 242347\n",
      "313536 ; loss 0.55 accuracy:77.28 ;\n",
      "<class 'torch.Tensor'> tensor(247316) 247316\n",
      "319936 ; loss 0.56 accuracy:77.29 ;\n",
      "<class 'torch.Tensor'> tensor(252257) 252257\n",
      "326336 ; loss 0.57 accuracy:77.28 ;\n",
      "<class 'torch.Tensor'> tensor(257263) 257263\n",
      "332736 ; loss 0.56 accuracy:77.3 ;\n",
      "<class 'torch.Tensor'> tensor(262217) 262217\n",
      "339136 ; loss 0.55 accuracy:77.3 ;\n",
      "<class 'torch.Tensor'> tensor(267171) 267171\n",
      "345536 ; loss 0.56 accuracy:77.31 ;\n",
      "<class 'torch.Tensor'> tensor(272112) 272112\n",
      "351936 ; loss 0.58 accuracy:77.3 ;\n",
      "<class 'torch.Tensor'> tensor(277068) 277068\n",
      "358336 ; loss 0.56 accuracy:77.31 ;\n",
      "<class 'torch.Tensor'> tensor(282079) 282079\n",
      "364736 ; loss 0.55 accuracy:77.32 ;\n",
      "<class 'torch.Tensor'> tensor(287073) 287073\n",
      "371136 ; loss 0.56 accuracy:77.34 ;\n",
      "<class 'torch.Tensor'> tensor(291961) 291961\n",
      "377536 ; loss 0.57 accuracy:77.32 ;\n",
      "<class 'torch.Tensor'> tensor(296927) 296927\n",
      "383936 ; loss 0.56 accuracy:77.32 ;\n",
      "<class 'torch.Tensor'> tensor(301879) 301879\n",
      "390336 ; loss 0.56 accuracy:77.33 ;\n",
      "<class 'torch.Tensor'> tensor(306820) 306820\n",
      "396736 ; loss 0.57 accuracy:77.32 ;\n",
      "<class 'torch.Tensor'> tensor(311776) 311776\n",
      "403136 ; loss 0.56 accuracy:77.33 ;\n",
      "<class 'torch.Tensor'> tensor(316679) 316679\n",
      "409536 ; loss 0.57 accuracy:77.31 ;\n",
      "<class 'torch.Tensor'> tensor(321663) 321663\n",
      "415936 ; loss 0.55 accuracy:77.32 ;\n",
      "<class 'torch.Tensor'> tensor(326646) 326646\n",
      "422336 ; loss 0.56 accuracy:77.33 ;\n",
      "<class 'torch.Tensor'> tensor(331605) 331605\n",
      "428736 ; loss 0.56 accuracy:77.33 ;\n",
      "<class 'torch.Tensor'> tensor(336576) 336576\n",
      "435136 ; loss 0.56 accuracy:77.34 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(341592) 341592\n",
      "441536 ; loss 0.55 accuracy:77.35 ;\n",
      "<class 'torch.Tensor'> tensor(346565) 346565\n",
      "447936 ; loss 0.56 accuracy:77.36 ;\n",
      "<class 'torch.Tensor'> tensor(351515) 351515\n",
      "454336 ; loss 0.56 accuracy:77.36 ;\n",
      "<class 'torch.Tensor'> tensor(356419) 356419\n",
      "460736 ; loss 0.58 accuracy:77.35 ;\n",
      "<class 'torch.Tensor'> tensor(361399) 361399\n",
      "467136 ; loss 0.57 accuracy:77.35 ;\n",
      "<class 'torch.Tensor'> tensor(366265) 366265\n",
      "473536 ; loss 0.58 accuracy:77.34 ;\n",
      "<class 'torch.Tensor'> tensor(371252) 371252\n",
      "479936 ; loss 0.54 accuracy:77.34 ;\n",
      "<class 'torch.Tensor'> tensor(376231) 376231\n",
      "486336 ; loss 0.56 accuracy:77.35 ;\n",
      "<class 'torch.Tensor'> tensor(381227) 381227\n",
      "492736 ; loss 0.56 accuracy:77.36 ;\n",
      "<class 'torch.Tensor'> tensor(386171) 386171\n",
      "499136 ; loss 0.57 accuracy:77.36 ;\n",
      "<class 'torch.Tensor'> tensor(391142) 391142\n",
      "505536 ; loss 0.55 accuracy:77.36 ;\n",
      "<class 'torch.Tensor'> tensor(396132) 396132\n",
      "511936 ; loss 0.56 accuracy:77.37 ;\n",
      "<class 'torch.Tensor'> tensor(401121) 401121\n",
      "518336 ; loss 0.56 accuracy:77.38 ;\n",
      "<class 'torch.Tensor'> tensor(406102) 406102\n",
      "524736 ; loss 0.55 accuracy:77.38 ;\n",
      "<class 'torch.Tensor'> tensor(411081) 411081\n",
      "531136 ; loss 0.55 accuracy:77.39 ;\n",
      "<class 'torch.Tensor'> tensor(416055) 416055\n",
      "537536 ; loss 0.55 accuracy:77.39 ;\n",
      "<class 'torch.Tensor'> tensor(421058) 421058\n",
      "543936 ; loss 0.55 accuracy:77.4 ;\n",
      "results : epoch 13 ; mean accuracy train : 77.4\n",
      "\n",
      "VALIDATION : Epoch 13\n",
      "togrep : results : epoch 13 ; mean accuracy valid :              78.25\n",
      "saving model at epoch 13\n",
      "\n",
      "TRAINING : Epoch 14\n",
      "Learning rate : 0.08775210229989679\n",
      "<class 'torch.Tensor'> tensor(5000) 5000\n",
      "6336 ; loss 0.55 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(9981) 9981\n",
      "12736 ; loss 0.56 accuracy:77.98 ;\n",
      "<class 'torch.Tensor'> tensor(15022) 15022\n",
      "19136 ; loss 0.54 accuracy:78.24 ;\n",
      "<class 'torch.Tensor'> tensor(20055) 20055\n",
      "25536 ; loss 0.54 accuracy:78.34 ;\n",
      "<class 'torch.Tensor'> tensor(25032) 25032\n",
      "31936 ; loss 0.55 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(29998) 29998\n",
      "38336 ; loss 0.57 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(34974) 34974\n",
      "44736 ; loss 0.56 accuracy:78.07 ;\n",
      "<class 'torch.Tensor'> tensor(39969) 39969\n",
      "51136 ; loss 0.55 accuracy:78.06 ;\n",
      "<class 'torch.Tensor'> tensor(44907) 44907\n",
      "57536 ; loss 0.56 accuracy:77.96 ;\n",
      "<class 'torch.Tensor'> tensor(49936) 49936\n",
      "63936 ; loss 0.54 accuracy:78.03 ;\n",
      "<class 'torch.Tensor'> tensor(54919) 54919\n",
      "70336 ; loss 0.55 accuracy:78.01 ;\n",
      "<class 'torch.Tensor'> tensor(59900) 59900\n",
      "76736 ; loss 0.55 accuracy:77.99 ;\n",
      "<class 'torch.Tensor'> tensor(64863) 64863\n",
      "83136 ; loss 0.57 accuracy:77.96 ;\n",
      "<class 'torch.Tensor'> tensor(69898) 69898\n",
      "89536 ; loss 0.54 accuracy:78.01 ;\n",
      "<class 'torch.Tensor'> tensor(74914) 74914\n",
      "95936 ; loss 0.54 accuracy:78.04 ;\n",
      "<class 'torch.Tensor'> tensor(79934) 79934\n",
      "102336 ; loss 0.55 accuracy:78.06 ;\n",
      "<class 'torch.Tensor'> tensor(84988) 84988\n",
      "108736 ; loss 0.53 accuracy:78.11 ;\n",
      "<class 'torch.Tensor'> tensor(90006) 90006\n",
      "115136 ; loss 0.54 accuracy:78.13 ;\n",
      "<class 'torch.Tensor'> tensor(95038) 95038\n",
      "121536 ; loss 0.54 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(100042) 100042\n",
      "127936 ; loss 0.54 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(104995) 104995\n",
      "134336 ; loss 0.56 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(109934) 109934\n",
      "140736 ; loss 0.56 accuracy:78.08 ;\n",
      "<class 'torch.Tensor'> tensor(114988) 114988\n",
      "147136 ; loss 0.54 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(119992) 119992\n",
      "153536 ; loss 0.55 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(124988) 124988\n",
      "159936 ; loss 0.54 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(129992) 129992\n",
      "166336 ; loss 0.55 accuracy:78.12 ;\n",
      "<class 'torch.Tensor'> tensor(135040) 135040\n",
      "172736 ; loss 0.53 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(140086) 140086\n",
      "179136 ; loss 0.54 accuracy:78.17 ;\n",
      "<class 'torch.Tensor'> tensor(145141) 145141\n",
      "185536 ; loss 0.53 accuracy:78.2 ;\n",
      "<class 'torch.Tensor'> tensor(150144) 150144\n",
      "191936 ; loss 0.55 accuracy:78.2 ;\n",
      "<class 'torch.Tensor'> tensor(155178) 155178\n",
      "198336 ; loss 0.54 accuracy:78.21 ;\n",
      "<class 'torch.Tensor'> tensor(160136) 160136\n",
      "204736 ; loss 0.55 accuracy:78.19 ;\n",
      "<class 'torch.Tensor'> tensor(165124) 165124\n",
      "211136 ; loss 0.55 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(170082) 170082\n",
      "217536 ; loss 0.56 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(175067) 175067\n",
      "223936 ; loss 0.56 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(180077) 180077\n",
      "230336 ; loss 0.53 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(185082) 185082\n",
      "236736 ; loss 0.55 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(190106) 190106\n",
      "243136 ; loss 0.54 accuracy:78.17 ;\n",
      "<class 'torch.Tensor'> tensor(195097) 195097\n",
      "249536 ; loss 0.55 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(200143) 200143\n",
      "255936 ; loss 0.53 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(205122) 205122\n",
      "262336 ; loss 0.56 accuracy:78.17 ;\n",
      "<class 'torch.Tensor'> tensor(210151) 210151\n",
      "268736 ; loss 0.54 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(215140) 215140\n",
      "275136 ; loss 0.55 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(220097) 220097\n",
      "281536 ; loss 0.56 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(225152) 225152\n",
      "287936 ; loss 0.53 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(230175) 230175\n",
      "294336 ; loss 0.54 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(235149) 235149\n",
      "300736 ; loss 0.55 accuracy:78.17 ;\n",
      "<class 'torch.Tensor'> tensor(240106) 240106\n",
      "307136 ; loss 0.56 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(245071) 245071\n",
      "313536 ; loss 0.56 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(250089) 250089\n",
      "319936 ; loss 0.53 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(255087) 255087\n",
      "326336 ; loss 0.55 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(260090) 260090\n",
      "332736 ; loss 0.54 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(265111) 265111\n",
      "339136 ; loss 0.54 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(270093) 270093\n",
      "345536 ; loss 0.56 accuracy:78.15 ;\n",
      "<class 'torch.Tensor'> tensor(275117) 275117\n",
      "351936 ; loss 0.54 accuracy:78.16 ;\n",
      "<class 'torch.Tensor'> tensor(280167) 280167\n",
      "358336 ; loss 0.53 accuracy:78.17 ;\n",
      "<class 'torch.Tensor'> tensor(285207) 285207\n",
      "364736 ; loss 0.55 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(290225) 290225\n",
      "371136 ; loss 0.56 accuracy:78.19 ;\n",
      "<class 'torch.Tensor'> tensor(295193) 295193\n",
      "377536 ; loss 0.55 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(300207) 300207\n",
      "383936 ; loss 0.55 accuracy:78.18 ;\n",
      "<class 'torch.Tensor'> tensor(305264) 305264\n",
      "390336 ; loss 0.54 accuracy:78.19 ;\n",
      "<class 'torch.Tensor'> tensor(310267) 310267\n",
      "396736 ; loss 0.55 accuracy:78.19 ;\n",
      "<class 'torch.Tensor'> tensor(315277) 315277\n",
      "403136 ; loss 0.54 accuracy:78.19 ;\n",
      "<class 'torch.Tensor'> tensor(320294) 320294\n",
      "409536 ; loss 0.54 accuracy:78.2 ;\n",
      "<class 'torch.Tensor'> tensor(325344) 325344\n",
      "415936 ; loss 0.53 accuracy:78.21 ;\n",
      "<class 'torch.Tensor'> tensor(330364) 330364\n",
      "422336 ; loss 0.55 accuracy:78.21 ;\n",
      "<class 'torch.Tensor'> tensor(335404) 335404\n",
      "428736 ; loss 0.54 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(340352) 340352\n",
      "435136 ; loss 0.56 accuracy:78.21 ;\n",
      "<class 'torch.Tensor'> tensor(345370) 345370\n",
      "441536 ; loss 0.54 accuracy:78.21 ;\n",
      "<class 'torch.Tensor'> tensor(350376) 350376\n",
      "447936 ; loss 0.55 accuracy:78.21 ;\n",
      "<class 'torch.Tensor'> tensor(355424) 355424\n",
      "454336 ; loss 0.54 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(360451) 360451\n",
      "460736 ; loss 0.54 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(365460) 365460\n",
      "467136 ; loss 0.54 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(370466) 370466\n",
      "473536 ; loss 0.55 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(375465) 375465\n",
      "479936 ; loss 0.55 accuracy:78.22 ;\n",
      "<class 'torch.Tensor'> tensor(380506) 380506\n",
      "486336 ; loss 0.53 accuracy:78.23 ;\n",
      "<class 'torch.Tensor'> tensor(385526) 385526\n",
      "492736 ; loss 0.53 accuracy:78.23 ;\n",
      "<class 'torch.Tensor'> tensor(390512) 390512\n",
      "499136 ; loss 0.54 accuracy:78.23 ;\n",
      "<class 'torch.Tensor'> tensor(395557) 395557\n",
      "505536 ; loss 0.54 accuracy:78.24 ;\n",
      "<class 'torch.Tensor'> tensor(400542) 400542\n",
      "511936 ; loss 0.55 accuracy:78.23 ;\n",
      "<class 'torch.Tensor'> tensor(405578) 405578\n",
      "518336 ; loss 0.53 accuracy:78.24 ;\n",
      "<class 'torch.Tensor'> tensor(410607) 410607\n",
      "524736 ; loss 0.55 accuracy:78.24 ;\n",
      "<class 'torch.Tensor'> tensor(415684) 415684\n",
      "531136 ; loss 0.54 accuracy:78.25 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(420717) 420717\n",
      "537536 ; loss 0.53 accuracy:78.26 ;\n",
      "<class 'torch.Tensor'> tensor(425723) 425723\n",
      "543936 ; loss 0.55 accuracy:78.26 ;\n",
      "results : epoch 14 ; mean accuracy train : 78.26\n",
      "\n",
      "VALIDATION : Epoch 14\n",
      "togrep : results : epoch 14 ; mean accuracy valid :              79.31\n",
      "saving model at epoch 14\n",
      "\n",
      "TRAINING : Epoch 15\n",
      "Learning rate : 0.08687458127689782\n",
      "<class 'torch.Tensor'> tensor(5050) 5050\n",
      "6336 ; loss 0.52 accuracy:78.91 ;\n",
      "<class 'torch.Tensor'> tensor(10073) 10073\n",
      "12736 ; loss 0.54 accuracy:78.7 ;\n",
      "<class 'torch.Tensor'> tensor(15156) 15156\n",
      "19136 ; loss 0.53 accuracy:78.94 ;\n",
      "<class 'torch.Tensor'> tensor(20222) 20222\n",
      "25536 ; loss 0.53 accuracy:78.99 ;\n",
      "<class 'torch.Tensor'> tensor(25229) 25229\n",
      "31936 ; loss 0.54 accuracy:78.84 ;\n",
      "<class 'torch.Tensor'> tensor(30279) 30279\n",
      "38336 ; loss 0.54 accuracy:78.85 ;\n",
      "<class 'torch.Tensor'> tensor(35343) 35343\n",
      "44736 ; loss 0.52 accuracy:78.89 ;\n",
      "<class 'torch.Tensor'> tensor(40359) 40359\n",
      "51136 ; loss 0.53 accuracy:78.83 ;\n",
      "<class 'torch.Tensor'> tensor(45438) 45438\n",
      "57536 ; loss 0.52 accuracy:78.89 ;\n",
      "<class 'torch.Tensor'> tensor(50460) 50460\n",
      "63936 ; loss 0.54 accuracy:78.84 ;\n",
      "<class 'torch.Tensor'> tensor(55489) 55489\n",
      "70336 ; loss 0.54 accuracy:78.82 ;\n",
      "<class 'torch.Tensor'> tensor(60531) 60531\n",
      "76736 ; loss 0.54 accuracy:78.82 ;\n",
      "<class 'torch.Tensor'> tensor(65535) 65535\n",
      "83136 ; loss 0.53 accuracy:78.77 ;\n",
      "<class 'torch.Tensor'> tensor(70594) 70594\n",
      "89536 ; loss 0.52 accuracy:78.79 ;\n",
      "<class 'torch.Tensor'> tensor(75588) 75588\n",
      "95936 ; loss 0.54 accuracy:78.74 ;\n",
      "<class 'torch.Tensor'> tensor(80657) 80657\n",
      "102336 ; loss 0.53 accuracy:78.77 ;\n",
      "<class 'torch.Tensor'> tensor(85736) 85736\n",
      "108736 ; loss 0.52 accuracy:78.8 ;\n",
      "<class 'torch.Tensor'> tensor(90782) 90782\n",
      "115136 ; loss 0.53 accuracy:78.8 ;\n",
      "<class 'torch.Tensor'> tensor(95837) 95837\n",
      "121536 ; loss 0.53 accuracy:78.81 ;\n",
      "<class 'torch.Tensor'> tensor(100856) 100856\n",
      "127936 ; loss 0.53 accuracy:78.79 ;\n",
      "<class 'torch.Tensor'> tensor(105895) 105895\n",
      "134336 ; loss 0.53 accuracy:78.79 ;\n",
      "<class 'torch.Tensor'> tensor(110944) 110944\n",
      "140736 ; loss 0.53 accuracy:78.8 ;\n",
      "<class 'torch.Tensor'> tensor(116034) 116034\n",
      "147136 ; loss 0.52 accuracy:78.83 ;\n",
      "<class 'torch.Tensor'> tensor(121076) 121076\n",
      "153536 ; loss 0.53 accuracy:78.83 ;\n",
      "<class 'torch.Tensor'> tensor(126135) 126135\n",
      "159936 ; loss 0.53 accuracy:78.83 ;\n",
      "<class 'torch.Tensor'> tensor(131243) 131243\n",
      "166336 ; loss 0.52 accuracy:78.87 ;\n",
      "<class 'torch.Tensor'> tensor(136298) 136298\n",
      "172736 ; loss 0.53 accuracy:78.88 ;\n",
      "<class 'torch.Tensor'> tensor(141377) 141377\n",
      "179136 ; loss 0.53 accuracy:78.89 ;\n",
      "<class 'torch.Tensor'> tensor(146449) 146449\n",
      "185536 ; loss 0.52 accuracy:78.91 ;\n",
      "<class 'torch.Tensor'> tensor(151494) 151494\n",
      "191936 ; loss 0.54 accuracy:78.9 ;\n",
      "<class 'torch.Tensor'> tensor(156530) 156530\n",
      "198336 ; loss 0.54 accuracy:78.9 ;\n",
      "<class 'torch.Tensor'> tensor(161548) 161548\n",
      "204736 ; loss 0.55 accuracy:78.88 ;\n",
      "<class 'torch.Tensor'> tensor(166586) 166586\n",
      "211136 ; loss 0.54 accuracy:78.88 ;\n",
      "<class 'torch.Tensor'> tensor(171632) 171632\n",
      "217536 ; loss 0.52 accuracy:78.88 ;\n",
      "<class 'torch.Tensor'> tensor(176649) 176649\n",
      "223936 ; loss 0.53 accuracy:78.86 ;\n",
      "<class 'torch.Tensor'> tensor(181656) 181656\n",
      "230336 ; loss 0.53 accuracy:78.84 ;\n",
      "<class 'torch.Tensor'> tensor(186803) 186803\n",
      "236736 ; loss 0.51 accuracy:78.89 ;\n",
      "<class 'torch.Tensor'> tensor(191807) 191807\n",
      "243136 ; loss 0.55 accuracy:78.87 ;\n",
      "<class 'torch.Tensor'> tensor(196872) 196872\n",
      "249536 ; loss 0.52 accuracy:78.88 ;\n",
      "<class 'torch.Tensor'> tensor(201903) 201903\n",
      "255936 ; loss 0.54 accuracy:78.87 ;\n",
      "<class 'torch.Tensor'> tensor(206922) 206922\n",
      "262336 ; loss 0.55 accuracy:78.86 ;\n",
      "<class 'torch.Tensor'> tensor(212061) 212061\n",
      "268736 ; loss 0.51 accuracy:78.89 ;\n",
      "<class 'torch.Tensor'> tensor(217128) 217128\n",
      "275136 ; loss 0.53 accuracy:78.9 ;\n",
      "<class 'torch.Tensor'> tensor(222189) 222189\n",
      "281536 ; loss 0.53 accuracy:78.9 ;\n",
      "<class 'torch.Tensor'> tensor(227232) 227232\n",
      "287936 ; loss 0.53 accuracy:78.9 ;\n",
      "<class 'torch.Tensor'> tensor(232334) 232334\n",
      "294336 ; loss 0.52 accuracy:78.92 ;\n",
      "<class 'torch.Tensor'> tensor(237350) 237350\n",
      "300736 ; loss 0.54 accuracy:78.91 ;\n",
      "<class 'torch.Tensor'> tensor(242454) 242454\n",
      "307136 ; loss 0.52 accuracy:78.92 ;\n",
      "<class 'torch.Tensor'> tensor(247536) 247536\n",
      "313536 ; loss 0.52 accuracy:78.93 ;\n",
      "<class 'torch.Tensor'> tensor(252645) 252645\n",
      "319936 ; loss 0.51 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(257721) 257721\n",
      "326336 ; loss 0.53 accuracy:78.96 ;\n",
      "<class 'torch.Tensor'> tensor(262797) 262797\n",
      "332736 ; loss 0.52 accuracy:78.97 ;\n",
      "<class 'torch.Tensor'> tensor(267875) 267875\n",
      "339136 ; loss 0.52 accuracy:78.97 ;\n",
      "<class 'torch.Tensor'> tensor(272894) 272894\n",
      "345536 ; loss 0.54 accuracy:78.96 ;\n",
      "<class 'torch.Tensor'> tensor(277911) 277911\n",
      "351936 ; loss 0.54 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(282967) 282967\n",
      "358336 ; loss 0.53 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(288013) 288013\n",
      "364736 ; loss 0.54 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(293074) 293074\n",
      "371136 ; loss 0.53 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(298111) 298111\n",
      "377536 ; loss 0.53 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(303183) 303183\n",
      "383936 ; loss 0.53 accuracy:78.95 ;\n",
      "<class 'torch.Tensor'> tensor(308281) 308281\n",
      "390336 ; loss 0.52 accuracy:78.97 ;\n",
      "<class 'torch.Tensor'> tensor(313325) 313325\n",
      "396736 ; loss 0.53 accuracy:78.96 ;\n",
      "<class 'torch.Tensor'> tensor(318422) 318422\n",
      "403136 ; loss 0.52 accuracy:78.97 ;\n",
      "<class 'torch.Tensor'> tensor(323500) 323500\n",
      "409536 ; loss 0.52 accuracy:78.98 ;\n",
      "<class 'torch.Tensor'> tensor(328529) 328529\n",
      "415936 ; loss 0.55 accuracy:78.97 ;\n",
      "<class 'torch.Tensor'> tensor(333600) 333600\n",
      "422336 ; loss 0.53 accuracy:78.98 ;\n",
      "<class 'torch.Tensor'> tensor(338619) 338619\n",
      "428736 ; loss 0.53 accuracy:78.97 ;\n",
      "<class 'torch.Tensor'> tensor(343740) 343740\n",
      "435136 ; loss 0.52 accuracy:78.98 ;\n",
      "<class 'torch.Tensor'> tensor(348843) 348843\n",
      "441536 ; loss 0.52 accuracy:79.0 ;\n",
      "<class 'torch.Tensor'> tensor(353879) 353879\n",
      "447936 ; loss 0.53 accuracy:78.99 ;\n",
      "<class 'torch.Tensor'> tensor(358975) 358975\n",
      "454336 ; loss 0.52 accuracy:79.0 ;\n",
      "<class 'torch.Tensor'> tensor(364069) 364069\n",
      "460736 ; loss 0.52 accuracy:79.01 ;\n",
      "<class 'torch.Tensor'> tensor(369118) 369118\n",
      "467136 ; loss 0.53 accuracy:79.01 ;\n",
      "<class 'torch.Tensor'> tensor(374211) 374211\n",
      "473536 ; loss 0.52 accuracy:79.01 ;\n",
      "<class 'torch.Tensor'> tensor(379295) 379295\n",
      "479936 ; loss 0.52 accuracy:79.02 ;\n",
      "<class 'torch.Tensor'> tensor(384424) 384424\n",
      "486336 ; loss 0.52 accuracy:79.03 ;\n",
      "<class 'torch.Tensor'> tensor(389478) 389478\n",
      "492736 ; loss 0.53 accuracy:79.03 ;\n",
      "<class 'torch.Tensor'> tensor(394520) 394520\n",
      "499136 ; loss 0.52 accuracy:79.03 ;\n",
      "<class 'torch.Tensor'> tensor(399566) 399566\n",
      "505536 ; loss 0.53 accuracy:79.03 ;\n",
      "<class 'torch.Tensor'> tensor(404608) 404608\n",
      "511936 ; loss 0.53 accuracy:79.03 ;\n",
      "<class 'torch.Tensor'> tensor(409617) 409617\n",
      "518336 ; loss 0.54 accuracy:79.02 ;\n",
      "<class 'torch.Tensor'> tensor(414703) 414703\n",
      "524736 ; loss 0.53 accuracy:79.02 ;\n",
      "<class 'torch.Tensor'> tensor(419840) 419840\n",
      "531136 ; loss 0.51 accuracy:79.04 ;\n",
      "<class 'torch.Tensor'> tensor(424904) 424904\n",
      "537536 ; loss 0.53 accuracy:79.04 ;\n",
      "<class 'torch.Tensor'> tensor(430028) 430028\n",
      "543936 ; loss 0.52 accuracy:79.05 ;\n",
      "results : epoch 15 ; mean accuracy train : 79.05\n",
      "\n",
      "VALIDATION : Epoch 15\n",
      "togrep : results : epoch 15 ; mean accuracy valid :              79.98\n",
      "saving model at epoch 15\n",
      "\n",
      "TRAINING : Epoch 16\n",
      "Learning rate : 0.08600583546412884\n",
      "<class 'torch.Tensor'> tensor(5082) 5082\n",
      "6336 ; loss 0.52 accuracy:79.41 ;\n",
      "<class 'torch.Tensor'> tensor(10177) 10177\n",
      "12736 ; loss 0.51 accuracy:79.51 ;\n",
      "<class 'torch.Tensor'> tensor(15235) 15235\n",
      "19136 ; loss 0.52 accuracy:79.35 ;\n",
      "<class 'torch.Tensor'> tensor(20281) 20281\n",
      "25536 ; loss 0.53 accuracy:79.22 ;\n",
      "<class 'torch.Tensor'> tensor(25400) 25400\n",
      "31936 ; loss 0.51 accuracy:79.38 ;\n",
      "<class 'torch.Tensor'> tensor(30482) 30482\n",
      "38336 ; loss 0.52 accuracy:79.38 ;\n",
      "<class 'torch.Tensor'> tensor(35586) 35586\n",
      "44736 ; loss 0.52 accuracy:79.43 ;\n",
      "<class 'torch.Tensor'> tensor(40719) 40719\n",
      "51136 ; loss 0.52 accuracy:79.53 ;\n",
      "<class 'torch.Tensor'> tensor(45831) 45831\n",
      "57536 ; loss 0.51 accuracy:79.57 ;\n",
      "<class 'torch.Tensor'> tensor(50935) 50935\n",
      "63936 ; loss 0.52 accuracy:79.59 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(55995) 55995\n",
      "70336 ; loss 0.52 accuracy:79.54 ;\n",
      "<class 'torch.Tensor'> tensor(61098) 61098\n",
      "76736 ; loss 0.51 accuracy:79.55 ;\n",
      "<class 'torch.Tensor'> tensor(66209) 66209\n",
      "83136 ; loss 0.51 accuracy:79.58 ;\n",
      "<class 'torch.Tensor'> tensor(71314) 71314\n",
      "89536 ; loss 0.51 accuracy:79.59 ;\n",
      "<class 'torch.Tensor'> tensor(76436) 76436\n",
      "95936 ; loss 0.51 accuracy:79.62 ;\n",
      "<class 'torch.Tensor'> tensor(81539) 81539\n",
      "102336 ; loss 0.52 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(86642) 86642\n",
      "108736 ; loss 0.52 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(91735) 91735\n",
      "115136 ; loss 0.52 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(96822) 96822\n",
      "121536 ; loss 0.52 accuracy:79.62 ;\n",
      "<class 'torch.Tensor'> tensor(101915) 101915\n",
      "127936 ; loss 0.51 accuracy:79.62 ;\n",
      "<class 'torch.Tensor'> tensor(107006) 107006\n",
      "134336 ; loss 0.52 accuracy:79.62 ;\n",
      "<class 'torch.Tensor'> tensor(112092) 112092\n",
      "140736 ; loss 0.51 accuracy:79.61 ;\n",
      "<class 'torch.Tensor'> tensor(117219) 117219\n",
      "147136 ; loss 0.51 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(122338) 122338\n",
      "153536 ; loss 0.51 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(127437) 127437\n",
      "159936 ; loss 0.51 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(132470) 132470\n",
      "166336 ; loss 0.52 accuracy:79.61 ;\n",
      "<class 'torch.Tensor'> tensor(137511) 137511\n",
      "172736 ; loss 0.52 accuracy:79.58 ;\n",
      "<class 'torch.Tensor'> tensor(142641) 142641\n",
      "179136 ; loss 0.5 accuracy:79.6 ;\n",
      "<class 'torch.Tensor'> tensor(147684) 147684\n",
      "185536 ; loss 0.53 accuracy:79.57 ;\n",
      "<class 'torch.Tensor'> tensor(152768) 152768\n",
      "191936 ; loss 0.52 accuracy:79.57 ;\n",
      "<class 'torch.Tensor'> tensor(157907) 157907\n",
      "198336 ; loss 0.5 accuracy:79.59 ;\n",
      "<class 'torch.Tensor'> tensor(163013) 163013\n",
      "204736 ; loss 0.52 accuracy:79.6 ;\n",
      "<class 'torch.Tensor'> tensor(168102) 168102\n",
      "211136 ; loss 0.52 accuracy:79.59 ;\n",
      "<class 'torch.Tensor'> tensor(173219) 173219\n",
      "217536 ; loss 0.51 accuracy:79.6 ;\n",
      "<class 'torch.Tensor'> tensor(178311) 178311\n",
      "223936 ; loss 0.52 accuracy:79.6 ;\n",
      "<class 'torch.Tensor'> tensor(183446) 183446\n",
      "230336 ; loss 0.52 accuracy:79.62 ;\n",
      "<class 'torch.Tensor'> tensor(188570) 188570\n",
      "236736 ; loss 0.51 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(193655) 193655\n",
      "243136 ; loss 0.52 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(198784) 198784\n",
      "249536 ; loss 0.51 accuracy:79.64 ;\n",
      "<class 'torch.Tensor'> tensor(203914) 203914\n",
      "255936 ; loss 0.51 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(209018) 209018\n",
      "262336 ; loss 0.51 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(214125) 214125\n",
      "268736 ; loss 0.52 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(219221) 219221\n",
      "275136 ; loss 0.51 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(224322) 224322\n",
      "281536 ; loss 0.51 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(229450) 229450\n",
      "287936 ; loss 0.51 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(234568) 234568\n",
      "294336 ; loss 0.51 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(239667) 239667\n",
      "300736 ; loss 0.52 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(244782) 244782\n",
      "307136 ; loss 0.51 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(249874) 249874\n",
      "313536 ; loss 0.52 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(254942) 254942\n",
      "319936 ; loss 0.52 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(259998) 259998\n",
      "326336 ; loss 0.52 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(265082) 265082\n",
      "332736 ; loss 0.52 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(270130) 270130\n",
      "339136 ; loss 0.53 accuracy:79.64 ;\n",
      "<class 'torch.Tensor'> tensor(275206) 275206\n",
      "345536 ; loss 0.53 accuracy:79.63 ;\n",
      "<class 'torch.Tensor'> tensor(280325) 280325\n",
      "351936 ; loss 0.51 accuracy:79.64 ;\n",
      "<class 'torch.Tensor'> tensor(285455) 285455\n",
      "358336 ; loss 0.5 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(290557) 290557\n",
      "364736 ; loss 0.52 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(295683) 295683\n",
      "371136 ; loss 0.5 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(300750) 300750\n",
      "377536 ; loss 0.52 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(305871) 305871\n",
      "383936 ; loss 0.5 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(310982) 310982\n",
      "390336 ; loss 0.52 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(316069) 316069\n",
      "396736 ; loss 0.51 accuracy:79.65 ;\n",
      "<class 'torch.Tensor'> tensor(321175) 321175\n",
      "403136 ; loss 0.5 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(326335) 326335\n",
      "409536 ; loss 0.49 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(331438) 331438\n",
      "415936 ; loss 0.5 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(336520) 336520\n",
      "422336 ; loss 0.52 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(341648) 341648\n",
      "428736 ; loss 0.51 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(346767) 346767\n",
      "435136 ; loss 0.51 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(351824) 351824\n",
      "441536 ; loss 0.51 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(356895) 356895\n",
      "447936 ; loss 0.52 accuracy:79.66 ;\n",
      "<class 'torch.Tensor'> tensor(362022) 362022\n",
      "454336 ; loss 0.51 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(367116) 367116\n",
      "460736 ; loss 0.52 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(372216) 372216\n",
      "467136 ; loss 0.51 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(377317) 377317\n",
      "473536 ; loss 0.51 accuracy:79.67 ;\n",
      "<class 'torch.Tensor'> tensor(382459) 382459\n",
      "479936 ; loss 0.5 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(387577) 387577\n",
      "486336 ; loss 0.51 accuracy:79.68 ;\n",
      "<class 'torch.Tensor'> tensor(392705) 392705\n",
      "492736 ; loss 0.51 accuracy:79.69 ;\n",
      "<class 'torch.Tensor'> tensor(397821) 397821\n",
      "499136 ; loss 0.51 accuracy:79.69 ;\n",
      "<class 'torch.Tensor'> tensor(402924) 402924\n",
      "505536 ; loss 0.5 accuracy:79.69 ;\n",
      "<class 'torch.Tensor'> tensor(408041) 408041\n",
      "511936 ; loss 0.51 accuracy:79.7 ;\n",
      "<class 'torch.Tensor'> tensor(413185) 413185\n",
      "518336 ; loss 0.5 accuracy:79.7 ;\n",
      "<class 'torch.Tensor'> tensor(418275) 418275\n",
      "524736 ; loss 0.52 accuracy:79.7 ;\n",
      "<class 'torch.Tensor'> tensor(423485) 423485\n",
      "531136 ; loss 0.5 accuracy:79.72 ;\n",
      "<class 'torch.Tensor'> tensor(428543) 428543\n",
      "537536 ; loss 0.52 accuracy:79.71 ;\n",
      "<class 'torch.Tensor'> tensor(433687) 433687\n",
      "543936 ; loss 0.5 accuracy:79.72 ;\n",
      "results : epoch 16 ; mean accuracy train : 79.72\n",
      "\n",
      "VALIDATION : Epoch 16\n",
      "togrep : results : epoch 16 ; mean accuracy valid :              80.3\n",
      "saving model at epoch 16\n",
      "\n",
      "TRAINING : Epoch 17\n",
      "Learning rate : 0.08514577710948755\n",
      "<class 'torch.Tensor'> tensor(5095) 5095\n",
      "6336 ; loss 0.51 accuracy:79.61 ;\n",
      "<class 'torch.Tensor'> tensor(10249) 10249\n",
      "12736 ; loss 0.5 accuracy:80.07 ;\n",
      "<class 'torch.Tensor'> tensor(15352) 15352\n",
      "19136 ; loss 0.51 accuracy:79.96 ;\n",
      "<class 'torch.Tensor'> tensor(20460) 20460\n",
      "25536 ; loss 0.5 accuracy:79.92 ;\n",
      "<class 'torch.Tensor'> tensor(25599) 25599\n",
      "31936 ; loss 0.51 accuracy:80.0 ;\n",
      "<class 'torch.Tensor'> tensor(30760) 30760\n",
      "38336 ; loss 0.5 accuracy:80.1 ;\n",
      "<class 'torch.Tensor'> tensor(35959) 35959\n",
      "44736 ; loss 0.48 accuracy:80.27 ;\n",
      "<class 'torch.Tensor'> tensor(41096) 41096\n",
      "51136 ; loss 0.51 accuracy:80.27 ;\n",
      "<class 'torch.Tensor'> tensor(46222) 46222\n",
      "57536 ; loss 0.51 accuracy:80.25 ;\n",
      "<class 'torch.Tensor'> tensor(51327) 51327\n",
      "63936 ; loss 0.5 accuracy:80.2 ;\n",
      "<class 'torch.Tensor'> tensor(56457) 56457\n",
      "70336 ; loss 0.51 accuracy:80.19 ;\n",
      "<class 'torch.Tensor'> tensor(61653) 61653\n",
      "76736 ; loss 0.49 accuracy:80.28 ;\n",
      "<class 'torch.Tensor'> tensor(66798) 66798\n",
      "83136 ; loss 0.5 accuracy:80.29 ;\n",
      "<class 'torch.Tensor'> tensor(71978) 71978\n",
      "89536 ; loss 0.49 accuracy:80.33 ;\n",
      "<class 'torch.Tensor'> tensor(77150) 77150\n",
      "95936 ; loss 0.49 accuracy:80.36 ;\n",
      "<class 'torch.Tensor'> tensor(82269) 82269\n",
      "102336 ; loss 0.5 accuracy:80.34 ;\n",
      "<class 'torch.Tensor'> tensor(87404) 87404\n",
      "108736 ; loss 0.5 accuracy:80.33 ;\n",
      "<class 'torch.Tensor'> tensor(92569) 92569\n",
      "115136 ; loss 0.5 accuracy:80.36 ;\n",
      "<class 'torch.Tensor'> tensor(97733) 97733\n",
      "121536 ; loss 0.48 accuracy:80.37 ;\n",
      "<class 'torch.Tensor'> tensor(102866) 102866\n",
      "127936 ; loss 0.5 accuracy:80.36 ;\n",
      "<class 'torch.Tensor'> tensor(107975) 107975\n",
      "134336 ; loss 0.51 accuracy:80.34 ;\n",
      "<class 'torch.Tensor'> tensor(113041) 113041\n",
      "140736 ; loss 0.52 accuracy:80.28 ;\n",
      "<class 'torch.Tensor'> tensor(118213) 118213\n",
      "147136 ; loss 0.49 accuracy:80.31 ;\n",
      "<class 'torch.Tensor'> tensor(123394) 123394\n",
      "153536 ; loss 0.5 accuracy:80.33 ;\n",
      "<class 'torch.Tensor'> tensor(128540) 128540\n",
      "159936 ; loss 0.5 accuracy:80.34 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(133656) 133656\n",
      "166336 ; loss 0.5 accuracy:80.32 ;\n",
      "<class 'torch.Tensor'> tensor(138776) 138776\n",
      "172736 ; loss 0.51 accuracy:80.31 ;\n",
      "<class 'torch.Tensor'> tensor(143925) 143925\n",
      "179136 ; loss 0.5 accuracy:80.32 ;\n",
      "<class 'torch.Tensor'> tensor(149030) 149030\n",
      "185536 ; loss 0.53 accuracy:80.3 ;\n",
      "<class 'torch.Tensor'> tensor(154159) 154159\n",
      "191936 ; loss 0.5 accuracy:80.29 ;\n",
      "<class 'torch.Tensor'> tensor(159363) 159363\n",
      "198336 ; loss 0.48 accuracy:80.32 ;\n",
      "<class 'torch.Tensor'> tensor(164519) 164519\n",
      "204736 ; loss 0.5 accuracy:80.33 ;\n",
      "<class 'torch.Tensor'> tensor(169644) 169644\n",
      "211136 ; loss 0.51 accuracy:80.32 ;\n",
      "<class 'torch.Tensor'> tensor(174830) 174830\n",
      "217536 ; loss 0.48 accuracy:80.34 ;\n",
      "<class 'torch.Tensor'> tensor(180051) 180051\n",
      "223936 ; loss 0.49 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(185259) 185259\n",
      "230336 ; loss 0.48 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(190379) 190379\n",
      "236736 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(195513) 195513\n",
      "243136 ; loss 0.5 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(200678) 200678\n",
      "249536 ; loss 0.49 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(205815) 205815\n",
      "255936 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(210915) 210915\n",
      "262336 ; loss 0.51 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(216092) 216092\n",
      "268736 ; loss 0.49 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(221259) 221259\n",
      "275136 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(226430) 226430\n",
      "281536 ; loss 0.49 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(231592) 231592\n",
      "287936 ; loss 0.49 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(236721) 236721\n",
      "294336 ; loss 0.51 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(241873) 241873\n",
      "300736 ; loss 0.5 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(246966) 246966\n",
      "307136 ; loss 0.51 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(252122) 252122\n",
      "313536 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(257322) 257322\n",
      "319936 ; loss 0.48 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(262467) 262467\n",
      "326336 ; loss 0.49 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(267575) 267575\n",
      "332736 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(272679) 272679\n",
      "339136 ; loss 0.51 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(277851) 277851\n",
      "345536 ; loss 0.48 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(282992) 282992\n",
      "351936 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(288061) 288061\n",
      "358336 ; loss 0.53 accuracy:80.37 ;\n",
      "<class 'torch.Tensor'> tensor(293154) 293154\n",
      "364736 ; loss 0.51 accuracy:80.36 ;\n",
      "<class 'torch.Tensor'> tensor(298308) 298308\n",
      "371136 ; loss 0.5 accuracy:80.36 ;\n",
      "<class 'torch.Tensor'> tensor(303478) 303478\n",
      "377536 ; loss 0.49 accuracy:80.37 ;\n",
      "<class 'torch.Tensor'> tensor(308616) 308616\n",
      "383936 ; loss 0.5 accuracy:80.37 ;\n",
      "<class 'torch.Tensor'> tensor(313746) 313746\n",
      "390336 ; loss 0.5 accuracy:80.37 ;\n",
      "<class 'torch.Tensor'> tensor(318884) 318884\n",
      "396736 ; loss 0.5 accuracy:80.36 ;\n",
      "<class 'torch.Tensor'> tensor(324049) 324049\n",
      "403136 ; loss 0.49 accuracy:80.37 ;\n",
      "<class 'torch.Tensor'> tensor(329217) 329217\n",
      "409536 ; loss 0.5 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(334384) 334384\n",
      "415936 ; loss 0.49 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(339536) 339536\n",
      "422336 ; loss 0.49 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(344707) 344707\n",
      "428736 ; loss 0.5 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(349815) 349815\n",
      "435136 ; loss 0.51 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(354967) 354967\n",
      "441536 ; loss 0.5 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(360101) 360101\n",
      "447936 ; loss 0.5 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(365276) 365276\n",
      "454336 ; loss 0.49 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(370451) 370451\n",
      "460736 ; loss 0.5 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(375617) 375617\n",
      "467136 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(380702) 380702\n",
      "473536 ; loss 0.52 accuracy:80.38 ;\n",
      "<class 'torch.Tensor'> tensor(385887) 385887\n",
      "479936 ; loss 0.48 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(391023) 391023\n",
      "486336 ; loss 0.5 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(396182) 396182\n",
      "492736 ; loss 0.5 accuracy:80.39 ;\n",
      "<class 'torch.Tensor'> tensor(401337) 401337\n",
      "499136 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(406487) 406487\n",
      "505536 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(411645) 411645\n",
      "511936 ; loss 0.5 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(416845) 416845\n",
      "518336 ; loss 0.48 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(422011) 422011\n",
      "524736 ; loss 0.49 accuracy:80.41 ;\n",
      "<class 'torch.Tensor'> tensor(427106) 427106\n",
      "531136 ; loss 0.51 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(432210) 432210\n",
      "537536 ; loss 0.51 accuracy:80.4 ;\n",
      "<class 'torch.Tensor'> tensor(437317) 437317\n",
      "543936 ; loss 0.5 accuracy:80.39 ;\n",
      "results : epoch 17 ; mean accuracy train : 80.39\n",
      "\n",
      "VALIDATION : Epoch 17\n",
      "togrep : results : epoch 17 ; mean accuracy valid :              80.2\n",
      "Shrinking lr by : 5. New lr = 0.01702915542189751\n",
      "\n",
      "TRAINING : Epoch 18\n",
      "Learning rate : 0.016858863867678535\n",
      "<class 'torch.Tensor'> tensor(5113) 5113\n",
      "6336 ; loss 0.5 accuracy:79.89 ;\n",
      "<class 'torch.Tensor'> tensor(10264) 10264\n",
      "12736 ; loss 0.49 accuracy:80.19 ;\n",
      "<class 'torch.Tensor'> tensor(15467) 15467\n",
      "19136 ; loss 0.48 accuracy:80.56 ;\n",
      "<class 'torch.Tensor'> tensor(20641) 20641\n",
      "25536 ; loss 0.49 accuracy:80.63 ;\n",
      "<class 'torch.Tensor'> tensor(25837) 25837\n",
      "31936 ; loss 0.49 accuracy:80.74 ;\n",
      "<class 'torch.Tensor'> tensor(31006) 31006\n",
      "38336 ; loss 0.49 accuracy:80.74 ;\n",
      "<class 'torch.Tensor'> tensor(36219) 36219\n",
      "44736 ; loss 0.48 accuracy:80.85 ;\n",
      "<class 'torch.Tensor'> tensor(41416) 41416\n",
      "51136 ; loss 0.49 accuracy:80.89 ;\n",
      "<class 'torch.Tensor'> tensor(46605) 46605\n",
      "57536 ; loss 0.49 accuracy:80.91 ;\n",
      "<class 'torch.Tensor'> tensor(51780) 51780\n",
      "63936 ; loss 0.49 accuracy:80.91 ;\n",
      "<class 'torch.Tensor'> tensor(56935) 56935\n",
      "70336 ; loss 0.5 accuracy:80.87 ;\n",
      "<class 'torch.Tensor'> tensor(62141) 62141\n",
      "76736 ; loss 0.48 accuracy:80.91 ;\n",
      "<class 'torch.Tensor'> tensor(67339) 67339\n",
      "83136 ; loss 0.48 accuracy:80.94 ;\n",
      "<class 'torch.Tensor'> tensor(72504) 72504\n",
      "89536 ; loss 0.49 accuracy:80.92 ;\n",
      "<class 'torch.Tensor'> tensor(77711) 77711\n",
      "95936 ; loss 0.47 accuracy:80.95 ;\n",
      "<class 'torch.Tensor'> tensor(82862) 82862\n",
      "102336 ; loss 0.49 accuracy:80.92 ;\n",
      "<class 'torch.Tensor'> tensor(88060) 88060\n",
      "108736 ; loss 0.48 accuracy:80.94 ;\n",
      "<class 'torch.Tensor'> tensor(93277) 93277\n",
      "115136 ; loss 0.48 accuracy:80.97 ;\n",
      "<class 'torch.Tensor'> tensor(98449) 98449\n",
      "121536 ; loss 0.49 accuracy:80.96 ;\n",
      "<class 'torch.Tensor'> tensor(103605) 103605\n",
      "127936 ; loss 0.49 accuracy:80.94 ;\n",
      "<class 'torch.Tensor'> tensor(108808) 108808\n",
      "134336 ; loss 0.47 accuracy:80.96 ;\n",
      "<class 'torch.Tensor'> tensor(113972) 113972\n",
      "140736 ; loss 0.5 accuracy:80.95 ;\n",
      "<class 'torch.Tensor'> tensor(119159) 119159\n",
      "147136 ; loss 0.49 accuracy:80.95 ;\n",
      "<class 'torch.Tensor'> tensor(124334) 124334\n",
      "153536 ; loss 0.48 accuracy:80.95 ;\n",
      "<class 'torch.Tensor'> tensor(129585) 129585\n",
      "159936 ; loss 0.47 accuracy:80.99 ;\n",
      "<class 'torch.Tensor'> tensor(134785) 134785\n",
      "166336 ; loss 0.48 accuracy:81.0 ;\n",
      "<class 'torch.Tensor'> tensor(139935) 139935\n",
      "172736 ; loss 0.5 accuracy:80.98 ;\n",
      "<class 'torch.Tensor'> tensor(145179) 145179\n",
      "179136 ; loss 0.47 accuracy:81.02 ;\n",
      "<class 'torch.Tensor'> tensor(150361) 150361\n",
      "185536 ; loss 0.49 accuracy:81.01 ;\n",
      "<class 'torch.Tensor'> tensor(155567) 155567\n",
      "191936 ; loss 0.49 accuracy:81.02 ;\n",
      "<class 'torch.Tensor'> tensor(160755) 160755\n",
      "198336 ; loss 0.48 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(165948) 165948\n",
      "204736 ; loss 0.48 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(171130) 171130\n",
      "211136 ; loss 0.49 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(176320) 176320\n",
      "217536 ; loss 0.49 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(181503) 181503\n",
      "223936 ; loss 0.48 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(186704) 186704\n",
      "230336 ; loss 0.48 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(191900) 191900\n",
      "236736 ; loss 0.48 accuracy:81.04 ;\n",
      "<class 'torch.Tensor'> tensor(197025) 197025\n",
      "243136 ; loss 0.5 accuracy:81.01 ;\n",
      "<class 'torch.Tensor'> tensor(202211) 202211\n",
      "249536 ; loss 0.48 accuracy:81.01 ;\n",
      "<class 'torch.Tensor'> tensor(207418) 207418\n",
      "255936 ; loss 0.48 accuracy:81.02 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(212610) 212610\n",
      "262336 ; loss 0.48 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(217788) 217788\n",
      "268736 ; loss 0.48 accuracy:81.02 ;\n",
      "<class 'torch.Tensor'> tensor(223000) 223000\n",
      "275136 ; loss 0.47 accuracy:81.03 ;\n",
      "<class 'torch.Tensor'> tensor(228249) 228249\n",
      "281536 ; loss 0.47 accuracy:81.05 ;\n",
      "<class 'torch.Tensor'> tensor(233477) 233477\n",
      "287936 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(238664) 238664\n",
      "294336 ; loss 0.49 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(243848) 243848\n",
      "300736 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(249023) 249023\n",
      "307136 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(254198) 254198\n",
      "313536 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(259381) 259381\n",
      "319936 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(264585) 264585\n",
      "326336 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(269748) 269748\n",
      "332736 ; loss 0.5 accuracy:81.05 ;\n",
      "<class 'torch.Tensor'> tensor(274941) 274941\n",
      "339136 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(280126) 280126\n",
      "345536 ; loss 0.49 accuracy:81.05 ;\n",
      "<class 'torch.Tensor'> tensor(285271) 285271\n",
      "351936 ; loss 0.5 accuracy:81.04 ;\n",
      "<class 'torch.Tensor'> tensor(290503) 290503\n",
      "358336 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(295709) 295709\n",
      "364736 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(300932) 300932\n",
      "371136 ; loss 0.47 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(306153) 306153\n",
      "377536 ; loss 0.48 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(311334) 311334\n",
      "383936 ; loss 0.48 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(316483) 316483\n",
      "390336 ; loss 0.5 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(321668) 321668\n",
      "396736 ; loss 0.49 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(326873) 326873\n",
      "403136 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(332067) 332067\n",
      "409536 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(337215) 337215\n",
      "415936 ; loss 0.5 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(342407) 342407\n",
      "422336 ; loss 0.48 accuracy:81.06 ;\n",
      "<class 'torch.Tensor'> tensor(347627) 347627\n",
      "428736 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(352836) 352836\n",
      "435136 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(358038) 358038\n",
      "441536 ; loss 0.48 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(363248) 363248\n",
      "447936 ; loss 0.49 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(368445) 368445\n",
      "454336 ; loss 0.48 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(373622) 373622\n",
      "460736 ; loss 0.49 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(378814) 378814\n",
      "467136 ; loss 0.48 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(383969) 383969\n",
      "473536 ; loss 0.49 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(389150) 389150\n",
      "479936 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(394344) 394344\n",
      "486336 ; loss 0.48 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(399519) 399519\n",
      "492736 ; loss 0.49 accuracy:81.07 ;\n",
      "<class 'torch.Tensor'> tensor(404776) 404776\n",
      "499136 ; loss 0.47 accuracy:81.08 ;\n",
      "<class 'torch.Tensor'> tensor(409969) 409969\n",
      "505536 ; loss 0.48 accuracy:81.09 ;\n",
      "<class 'torch.Tensor'> tensor(415188) 415188\n",
      "511936 ; loss 0.48 accuracy:81.09 ;\n",
      "<class 'torch.Tensor'> tensor(420417) 420417\n",
      "518336 ; loss 0.48 accuracy:81.1 ;\n",
      "<class 'torch.Tensor'> tensor(425566) 425566\n",
      "524736 ; loss 0.5 accuracy:81.09 ;\n",
      "<class 'torch.Tensor'> tensor(430750) 430750\n",
      "531136 ; loss 0.49 accuracy:81.09 ;\n",
      "<class 'torch.Tensor'> tensor(435922) 435922\n",
      "537536 ; loss 0.48 accuracy:81.09 ;\n",
      "<class 'torch.Tensor'> tensor(441112) 441112\n",
      "543936 ; loss 0.48 accuracy:81.09 ;\n",
      "results : epoch 18 ; mean accuracy train : 81.08\n",
      "\n",
      "VALIDATION : Epoch 18\n",
      "togrep : results : epoch 18 ; mean accuracy valid :              81.02\n",
      "saving model at epoch 18\n",
      "\n",
      "TRAINING : Epoch 19\n",
      "Learning rate : 0.01669027522900175\n",
      "<class 'torch.Tensor'> tensor(5219) 5219\n",
      "6336 ; loss 0.48 accuracy:81.55 ;\n",
      "<class 'torch.Tensor'> tensor(10455) 10455\n",
      "12736 ; loss 0.46 accuracy:81.68 ;\n",
      "<class 'torch.Tensor'> tensor(15659) 15659\n",
      "19136 ; loss 0.48 accuracy:81.56 ;\n",
      "<class 'torch.Tensor'> tensor(20822) 20822\n",
      "25536 ; loss 0.49 accuracy:81.34 ;\n",
      "<class 'torch.Tensor'> tensor(26019) 26019\n",
      "31936 ; loss 0.48 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(31256) 31256\n",
      "38336 ; loss 0.48 accuracy:81.4 ;\n",
      "<class 'torch.Tensor'> tensor(36493) 36493\n",
      "44736 ; loss 0.48 accuracy:81.46 ;\n",
      "<class 'torch.Tensor'> tensor(41669) 41669\n",
      "51136 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(46829) 46829\n",
      "57536 ; loss 0.49 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(52067) 52067\n",
      "63936 ; loss 0.48 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(57213) 57213\n",
      "70336 ; loss 0.49 accuracy:81.27 ;\n",
      "<class 'torch.Tensor'> tensor(62431) 62431\n",
      "76736 ; loss 0.47 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(67632) 67632\n",
      "83136 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(72800) 72800\n",
      "89536 ; loss 0.49 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(77952) 77952\n",
      "95936 ; loss 0.49 accuracy:81.2 ;\n",
      "<class 'torch.Tensor'> tensor(83107) 83107\n",
      "102336 ; loss 0.48 accuracy:81.16 ;\n",
      "<class 'torch.Tensor'> tensor(88346) 88346\n",
      "108736 ; loss 0.48 accuracy:81.2 ;\n",
      "<class 'torch.Tensor'> tensor(93553) 93553\n",
      "115136 ; loss 0.47 accuracy:81.21 ;\n",
      "<class 'torch.Tensor'> tensor(98765) 98765\n",
      "121536 ; loss 0.49 accuracy:81.22 ;\n",
      "<class 'torch.Tensor'> tensor(103948) 103948\n",
      "127936 ; loss 0.49 accuracy:81.21 ;\n",
      "<class 'torch.Tensor'> tensor(109179) 109179\n",
      "134336 ; loss 0.47 accuracy:81.23 ;\n",
      "<class 'torch.Tensor'> tensor(114390) 114390\n",
      "140736 ; loss 0.48 accuracy:81.24 ;\n",
      "<class 'torch.Tensor'> tensor(119563) 119563\n",
      "147136 ; loss 0.48 accuracy:81.22 ;\n",
      "<class 'torch.Tensor'> tensor(124759) 124759\n",
      "153536 ; loss 0.48 accuracy:81.22 ;\n",
      "<class 'torch.Tensor'> tensor(129976) 129976\n",
      "159936 ; loss 0.48 accuracy:81.23 ;\n",
      "<class 'torch.Tensor'> tensor(135166) 135166\n",
      "166336 ; loss 0.48 accuracy:81.23 ;\n",
      "<class 'torch.Tensor'> tensor(140369) 140369\n",
      "172736 ; loss 0.49 accuracy:81.23 ;\n",
      "<class 'torch.Tensor'> tensor(145587) 145587\n",
      "179136 ; loss 0.48 accuracy:81.24 ;\n",
      "<class 'torch.Tensor'> tensor(150748) 150748\n",
      "185536 ; loss 0.49 accuracy:81.22 ;\n",
      "<class 'torch.Tensor'> tensor(155976) 155976\n",
      "191936 ; loss 0.47 accuracy:81.24 ;\n",
      "<class 'torch.Tensor'> tensor(161220) 161220\n",
      "198336 ; loss 0.48 accuracy:81.26 ;\n",
      "<class 'torch.Tensor'> tensor(166475) 166475\n",
      "204736 ; loss 0.46 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(171709) 171709\n",
      "211136 ; loss 0.48 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(176930) 176930\n",
      "217536 ; loss 0.49 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(182137) 182137\n",
      "223936 ; loss 0.48 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(187309) 187309\n",
      "230336 ; loss 0.49 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(192513) 192513\n",
      "236736 ; loss 0.48 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(197696) 197696\n",
      "243136 ; loss 0.49 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(202923) 202923\n",
      "249536 ; loss 0.47 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(208129) 208129\n",
      "255936 ; loss 0.48 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(213313) 213313\n",
      "262336 ; loss 0.49 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(218515) 218515\n",
      "268736 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(223718) 223718\n",
      "275136 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(228942) 228942\n",
      "281536 ; loss 0.47 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(234166) 234166\n",
      "287936 ; loss 0.48 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(239388) 239388\n",
      "294336 ; loss 0.47 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(244626) 244626\n",
      "300736 ; loss 0.47 accuracy:81.33 ;\n",
      "<class 'torch.Tensor'> tensor(249827) 249827\n",
      "307136 ; loss 0.49 accuracy:81.32 ;\n",
      "<class 'torch.Tensor'> tensor(255040) 255040\n",
      "313536 ; loss 0.48 accuracy:81.33 ;\n",
      "<class 'torch.Tensor'> tensor(260186) 260186\n",
      "319936 ; loss 0.49 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(265313) 265313\n",
      "326336 ; loss 0.5 accuracy:81.28 ;\n",
      "<class 'torch.Tensor'> tensor(270553) 270553\n",
      "332736 ; loss 0.46 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(275768) 275768\n",
      "339136 ; loss 0.48 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(280975) 280975\n",
      "345536 ; loss 0.48 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(286186) 286186\n",
      "351936 ; loss 0.47 accuracy:81.3 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(291407) 291407\n",
      "358336 ; loss 0.47 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(296566) 296566\n",
      "364736 ; loss 0.49 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(301729) 301729\n",
      "371136 ; loss 0.48 accuracy:81.28 ;\n",
      "<class 'torch.Tensor'> tensor(306945) 306945\n",
      "377536 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(312189) 312189\n",
      "383936 ; loss 0.47 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(317375) 317375\n",
      "390336 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(322551) 322551\n",
      "396736 ; loss 0.5 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(327756) 327756\n",
      "403136 ; loss 0.49 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(332977) 332977\n",
      "409536 ; loss 0.49 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(338156) 338156\n",
      "415936 ; loss 0.49 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(343360) 343360\n",
      "422336 ; loss 0.47 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(348560) 348560\n",
      "428736 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(353780) 353780\n",
      "435136 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(358977) 358977\n",
      "441536 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(364192) 364192\n",
      "447936 ; loss 0.47 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(369383) 369383\n",
      "454336 ; loss 0.48 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(374560) 374560\n",
      "460736 ; loss 0.48 accuracy:81.28 ;\n",
      "<class 'torch.Tensor'> tensor(379704) 379704\n",
      "467136 ; loss 0.49 accuracy:81.27 ;\n",
      "<class 'torch.Tensor'> tensor(384865) 384865\n",
      "473536 ; loss 0.48 accuracy:81.26 ;\n",
      "<class 'torch.Tensor'> tensor(390050) 390050\n",
      "479936 ; loss 0.49 accuracy:81.26 ;\n",
      "<class 'torch.Tensor'> tensor(395221) 395221\n",
      "486336 ; loss 0.49 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(400386) 400386\n",
      "492736 ; loss 0.5 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(405634) 405634\n",
      "499136 ; loss 0.47 accuracy:81.26 ;\n",
      "<class 'torch.Tensor'> tensor(410817) 410817\n",
      "505536 ; loss 0.48 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(416013) 416013\n",
      "511936 ; loss 0.48 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(421197) 421197\n",
      "518336 ; loss 0.48 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(426436) 426436\n",
      "524736 ; loss 0.47 accuracy:81.26 ;\n",
      "<class 'torch.Tensor'> tensor(431615) 431615\n",
      "531136 ; loss 0.48 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(436760) 436760\n",
      "537536 ; loss 0.49 accuracy:81.24 ;\n",
      "<class 'torch.Tensor'> tensor(441961) 441961\n",
      "543936 ; loss 0.48 accuracy:81.24 ;\n",
      "results : epoch 19 ; mean accuracy train : 81.24\n",
      "\n",
      "VALIDATION : Epoch 19\n",
      "togrep : results : epoch 19 ; mean accuracy valid :              81.26\n",
      "saving model at epoch 19\n",
      "\n",
      "TRAINING : Epoch 20\n",
      "Learning rate : 0.01652337247671173\n",
      "<class 'torch.Tensor'> tensor(5141) 5141\n",
      "6336 ; loss 0.49 accuracy:80.33 ;\n",
      "<class 'torch.Tensor'> tensor(10382) 10382\n",
      "12736 ; loss 0.47 accuracy:81.11 ;\n",
      "<class 'torch.Tensor'> tensor(15554) 15554\n",
      "19136 ; loss 0.49 accuracy:81.01 ;\n",
      "<class 'torch.Tensor'> tensor(20718) 20718\n",
      "25536 ; loss 0.48 accuracy:80.93 ;\n",
      "<class 'torch.Tensor'> tensor(25916) 25916\n",
      "31936 ; loss 0.48 accuracy:80.99 ;\n",
      "<class 'torch.Tensor'> tensor(31147) 31147\n",
      "38336 ; loss 0.48 accuracy:81.11 ;\n",
      "<class 'torch.Tensor'> tensor(36398) 36398\n",
      "44736 ; loss 0.47 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(41656) 41656\n",
      "51136 ; loss 0.46 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(46800) 46800\n",
      "57536 ; loss 0.48 accuracy:81.25 ;\n",
      "<class 'torch.Tensor'> tensor(52032) 52032\n",
      "63936 ; loss 0.48 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(57250) 57250\n",
      "70336 ; loss 0.49 accuracy:81.32 ;\n",
      "<class 'torch.Tensor'> tensor(62466) 62466\n",
      "76736 ; loss 0.48 accuracy:81.34 ;\n",
      "<class 'torch.Tensor'> tensor(67650) 67650\n",
      "83136 ; loss 0.48 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(72877) 72877\n",
      "89536 ; loss 0.48 accuracy:81.34 ;\n",
      "<class 'torch.Tensor'> tensor(78041) 78041\n",
      "95936 ; loss 0.49 accuracy:81.29 ;\n",
      "<class 'torch.Tensor'> tensor(83258) 83258\n",
      "102336 ; loss 0.47 accuracy:81.31 ;\n",
      "<class 'torch.Tensor'> tensor(88454) 88454\n",
      "108736 ; loss 0.49 accuracy:81.3 ;\n",
      "<class 'torch.Tensor'> tensor(93700) 93700\n",
      "115136 ; loss 0.47 accuracy:81.34 ;\n",
      "<class 'torch.Tensor'> tensor(98930) 98930\n",
      "121536 ; loss 0.47 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(104149) 104149\n",
      "127936 ; loss 0.48 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(109317) 109317\n",
      "134336 ; loss 0.49 accuracy:81.34 ;\n",
      "<class 'torch.Tensor'> tensor(114542) 114542\n",
      "140736 ; loss 0.47 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(119755) 119755\n",
      "147136 ; loss 0.48 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(124946) 124946\n",
      "153536 ; loss 0.48 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(130148) 130148\n",
      "159936 ; loss 0.48 accuracy:81.34 ;\n",
      "<class 'torch.Tensor'> tensor(135371) 135371\n",
      "166336 ; loss 0.47 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(140615) 140615\n",
      "172736 ; loss 0.47 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(145881) 145881\n",
      "179136 ; loss 0.47 accuracy:81.41 ;\n",
      "<class 'torch.Tensor'> tensor(151133) 151133\n",
      "185536 ; loss 0.47 accuracy:81.43 ;\n",
      "<class 'torch.Tensor'> tensor(156269) 156269\n",
      "191936 ; loss 0.49 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(161468) 161468\n",
      "198336 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(166683) 166683\n",
      "204736 ; loss 0.47 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(171859) 171859\n",
      "211136 ; loss 0.48 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(177077) 177077\n",
      "217536 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(182294) 182294\n",
      "223936 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(187522) 187522\n",
      "230336 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(192786) 192786\n",
      "236736 ; loss 0.47 accuracy:81.41 ;\n",
      "<class 'torch.Tensor'> tensor(197915) 197915\n",
      "243136 ; loss 0.49 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(203143) 203143\n",
      "249536 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(208363) 208363\n",
      "255936 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(213538) 213538\n",
      "262336 ; loss 0.49 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(218717) 218717\n",
      "268736 ; loss 0.49 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(223922) 223922\n",
      "275136 ; loss 0.48 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(229154) 229154\n",
      "281536 ; loss 0.47 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(234390) 234390\n",
      "287936 ; loss 0.47 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(239580) 239580\n",
      "294336 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(244779) 244779\n",
      "300736 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(249988) 249988\n",
      "307136 ; loss 0.47 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(255235) 255235\n",
      "313536 ; loss 0.46 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(260439) 260439\n",
      "319936 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(265667) 265667\n",
      "326336 ; loss 0.47 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(270910) 270910\n",
      "332736 ; loss 0.48 accuracy:81.4 ;\n",
      "<class 'torch.Tensor'> tensor(276100) 276100\n",
      "339136 ; loss 0.48 accuracy:81.4 ;\n",
      "<class 'torch.Tensor'> tensor(281289) 281289\n",
      "345536 ; loss 0.49 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(286484) 286484\n",
      "351936 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(291695) 291695\n",
      "358336 ; loss 0.47 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(296923) 296923\n",
      "364736 ; loss 0.48 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(302112) 302112\n",
      "371136 ; loss 0.49 accuracy:81.39 ;\n",
      "<class 'torch.Tensor'> tensor(307291) 307291\n",
      "377536 ; loss 0.5 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(312486) 312486\n",
      "383936 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(317689) 317689\n",
      "390336 ; loss 0.47 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(322930) 322930\n",
      "396736 ; loss 0.47 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(328116) 328116\n",
      "403136 ; loss 0.48 accuracy:81.38 ;\n",
      "<class 'torch.Tensor'> tensor(333294) 333294\n",
      "409536 ; loss 0.49 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(338464) 338464\n",
      "415936 ; loss 0.49 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(343674) 343674\n",
      "422336 ; loss 0.47 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(348859) 348859\n",
      "428736 ; loss 0.48 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(354072) 354072\n",
      "435136 ; loss 0.48 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(359267) 359267\n",
      "441536 ; loss 0.47 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(364499) 364499\n",
      "447936 ; loss 0.48 accuracy:81.36 ;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor(369739) 369739\n",
      "454336 ; loss 0.46 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(374954) 374954\n",
      "460736 ; loss 0.48 accuracy:81.37 ;\n",
      "<class 'torch.Tensor'> tensor(380133) 380133\n",
      "467136 ; loss 0.47 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(385322) 385322\n",
      "473536 ; loss 0.49 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(390548) 390548\n",
      "479936 ; loss 0.48 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(395756) 395756\n",
      "486336 ; loss 0.48 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(400957) 400957\n",
      "492736 ; loss 0.48 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(406137) 406137\n",
      "499136 ; loss 0.49 accuracy:81.36 ;\n",
      "<class 'torch.Tensor'> tensor(411317) 411317\n",
      "505536 ; loss 0.48 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(416536) 416536\n",
      "511936 ; loss 0.47 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(421740) 421740\n",
      "518336 ; loss 0.47 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(426925) 426925\n",
      "524736 ; loss 0.48 accuracy:81.35 ;\n",
      "<class 'torch.Tensor'> tensor(432050) 432050\n",
      "531136 ; loss 0.5 accuracy:81.33 ;\n",
      "<class 'torch.Tensor'> tensor(437242) 437242\n",
      "537536 ; loss 0.48 accuracy:81.33 ;\n",
      "<class 'torch.Tensor'> tensor(442443) 442443\n",
      "543936 ; loss 0.48 accuracy:81.33 ;\n",
      "results : epoch 20 ; mean accuracy train : 81.33\n",
      "\n",
      "VALIDATION : Epoch 20\n",
      "togrep : results : epoch 20 ; mean accuracy valid :              81.1\n",
      "Shrinking lr by : 5. New lr = 0.003304674495342346\n",
      "\n",
      "TEST : Epoch 21\n",
      "\n",
      "VALIDATION : Epoch 1000000.0\n",
      "finalgrep : accuracy valid : 81.1\n",
      "finalgrep : accuracy test : 81.15\n"
     ]
    }
   ],
   "source": [
    "#InferSent\n",
    "! python train_nli.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
