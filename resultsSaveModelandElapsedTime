
togrep : []

Namespace(LSTM_num_layers=1, batch_size=64, data_dir='/home/ubuntu/cs230_project/dataset', decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='InferSent', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=2, n_enc_layers=1, n_epochs=10, nlipath='/home/ubuntu/InferSent/dataset/SNLI', nonlinear_fc=1, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='3layernonlinear.pickle', pool_type='max', seed=1234, weight_decay=0.0005, word_emb_dim=300)
quora checkpoint len(train[s1]):242494,len(train[s2]):242494,          len(train[label]):242494
============
len(valid['s1']):80832, len(valid[s2]):80832,           len(valid['label']):80832
============
len(test['s1']):80832,len(test['s2']):80832,           len(test['label']):80832
Found 88571(/232484) words with glove vectors
Vocab size : 88571
NLINet(
  (encoder): InferSent(
    (enc_lstm): LSTM(300, 2048, bidirectional=True)
  )
  (classifier): Sequential(
    (0): Linear(in_features=16384, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.0)
    (4): Linear(in_features=512, out_features=512, bias=True)
    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.0)
    (8): Linear(in_features=512, out_features=512, bias=True)
    (9): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.0)
    (12): Linear(in_features=512, out_features=2, bias=True)
  )
)
total num epochs:10

TRAINING : Epoch 1
Learning rate : 0.1
<class 'torch.Tensor'> tensor(4178) 4178
6336 ; loss 0.61 ; sentence/s 715 ; words/s 46616 ; accuracy train : 65.28
<class 'torch.Tensor'> tensor(8717) 8717
12736 ; loss 0.54 ; sentence/s 721 ; words/s 46136 ; accuracy train : 68.1
<class 'torch.Tensor'> tensor(13343) 13343
19136 ; loss 0.53 ; sentence/s 705 ; words/s 47510 ; accuracy train : 69.49
<class 'torch.Tensor'> tensor(18044) 18044
25536 ; loss 0.51 ; sentence/s 718 ; words/s 46052 ; accuracy train : 70.48
<class 'torch.Tensor'> tensor(22807) 22807
31936 ; loss 0.49 ; sentence/s 711 ; words/s 46728 ; accuracy train : 71.27
<class 'torch.Tensor'> tensor(27568) 27568
38336 ; loss 0.5 ; sentence/s 723 ; words/s 46649 ; accuracy train : 71.79
<class 'torch.Tensor'> tensor(32343) 32343
44736 ; loss 0.48 ; sentence/s 727 ; words/s 45923 ; accuracy train : 72.19
<class 'torch.Tensor'> tensor(37143) 37143
51136 ; loss 0.48 ; sentence/s 713 ; words/s 46885 ; accuracy train : 72.54
<class 'torch.Tensor'> tensor(42054) 42054
57536 ; loss 0.47 ; sentence/s 731 ; words/s 45650 ; accuracy train : 73.01
<class 'torch.Tensor'> tensor(46945) 46945
63936 ; loss 0.46 ; sentence/s 723 ; words/s 46034 ; accuracy train : 73.35
<class 'torch.Tensor'> tensor(51879) 51879
70336 ; loss 0.46 ; sentence/s 724 ; words/s 46309 ; accuracy train : 73.69
<class 'torch.Tensor'> tensor(56812) 56812
76736 ; loss 0.46 ; sentence/s 714 ; words/s 46757 ; accuracy train : 73.97
<class 'torch.Tensor'> tensor(61775) 61775
83136 ; loss 0.45 ; sentence/s 731 ; words/s 45047 ; accuracy train : 74.25
<class 'torch.Tensor'> tensor(66718) 66718
89536 ; loss 0.44 ; sentence/s 719 ; words/s 47033 ; accuracy train : 74.46
<class 'torch.Tensor'> tensor(71693) 71693
95936 ; loss 0.44 ; sentence/s 710 ; words/s 46971 ; accuracy train : 74.68
<class 'torch.Tensor'> tensor(76626) 76626
102336 ; loss 0.45 ; sentence/s 718 ; words/s 47072 ; accuracy train : 74.83
<class 'torch.Tensor'> tensor(81616) 81616
108736 ; loss 0.44 ; sentence/s 712 ; words/s 46664 ; accuracy train : 75.01
<class 'torch.Tensor'> tensor(86594) 86594
115136 ; loss 0.44 ; sentence/s 727 ; words/s 45670 ; accuracy train : 75.17
<class 'torch.Tensor'> tensor(91641) 91641
121536 ; loss 0.43 ; sentence/s 711 ; words/s 47121 ; accuracy train : 75.36
<class 'torch.Tensor'> tensor(96637) 96637
127936 ; loss 0.44 ; sentence/s 726 ; words/s 45713 ; accuracy train : 75.5
<class 'torch.Tensor'> tensor(101610) 101610
134336 ; loss 0.45 ; sentence/s 710 ; words/s 46945 ; accuracy train : 75.6
<class 'torch.Tensor'> tensor(106621) 106621
140736 ; loss 0.43 ; sentence/s 714 ; words/s 46145 ; accuracy train : 75.73
<class 'torch.Tensor'> tensor(111637) 111637
147136 ; loss 0.42 ; sentence/s 717 ; words/s 46309 ; accuracy train : 75.84
<class 'torch.Tensor'> tensor(116691) 116691
153536 ; loss 0.42 ; sentence/s 718 ; words/s 46304 ; accuracy train : 75.97
<class 'torch.Tensor'> tensor(121691) 121691
159936 ; loss 0.42 ; sentence/s 721 ; words/s 45855 ; accuracy train : 76.06
<class 'torch.Tensor'> tensor(126702) 126702
166336 ; loss 0.43 ; sentence/s 717 ; words/s 46602 ; accuracy train : 76.14
<class 'torch.Tensor'> tensor(131775) 131775
172736 ; loss 0.41 ; sentence/s 702 ; words/s 46871 ; accuracy train : 76.26
<class 'torch.Tensor'> tensor(136841) 136841
179136 ; loss 0.42 ; sentence/s 724 ; words/s 45948 ; accuracy train : 76.36
<class 'torch.Tensor'> tensor(141900) 141900
185536 ; loss 0.42 ; sentence/s 716 ; words/s 47232 ; accuracy train : 76.45
<class 'torch.Tensor'> tensor(146940) 146940
191936 ; loss 0.42 ; sentence/s 715 ; words/s 46455 ; accuracy train : 76.53
<class 'torch.Tensor'> tensor(152005) 152005
198336 ; loss 0.42 ; sentence/s 730 ; words/s 45420 ; accuracy train : 76.62
<class 'torch.Tensor'> tensor(157072) 157072
204736 ; loss 0.42 ; sentence/s 708 ; words/s 47631 ; accuracy train : 76.7
<class 'torch.Tensor'> tensor(162132) 162132
211136 ; loss 0.42 ; sentence/s 716 ; words/s 46541 ; accuracy train : 76.77
<class 'torch.Tensor'> tensor(167209) 167209
217536 ; loss 0.41 ; sentence/s 726 ; words/s 45876 ; accuracy train : 76.84
<class 'torch.Tensor'> tensor(172238) 172238
223936 ; loss 0.43 ; sentence/s 723 ; words/s 46562 ; accuracy train : 76.89
<class 'torch.Tensor'> tensor(177307) 177307
230336 ; loss 0.42 ; sentence/s 706 ; words/s 46981 ; accuracy train : 76.96
<class 'torch.Tensor'> tensor(182366) 182366
236736 ; loss 0.42 ; sentence/s 733 ; words/s 45405 ; accuracy train : 77.01
results : epoch 1 ; mean accuracy train : 77.06

VALIDATION : Epoch 1
togrep : results : epoch 1 ; mean accuracy valid :              79.7
saving model at epoch 1

TRAINING : Epoch 2
Learning rate : 0.099
<class 'torch.Tensor'> tensor(5270) 5270
6336 ; loss 0.37 ; sentence/s 720 ; words/s 45816 ; accuracy train : 82.34
<class 'torch.Tensor'> tensor(10544) 10544
12736 ; loss 0.37 ; sentence/s 709 ; words/s 46968 ; accuracy train : 82.38
<class 'torch.Tensor'> tensor(15836) 15836
19136 ; loss 0.37 ; sentence/s 715 ; words/s 46532 ; accuracy train : 82.48
<class 'torch.Tensor'> tensor(21054) 21054
25536 ; loss 0.38 ; sentence/s 711 ; words/s 46600 ; accuracy train : 82.24
<class 'torch.Tensor'> tensor(26351) 26351
31936 ; loss 0.37 ; sentence/s 710 ; words/s 47502 ; accuracy train : 82.35
<class 'torch.Tensor'> tensor(31604) 31604
38336 ; loss 0.38 ; sentence/s 725 ; words/s 45380 ; accuracy train : 82.3
<class 'torch.Tensor'> tensor(36863) 36863
44736 ; loss 0.37 ; sentence/s 724 ; words/s 46053 ; accuracy train : 82.28
<class 'torch.Tensor'> tensor(42141) 42141
51136 ; loss 0.37 ; sentence/s 713 ; words/s 46479 ; accuracy train : 82.31
<class 'torch.Tensor'> tensor(47416) 47416
57536 ; loss 0.37 ; sentence/s 703 ; words/s 47065 ; accuracy train : 82.32
<class 'torch.Tensor'> tensor(52686) 52686
63936 ; loss 0.38 ; sentence/s 714 ; words/s 46805 ; accuracy train : 82.32
<class 'torch.Tensor'> tensor(57994) 57994
70336 ; loss 0.37 ; sentence/s 716 ; words/s 46403 ; accuracy train : 82.38
<class 'torch.Tensor'> tensor(63269) 63269
76736 ; loss 0.38 ; sentence/s 723 ; words/s 46386 ; accuracy train : 82.38
<class 'torch.Tensor'> tensor(68566) 68566
83136 ; loss 0.36 ; sentence/s 719 ; words/s 46296 ; accuracy train : 82.41
<class 'torch.Tensor'> tensor(73883) 73883
89536 ; loss 0.36 ; sentence/s 714 ; words/s 46846 ; accuracy train : 82.46
<class 'torch.Tensor'> tensor(79178) 79178
95936 ; loss 0.37 ; sentence/s 734 ; words/s 45771 ; accuracy train : 82.48
<class 'torch.Tensor'> tensor(84454) 84454
102336 ; loss 0.37 ; sentence/s 721 ; words/s 47098 ; accuracy train : 82.47
<class 'torch.Tensor'> tensor(89747) 89747
108736 ; loss 0.36 ; sentence/s 715 ; words/s 46362 ; accuracy train : 82.49
<class 'torch.Tensor'> tensor(95002) 95002
115136 ; loss 0.37 ; sentence/s 713 ; words/s 47188 ; accuracy train : 82.47
<class 'torch.Tensor'> tensor(100247) 100247
121536 ; loss 0.37 ; sentence/s 706 ; words/s 47675 ; accuracy train : 82.44
<class 'torch.Tensor'> tensor(105547) 105547
127936 ; loss 0.36 ; sentence/s 720 ; words/s 46570 ; accuracy train : 82.46
<class 'torch.Tensor'> tensor(110863) 110863
134336 ; loss 0.35 ; sentence/s 720 ; words/s 46094 ; accuracy train : 82.49
<class 'torch.Tensor'> tensor(116122) 116122
140736 ; loss 0.37 ; sentence/s 728 ; words/s 45977 ; accuracy train : 82.47
<class 'torch.Tensor'> tensor(121412) 121412
147136 ; loss 0.36 ; sentence/s 709 ; words/s 46727 ; accuracy train : 82.48
<class 'torch.Tensor'> tensor(126702) 126702
153536 ; loss 0.37 ; sentence/s 717 ; words/s 46957 ; accuracy train : 82.49
<class 'torch.Tensor'> tensor(132021) 132021
159936 ; loss 0.36 ; sentence/s 723 ; words/s 46098 ; accuracy train : 82.51
<class 'torch.Tensor'> tensor(137304) 137304
166336 ; loss 0.37 ; sentence/s 721 ; words/s 46326 ; accuracy train : 82.51
<class 'torch.Tensor'> tensor(142614) 142614
172736 ; loss 0.36 ; sentence/s 711 ; words/s 46655 ; accuracy train : 82.53
<class 'torch.Tensor'> tensor(147885) 147885
179136 ; loss 0.37 ; sentence/s 729 ; words/s 45571 ; accuracy train : 82.53
<class 'torch.Tensor'> tensor(153236) 153236
185536 ; loss 0.35 ; sentence/s 724 ; words/s 46351 ; accuracy train : 82.56
<class 'torch.Tensor'> tensor(158516) 158516
191936 ; loss 0.37 ; sentence/s 717 ; words/s 46733 ; accuracy train : 82.56
<class 'torch.Tensor'> tensor(163841) 163841
198336 ; loss 0.36 ; sentence/s 727 ; words/s 45772 ; accuracy train : 82.58
<class 'torch.Tensor'> tensor(169123) 169123
204736 ; loss 0.36 ; sentence/s 722 ; words/s 46242 ; accuracy train : 82.58
<class 'torch.Tensor'> tensor(174430) 174430
211136 ; loss 0.36 ; sentence/s 728 ; words/s 45597 ; accuracy train : 82.59
<class 'torch.Tensor'> tensor(179696) 179696
217536 ; loss 0.36 ; sentence/s 726 ; words/s 46534 ; accuracy train : 82.58
<class 'torch.Tensor'> tensor(185027) 185027
223936 ; loss 0.36 ; sentence/s 710 ; words/s 47274 ; accuracy train : 82.6
<class 'torch.Tensor'> tensor(190325) 190325
230336 ; loss 0.35 ; sentence/s 717 ; words/s 46862 ; accuracy train : 82.61
<class 'torch.Tensor'> tensor(195595) 195595
236736 ; loss 0.36 ; sentence/s 722 ; words/s 46158 ; accuracy train : 82.6
results : epoch 2 ; mean accuracy train : 82.6

VALIDATION : Epoch 2
togrep : results : epoch 2 ; mean accuracy valid :              81.35
saving model at epoch 2

TRAINING : Epoch 3
Learning rate : 0.09801
<class 'torch.Tensor'> tensor(5533) 5533
6336 ; loss 0.31 ; sentence/s 711 ; words/s 47053 ; accuracy train : 86.45
<class 'torch.Tensor'> tensor(11026) 11026
12736 ; loss 0.31 ; sentence/s 730 ; words/s 45614 ; accuracy train : 86.14
<class 'torch.Tensor'> tensor(16540) 16540
19136 ; loss 0.31 ; sentence/s 714 ; words/s 47099 ; accuracy train : 86.15
<class 'torch.Tensor'> tensor(22162) 22162
25536 ; loss 0.28 ; sentence/s 722 ; words/s 45539 ; accuracy train : 86.57
<class 'torch.Tensor'> tensor(27724) 27724
31936 ; loss 0.3 ; sentence/s 729 ; words/s 46163 ; accuracy train : 86.64
<class 'torch.Tensor'> tensor(33284) 33284
38336 ; loss 0.3 ; sentence/s 733 ; words/s 45639 ; accuracy train : 86.68
<class 'torch.Tensor'> tensor(38792) 38792
44736 ; loss 0.31 ; sentence/s 722 ; words/s 46011 ; accuracy train : 86.59
<class 'torch.Tensor'> tensor(44292) 44292
51136 ; loss 0.31 ; sentence/s 727 ; words/s 45739 ; accuracy train : 86.51
<class 'torch.Tensor'> tensor(49814) 49814
57536 ; loss 0.3 ; sentence/s 713 ; words/s 47445 ; accuracy train : 86.48
<class 'torch.Tensor'> tensor(55285) 55285
63936 ; loss 0.31 ; sentence/s 724 ; words/s 46274 ; accuracy train : 86.38
<class 'torch.Tensor'> tensor(60809) 60809
70336 ; loss 0.3 ; sentence/s 726 ; words/s 45848 ; accuracy train : 86.38
<class 'torch.Tensor'> tensor(66332) 66332
76736 ; loss 0.31 ; sentence/s 727 ; words/s 45684 ; accuracy train : 86.37
<class 'torch.Tensor'> tensor(71803) 71803
83136 ; loss 0.31 ; sentence/s 718 ; words/s 46423 ; accuracy train : 86.3
<class 'torch.Tensor'> tensor(77293) 77293
89536 ; loss 0.31 ; sentence/s 710 ; words/s 47622 ; accuracy train : 86.26
<class 'torch.Tensor'> tensor(82796) 82796
95936 ; loss 0.31 ; sentence/s 718 ; words/s 46430 ; accuracy train : 86.25
<class 'torch.Tensor'> tensor(88305) 88305
102336 ; loss 0.31 ; sentence/s 710 ; words/s 46626 ; accuracy train : 86.24
<class 'torch.Tensor'> tensor(93854) 93854
108736 ; loss 0.3 ; sentence/s 718 ; words/s 45950 ; accuracy train : 86.26
<class 'torch.Tensor'> tensor(99356) 99356
115136 ; loss 0.31 ; sentence/s 709 ; words/s 47176 ; accuracy train : 86.25
<class 'torch.Tensor'> tensor(104828) 104828
121536 ; loss 0.31 ; sentence/s 728 ; words/s 45855 ; accuracy train : 86.21
<class 'torch.Tensor'> tensor(110296) 110296
127936 ; loss 0.32 ; sentence/s 720 ; words/s 46284 ; accuracy train : 86.17
<class 'torch.Tensor'> tensor(115824) 115824
134336 ; loss 0.3 ; sentence/s 718 ; words/s 46597 ; accuracy train : 86.18
<class 'torch.Tensor'> tensor(121344) 121344
140736 ; loss 0.3 ; sentence/s 723 ; words/s 46226 ; accuracy train : 86.18
<class 'torch.Tensor'> tensor(126820) 126820
147136 ; loss 0.32 ; sentence/s 720 ; words/s 46483 ; accuracy train : 86.15
<class 'torch.Tensor'> tensor(132305) 132305
153536 ; loss 0.31 ; sentence/s 703 ; words/s 47810 ; accuracy train : 86.14
<class 'torch.Tensor'> tensor(137780) 137780
159936 ; loss 0.31 ; sentence/s 718 ; words/s 46594 ; accuracy train : 86.11
<class 'torch.Tensor'> tensor(143287) 143287
166336 ; loss 0.31 ; sentence/s 716 ; words/s 46200 ; accuracy train : 86.11
<class 'torch.Tensor'> tensor(148763) 148763
172736 ; loss 0.32 ; sentence/s 717 ; words/s 46474 ; accuracy train : 86.09
<class 'torch.Tensor'> tensor(154248) 154248
179136 ; loss 0.31 ; sentence/s 718 ; words/s 46735 ; accuracy train : 86.08
<class 'torch.Tensor'> tensor(159736) 159736
185536 ; loss 0.31 ; sentence/s 709 ; words/s 47151 ; accuracy train : 86.06
<class 'torch.Tensor'> tensor(165182) 165182
191936 ; loss 0.32 ; sentence/s 727 ; words/s 45739 ; accuracy train : 86.03
<class 'torch.Tensor'> tensor(170646) 170646
198336 ; loss 0.31 ; sentence/s 726 ; words/s 45774 ; accuracy train : 86.01
<class 'torch.Tensor'> tensor(176157) 176157
204736 ; loss 0.31 ; sentence/s 702 ; words/s 47554 ; accuracy train : 86.01
<class 'torch.Tensor'> tensor(181631) 181631
211136 ; loss 0.31 ; sentence/s 725 ; words/s 46191 ; accuracy train : 86.0
<class 'torch.Tensor'> tensor(187098) 187098
217536 ; loss 0.31 ; sentence/s 717 ; words/s 46396 ; accuracy train : 85.98
<class 'torch.Tensor'> tensor(192605) 192605
223936 ; loss 0.31 ; sentence/s 717 ; words/s 46657 ; accuracy train : 85.98
<class 'torch.Tensor'> tensor(198064) 198064
230336 ; loss 0.32 ; sentence/s 723 ; words/s 46254 ; accuracy train : 85.97
<class 'torch.Tensor'> tensor(203529) 203529
236736 ; loss 0.32 ; sentence/s 714 ; words/s 46516 ; accuracy train : 85.95
results : epoch 3 ; mean accuracy train : 85.94

VALIDATION : Epoch 3
togrep : results : epoch 3 ; mean accuracy valid :              81.52
saving model at epoch 3

TRAINING : Epoch 4
Learning rate : 0.0970299
<class 'torch.Tensor'> tensor(5781) 5781
6336 ; loss 0.25 ; sentence/s 717 ; words/s 46230 ; accuracy train : 90.33
<class 'torch.Tensor'> tensor(11527) 11527
12736 ; loss 0.25 ; sentence/s 712 ; words/s 46899 ; accuracy train : 90.05
<class 'torch.Tensor'> tensor(17278) 17278
19136 ; loss 0.24 ; sentence/s 711 ; words/s 46541 ; accuracy train : 89.99
<class 'torch.Tensor'> tensor(23001) 23001
25536 ; loss 0.24 ; sentence/s 710 ; words/s 46736 ; accuracy train : 89.85
<class 'torch.Tensor'> tensor(28677) 28677
31936 ; loss 0.25 ; sentence/s 727 ; words/s 45825 ; accuracy train : 89.62
<class 'torch.Tensor'> tensor(34426) 34426
38336 ; loss 0.25 ; sentence/s 724 ; words/s 45673 ; accuracy train : 89.65
<class 'torch.Tensor'> tensor(40134) 40134
44736 ; loss 0.25 ; sentence/s 725 ; words/s 45391 ; accuracy train : 89.58
<class 'torch.Tensor'> tensor(45869) 45869
51136 ; loss 0.24 ; sentence/s 727 ; words/s 45279 ; accuracy train : 89.59
<class 'torch.Tensor'> tensor(51591) 51591
57536 ; loss 0.24 ; sentence/s 706 ; words/s 47143 ; accuracy train : 89.57
<class 'torch.Tensor'> tensor(57293) 57293
63936 ; loss 0.25 ; sentence/s 719 ; words/s 46188 ; accuracy train : 89.52
<class 'torch.Tensor'> tensor(63043) 63043
70336 ; loss 0.24 ; sentence/s 723 ; words/s 45709 ; accuracy train : 89.55
<class 'torch.Tensor'> tensor(68745) 68745
76736 ; loss 0.25 ; sentence/s 721 ; words/s 46308 ; accuracy train : 89.51
<class 'torch.Tensor'> tensor(74455) 74455
83136 ; loss 0.25 ; sentence/s 720 ; words/s 46288 ; accuracy train : 89.49
<class 'torch.Tensor'> tensor(80133) 80133
89536 ; loss 0.26 ; sentence/s 714 ; words/s 46153 ; accuracy train : 89.43
<class 'torch.Tensor'> tensor(85833) 85833
95936 ; loss 0.25 ; sentence/s 721 ; words/s 46323 ; accuracy train : 89.41
<class 'torch.Tensor'> tensor(91556) 91556
102336 ; loss 0.25 ; sentence/s 726 ; words/s 45956 ; accuracy train : 89.41
<class 'torch.Tensor'> tensor(97256) 97256
108736 ; loss 0.25 ; sentence/s 725 ; words/s 46149 ; accuracy train : 89.39
<class 'torch.Tensor'> tensor(102980) 102980
115136 ; loss 0.25 ; sentence/s 713 ; words/s 46858 ; accuracy train : 89.39
<class 'torch.Tensor'> tensor(108672) 108672
121536 ; loss 0.25 ; sentence/s 724 ; words/s 46260 ; accuracy train : 89.37
<class 'torch.Tensor'> tensor(114332) 114332
127936 ; loss 0.26 ; sentence/s 726 ; words/s 46005 ; accuracy train : 89.32
<class 'torch.Tensor'> tensor(119999) 119999
134336 ; loss 0.26 ; sentence/s 712 ; words/s 46304 ; accuracy train : 89.28
<class 'torch.Tensor'> tensor(125733) 125733
140736 ; loss 0.25 ; sentence/s 706 ; words/s 47087 ; accuracy train : 89.3
<class 'torch.Tensor'> tensor(131407) 131407
147136 ; loss 0.26 ; sentence/s 696 ; words/s 47512 ; accuracy train : 89.27
<class 'torch.Tensor'> tensor(137088) 137088
153536 ; loss 0.26 ; sentence/s 712 ; words/s 47245 ; accuracy train : 89.25
<class 'torch.Tensor'> tensor(142756) 142756
159936 ; loss 0.25 ; sentence/s 713 ; words/s 46879 ; accuracy train : 89.22
<class 'torch.Tensor'> tensor(148387) 148387
166336 ; loss 0.27 ; sentence/s 722 ; words/s 45882 ; accuracy train : 89.17
<class 'torch.Tensor'> tensor(154002) 154002
172736 ; loss 0.27 ; sentence/s 722 ; words/s 46423 ; accuracy train : 89.12
<class 'torch.Tensor'> tensor(159640) 159640
179136 ; loss 0.26 ; sentence/s 720 ; words/s 46343 ; accuracy train : 89.08
<class 'torch.Tensor'> tensor(165284) 165284
185536 ; loss 0.27 ; sentence/s 718 ; words/s 46667 ; accuracy train : 89.05
<class 'torch.Tensor'> tensor(170930) 170930
191936 ; loss 0.26 ; sentence/s 721 ; words/s 46462 ; accuracy train : 89.03
<class 'torch.Tensor'> tensor(176536) 176536
198336 ; loss 0.27 ; sentence/s 724 ; words/s 46039 ; accuracy train : 88.98
<class 'torch.Tensor'> tensor(182190) 182190
204736 ; loss 0.26 ; sentence/s 719 ; words/s 46860 ; accuracy train : 88.96
<class 'torch.Tensor'> tensor(187780) 187780
211136 ; loss 0.27 ; sentence/s 717 ; words/s 47055 ; accuracy train : 88.91
<class 'torch.Tensor'> tensor(193402) 193402
217536 ; loss 0.27 ; sentence/s 720 ; words/s 45928 ; accuracy train : 88.88
<class 'torch.Tensor'> tensor(199045) 199045
223936 ; loss 0.26 ; sentence/s 715 ; words/s 46310 ; accuracy train : 88.86
<class 'torch.Tensor'> tensor(204654) 204654
230336 ; loss 0.27 ; sentence/s 729 ; words/s 45935 ; accuracy train : 88.83
<class 'torch.Tensor'> tensor(210244) 210244
236736 ; loss 0.27 ; sentence/s 716 ; words/s 46555 ; accuracy train : 88.79
results : epoch 4 ; mean accuracy train : 88.79

VALIDATION : Epoch 4
togrep : results : epoch 4 ; mean accuracy valid :              80.29
Shrinking lr by : 5. New lr = 0.01940598

TRAINING : Epoch 5
Learning rate : 0.0192119202
<class 'torch.Tensor'> tensor(5879) 5879
6336 ; loss 0.2 ; sentence/s 710 ; words/s 47187 ; accuracy train : 91.86
<class 'torch.Tensor'> tensor(11872) 11872
12736 ; loss 0.18 ; sentence/s 725 ; words/s 45800 ; accuracy train : 92.75
<class 'torch.Tensor'> tensor(17838) 17838
19136 ; loss 0.18 ; sentence/s 721 ; words/s 45600 ; accuracy train : 92.91
<class 'torch.Tensor'> tensor(23787) 23787
25536 ; loss 0.19 ; sentence/s 718 ; words/s 46891 ; accuracy train : 92.92
<class 'torch.Tensor'> tensor(29789) 29789
31936 ; loss 0.17 ; sentence/s 711 ; words/s 46944 ; accuracy train : 93.09
<class 'torch.Tensor'> tensor(35755) 35755
38336 ; loss 0.18 ; sentence/s 716 ; words/s 46694 ; accuracy train : 93.11
<class 'torch.Tensor'> tensor(41764) 41764
44736 ; loss 0.17 ; sentence/s 717 ; words/s 46997 ; accuracy train : 93.22
<class 'torch.Tensor'> tensor(47764) 47764
51136 ; loss 0.17 ; sentence/s 722 ; words/s 46104 ; accuracy train : 93.29
<class 'torch.Tensor'> tensor(53747) 53747
57536 ; loss 0.17 ; sentence/s 718 ; words/s 45797 ; accuracy train : 93.31
<class 'torch.Tensor'> tensor(59754) 59754
63936 ; loss 0.17 ; sentence/s 718 ; words/s 45708 ; accuracy train : 93.37
<class 'torch.Tensor'> tensor(65771) 65771
70336 ; loss 0.17 ; sentence/s 707 ; words/s 46133 ; accuracy train : 93.42
<class 'torch.Tensor'> tensor(71766) 71766
76736 ; loss 0.17 ; sentence/s 710 ; words/s 46360 ; accuracy train : 93.45
<class 'torch.Tensor'> tensor(77773) 77773
83136 ; loss 0.17 ; sentence/s 717 ; words/s 47062 ; accuracy train : 93.48
<class 'torch.Tensor'> tensor(83802) 83802
89536 ; loss 0.16 ; sentence/s 708 ; words/s 47245 ; accuracy train : 93.53
<class 'torch.Tensor'> tensor(89832) 89832
95936 ; loss 0.17 ; sentence/s 721 ; words/s 46388 ; accuracy train : 93.58
<class 'torch.Tensor'> tensor(95872) 95872
102336 ; loss 0.16 ; sentence/s 731 ; words/s 46115 ; accuracy train : 93.62
<class 'torch.Tensor'> tensor(101883) 101883
108736 ; loss 0.17 ; sentence/s 733 ; words/s 46056 ; accuracy train : 93.64
<class 'torch.Tensor'> tensor(107902) 107902
115136 ; loss 0.16 ; sentence/s 706 ; words/s 47835 ; accuracy train : 93.66
<class 'torch.Tensor'> tensor(113915) 113915
121536 ; loss 0.16 ; sentence/s 730 ; words/s 46351 ; accuracy train : 93.68
<class 'torch.Tensor'> tensor(119914) 119914
127936 ; loss 0.17 ; sentence/s 721 ; words/s 46343 ; accuracy train : 93.68
<class 'torch.Tensor'> tensor(125926) 125926
134336 ; loss 0.16 ; sentence/s 710 ; words/s 47540 ; accuracy train : 93.69
<class 'torch.Tensor'> tensor(131929) 131929
140736 ; loss 0.16 ; sentence/s 730 ; words/s 45735 ; accuracy train : 93.7
<class 'torch.Tensor'> tensor(137944) 137944
147136 ; loss 0.16 ; sentence/s 725 ; words/s 46643 ; accuracy train : 93.71
<class 'torch.Tensor'> tensor(143961) 143961
153536 ; loss 0.16 ; sentence/s 724 ; words/s 46550 ; accuracy train : 93.72
<class 'torch.Tensor'> tensor(149967) 149967
159936 ; loss 0.16 ; sentence/s 719 ; words/s 46514 ; accuracy train : 93.73
<class 'torch.Tensor'> tensor(155976) 155976
166336 ; loss 0.16 ; sentence/s 727 ; words/s 45988 ; accuracy train : 93.74
<class 'torch.Tensor'> tensor(162011) 162011
172736 ; loss 0.16 ; sentence/s 729 ; words/s 45917 ; accuracy train : 93.76
<class 'torch.Tensor'> tensor(168060) 168060
179136 ; loss 0.15 ; sentence/s 715 ; words/s 47083 ; accuracy train : 93.78
<class 'torch.Tensor'> tensor(174061) 174061
185536 ; loss 0.16 ; sentence/s 709 ; words/s 47972 ; accuracy train : 93.78
<class 'torch.Tensor'> tensor(180095) 180095
191936 ; loss 0.16 ; sentence/s 730 ; words/s 46000 ; accuracy train : 93.8
<class 'torch.Tensor'> tensor(186154) 186154
198336 ; loss 0.15 ; sentence/s 722 ; words/s 46982 ; accuracy train : 93.83
<class 'torch.Tensor'> tensor(192176) 192176
204736 ; loss 0.16 ; sentence/s 714 ; words/s 46881 ; accuracy train : 93.84
<class 'torch.Tensor'> tensor(198198) 198198
211136 ; loss 0.16 ; sentence/s 719 ; words/s 46546 ; accuracy train : 93.84
<class 'torch.Tensor'> tensor(204258) 204258
217536 ; loss 0.15 ; sentence/s 717 ; words/s 46703 ; accuracy train : 93.87
<class 'torch.Tensor'> tensor(210290) 210290
223936 ; loss 0.16 ; sentence/s 734 ; words/s 45795 ; accuracy train : 93.88
<class 'torch.Tensor'> tensor(216290) 216290
230336 ; loss 0.16 ; sentence/s 731 ; words/s 45988 ; accuracy train : 93.88
<class 'torch.Tensor'> tensor(222335) 222335
236736 ; loss 0.16 ; sentence/s 718 ; words/s 46648 ; accuracy train : 93.89
results : epoch 5 ; mean accuracy train : 93.9

VALIDATION : Epoch 5
togrep : results : epoch 5 ; mean accuracy valid :              83.32
saving model at epoch 5

TRAINING : Epoch 6
Learning rate : 0.019019800998
<class 'torch.Tensor'> tensor(6115) 6115
6336 ; loss 0.14 ; sentence/s 724 ; words/s 45902 ; accuracy train : 95.55
<class 'torch.Tensor'> tensor(12223) 12223
12736 ; loss 0.14 ; sentence/s 727 ; words/s 46328 ; accuracy train : 95.49
<class 'torch.Tensor'> tensor(18357) 18357
19136 ; loss 0.13 ; sentence/s 716 ; words/s 46220 ; accuracy train : 95.61
<class 'torch.Tensor'> tensor(24503) 24503
25536 ; loss 0.13 ; sentence/s 720 ; words/s 46455 ; accuracy train : 95.71
<class 'torch.Tensor'> tensor(30614) 30614
31936 ; loss 0.13 ; sentence/s 711 ; words/s 47132 ; accuracy train : 95.67
<class 'torch.Tensor'> tensor(36704) 36704
38336 ; loss 0.14 ; sentence/s 707 ; words/s 48061 ; accuracy train : 95.58
<class 'torch.Tensor'> tensor(42831) 42831
44736 ; loss 0.13 ; sentence/s 733 ; words/s 45873 ; accuracy train : 95.6
<class 'torch.Tensor'> tensor(48913) 48913
51136 ; loss 0.14 ; sentence/s 718 ; words/s 46941 ; accuracy train : 95.53
<class 'torch.Tensor'> tensor(54996) 54996
57536 ; loss 0.14 ; sentence/s 712 ; words/s 47402 ; accuracy train : 95.48
<class 'torch.Tensor'> tensor(61129) 61129
63936 ; loss 0.13 ; sentence/s 736 ; words/s 45472 ; accuracy train : 95.51
<class 'torch.Tensor'> tensor(67228) 67228
70336 ; loss 0.14 ; sentence/s 735 ; words/s 45760 ; accuracy train : 95.49
<class 'torch.Tensor'> tensor(73327) 73327
76736 ; loss 0.13 ; sentence/s 731 ; words/s 46181 ; accuracy train : 95.48
<class 'torch.Tensor'> tensor(79411) 79411
83136 ; loss 0.14 ; sentence/s 729 ; words/s 46160 ; accuracy train : 95.45
<class 'torch.Tensor'> tensor(85514) 85514
89536 ; loss 0.13 ; sentence/s 728 ; words/s 46055 ; accuracy train : 95.44
<class 'torch.Tensor'> tensor(91634) 91634
95936 ; loss 0.13 ; sentence/s 727 ; words/s 45947 ; accuracy train : 95.45
<class 'torch.Tensor'> tensor(97706) 97706
102336 ; loss 0.14 ; sentence/s 740 ; words/s 45412 ; accuracy train : 95.42
<class 'torch.Tensor'> tensor(103812) 103812
108736 ; loss 0.13 ; sentence/s 714 ; words/s 46719 ; accuracy train : 95.42
<class 'torch.Tensor'> tensor(109921) 109921
115136 ; loss 0.14 ; sentence/s 720 ; words/s 46723 ; accuracy train : 95.42
<class 'torch.Tensor'> tensor(116020) 116020
121536 ; loss 0.13 ; sentence/s 723 ; words/s 46500 ; accuracy train : 95.41
<class 'torch.Tensor'> tensor(122135) 122135
127936 ; loss 0.13 ; sentence/s 716 ; words/s 46472 ; accuracy train : 95.42
<class 'torch.Tensor'> tensor(128239) 128239
134336 ; loss 0.14 ; sentence/s 729 ; words/s 45829 ; accuracy train : 95.42
<class 'torch.Tensor'> tensor(134358) 134358
140736 ; loss 0.13 ; sentence/s 719 ; words/s 46642 ; accuracy train : 95.42
<class 'torch.Tensor'> tensor(140442) 140442
147136 ; loss 0.14 ; sentence/s 713 ; words/s 47049 ; accuracy train : 95.41
<class 'torch.Tensor'> tensor(146526) 146526
153536 ; loss 0.14 ; sentence/s 706 ; words/s 47765 ; accuracy train : 95.39
<class 'torch.Tensor'> tensor(152623) 152623
159936 ; loss 0.14 ; sentence/s 719 ; words/s 46702 ; accuracy train : 95.39
<class 'torch.Tensor'> tensor(158672) 158672
166336 ; loss 0.14 ; sentence/s 713 ; words/s 47135 ; accuracy train : 95.36
<class 'torch.Tensor'> tensor(164735) 164735
172736 ; loss 0.14 ; sentence/s 729 ; words/s 45682 ; accuracy train : 95.33
<class 'torch.Tensor'> tensor(170831) 170831
179136 ; loss 0.14 ; sentence/s 719 ; words/s 46757 ; accuracy train : 95.33
<class 'torch.Tensor'> tensor(176914) 176914
185536 ; loss 0.14 ; sentence/s 710 ; words/s 46970 ; accuracy train : 95.32
<class 'torch.Tensor'> tensor(182964) 182964
191936 ; loss 0.14 ; sentence/s 709 ; words/s 47611 ; accuracy train : 95.29
<class 'torch.Tensor'> tensor(189055) 189055
198336 ; loss 0.14 ; sentence/s 726 ; words/s 45837 ; accuracy train : 95.29
<class 'torch.Tensor'> tensor(195139) 195139
204736 ; loss 0.14 ; sentence/s 713 ; words/s 47152 ; accuracy train : 95.28
<class 'torch.Tensor'> tensor(201215) 201215
211136 ; loss 0.14 ; sentence/s 714 ; words/s 46873 ; accuracy train : 95.27
<class 'torch.Tensor'> tensor(207290) 207290
217536 ; loss 0.13 ; sentence/s 725 ; words/s 46821 ; accuracy train : 95.26
<class 'torch.Tensor'> tensor(213372) 213372
223936 ; loss 0.14 ; sentence/s 713 ; words/s 46707 ; accuracy train : 95.26
<class 'torch.Tensor'> tensor(219456) 219456
230336 ; loss 0.14 ; sentence/s 722 ; words/s 46484 ; accuracy train : 95.25
<class 'torch.Tensor'> tensor(225566) 225566
236736 ; loss 0.13 ; sentence/s 712 ; words/s 46680 ; accuracy train : 95.26
results : epoch 6 ; mean accuracy train : 95.25

VALIDATION : Epoch 6
togrep : results : epoch 6 ; mean accuracy valid :              83.19
Shrinking lr by : 5. New lr = 0.0038039601995999996

TRAINING : Epoch 7
Learning rate : 0.0037659205976039996
<class 'torch.Tensor'> tensor(6155) 6155
6336 ; loss 0.12 ; sentence/s 709 ; words/s 47143 ; accuracy train : 96.17
<class 'torch.Tensor'> tensor(12347) 12347
12736 ; loss 0.11 ; sentence/s 726 ; words/s 45830 ; accuracy train : 96.46
<class 'torch.Tensor'> tensor(18518) 18518
19136 ; loss 0.11 ; sentence/s 713 ; words/s 47287 ; accuracy train : 96.45
<class 'torch.Tensor'> tensor(24701) 24701
25536 ; loss 0.11 ; sentence/s 725 ; words/s 46523 ; accuracy train : 96.49
<class 'torch.Tensor'> tensor(30887) 30887
31936 ; loss 0.11 ; sentence/s 719 ; words/s 46500 ; accuracy train : 96.52
<class 'torch.Tensor'> tensor(37080) 37080
38336 ; loss 0.11 ; sentence/s 724 ; words/s 46367 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(43263) 43263
44736 ; loss 0.11 ; sentence/s 730 ; words/s 46077 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(49443) 49443
51136 ; loss 0.11 ; sentence/s 730 ; words/s 45458 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(55620) 55620
57536 ; loss 0.11 ; sentence/s 708 ; words/s 47138 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(61791) 61791
63936 ; loss 0.11 ; sentence/s 720 ; words/s 46901 ; accuracy train : 96.55
<class 'torch.Tensor'> tensor(67975) 67975
70336 ; loss 0.12 ; sentence/s 714 ; words/s 47025 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(74168) 74168
76736 ; loss 0.1 ; sentence/s 732 ; words/s 46005 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(80354) 80354
83136 ; loss 0.11 ; sentence/s 718 ; words/s 47050 ; accuracy train : 96.58
<class 'torch.Tensor'> tensor(86508) 86508
89536 ; loss 0.11 ; sentence/s 722 ; words/s 46650 ; accuracy train : 96.55
<class 'torch.Tensor'> tensor(92710) 92710
95936 ; loss 0.11 ; sentence/s 729 ; words/s 46352 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(98926) 98926
102336 ; loss 0.11 ; sentence/s 713 ; words/s 46683 ; accuracy train : 96.61
<class 'torch.Tensor'> tensor(105066) 105066
108736 ; loss 0.12 ; sentence/s 716 ; words/s 46598 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(111253) 111253
115136 ; loss 0.11 ; sentence/s 718 ; words/s 46345 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(117432) 117432
121536 ; loss 0.11 ; sentence/s 709 ; words/s 47006 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(123640) 123640
127936 ; loss 0.1 ; sentence/s 720 ; words/s 46720 ; accuracy train : 96.59
<class 'torch.Tensor'> tensor(129796) 129796
134336 ; loss 0.11 ; sentence/s 707 ; words/s 47623 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(135957) 135957
140736 ; loss 0.11 ; sentence/s 727 ; words/s 46224 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(142121) 142121
147136 ; loss 0.11 ; sentence/s 711 ; words/s 47203 ; accuracy train : 96.55
<class 'torch.Tensor'> tensor(148310) 148310
153536 ; loss 0.11 ; sentence/s 727 ; words/s 46385 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(154503) 154503
159936 ; loss 0.11 ; sentence/s 718 ; words/s 46273 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(160685) 160685
166336 ; loss 0.11 ; sentence/s 737 ; words/s 45607 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(166890) 166890
172736 ; loss 0.11 ; sentence/s 703 ; words/s 47646 ; accuracy train : 96.58
<class 'torch.Tensor'> tensor(173054) 173054
179136 ; loss 0.12 ; sentence/s 716 ; words/s 46069 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(179215) 179215
185536 ; loss 0.11 ; sentence/s 718 ; words/s 46849 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(185389) 185389
191936 ; loss 0.11 ; sentence/s 719 ; words/s 46669 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(191567) 191567
198336 ; loss 0.11 ; sentence/s 712 ; words/s 46943 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(197748) 197748
204736 ; loss 0.11 ; sentence/s 716 ; words/s 46972 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(203937) 203937
211136 ; loss 0.11 ; sentence/s 716 ; words/s 46124 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(210126) 210126
217536 ; loss 0.11 ; sentence/s 725 ; words/s 46163 ; accuracy train : 96.57
<class 'torch.Tensor'> tensor(216300) 216300
223936 ; loss 0.11 ; sentence/s 733 ; words/s 45573 ; accuracy train : 96.56
<class 'torch.Tensor'> tensor(222447) 222447
230336 ; loss 0.12 ; sentence/s 714 ; words/s 46467 ; accuracy train : 96.55
<class 'torch.Tensor'> tensor(228630) 228630
236736 ; loss 0.11 ; sentence/s 728 ; words/s 46210 ; accuracy train : 96.55
results : epoch 7 ; mean accuracy train : 96.56

VALIDATION : Epoch 7
togrep : results : epoch 7 ; mean accuracy valid :              83.24
Shrinking lr by : 5. New lr = 0.0007531841195207999

TRAINING : Epoch 8
Learning rate : 0.0007456522783255919
<class 'torch.Tensor'> tensor(6179) 6179
6336 ; loss 0.11 ; sentence/s 726 ; words/s 45797 ; accuracy train : 96.55
<class 'torch.Tensor'> tensor(12379) 12379
12736 ; loss 0.1 ; sentence/s 719 ; words/s 46002 ; accuracy train : 96.71
<class 'torch.Tensor'> tensor(18590) 18590
19136 ; loss 0.1 ; sentence/s 709 ; words/s 47061 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(24806) 24806
25536 ; loss 0.1 ; sentence/s 727 ; words/s 45479 ; accuracy train : 96.9
<class 'torch.Tensor'> tensor(31008) 31008
31936 ; loss 0.11 ; sentence/s 699 ; words/s 47650 ; accuracy train : 96.9
<class 'torch.Tensor'> tensor(37218) 37218
38336 ; loss 0.1 ; sentence/s 725 ; words/s 45993 ; accuracy train : 96.92
<class 'torch.Tensor'> tensor(43435) 43435
44736 ; loss 0.1 ; sentence/s 715 ; words/s 46844 ; accuracy train : 96.95
<class 'torch.Tensor'> tensor(49615) 49615
51136 ; loss 0.1 ; sentence/s 704 ; words/s 47425 ; accuracy train : 96.9
<class 'torch.Tensor'> tensor(55788) 55788
57536 ; loss 0.11 ; sentence/s 719 ; words/s 46266 ; accuracy train : 96.85
<class 'torch.Tensor'> tensor(61981) 61981
63936 ; loss 0.11 ; sentence/s 719 ; words/s 46565 ; accuracy train : 96.85
<class 'torch.Tensor'> tensor(68153) 68153
70336 ; loss 0.11 ; sentence/s 720 ; words/s 46418 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(74357) 74357
76736 ; loss 0.1 ; sentence/s 696 ; words/s 48092 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(80547) 80547
83136 ; loss 0.11 ; sentence/s 724 ; words/s 45875 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(86761) 86761
89536 ; loss 0.1 ; sentence/s 722 ; words/s 45753 ; accuracy train : 96.83
<class 'torch.Tensor'> tensor(92922) 92922
95936 ; loss 0.11 ; sentence/s 722 ; words/s 46068 ; accuracy train : 96.79
<class 'torch.Tensor'> tensor(99127) 99127
102336 ; loss 0.11 ; sentence/s 702 ; words/s 48288 ; accuracy train : 96.8
<class 'torch.Tensor'> tensor(105334) 105334
108736 ; loss 0.1 ; sentence/s 724 ; words/s 46468 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(111519) 111519
115136 ; loss 0.11 ; sentence/s 718 ; words/s 46259 ; accuracy train : 96.8
<class 'torch.Tensor'> tensor(117715) 117715
121536 ; loss 0.1 ; sentence/s 740 ; words/s 45282 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(123921) 123921
127936 ; loss 0.11 ; sentence/s 718 ; words/s 46597 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(130127) 130127
134336 ; loss 0.11 ; sentence/s 724 ; words/s 46723 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(136324) 136324
140736 ; loss 0.1 ; sentence/s 714 ; words/s 46670 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(142522) 142522
147136 ; loss 0.1 ; sentence/s 711 ; words/s 47029 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(148741) 148741
153536 ; loss 0.1 ; sentence/s 719 ; words/s 46019 ; accuracy train : 96.84
<class 'torch.Tensor'> tensor(154947) 154947
159936 ; loss 0.1 ; sentence/s 715 ; words/s 46339 ; accuracy train : 96.84
<class 'torch.Tensor'> tensor(161144) 161144
166336 ; loss 0.1 ; sentence/s 716 ; words/s 47126 ; accuracy train : 96.84
<class 'torch.Tensor'> tensor(167312) 167312
172736 ; loss 0.11 ; sentence/s 726 ; words/s 45831 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(173512) 173512
179136 ; loss 0.11 ; sentence/s 721 ; words/s 46141 ; accuracy train : 96.83
<class 'torch.Tensor'> tensor(179725) 179725
185536 ; loss 0.1 ; sentence/s 714 ; words/s 47716 ; accuracy train : 96.83
<class 'torch.Tensor'> tensor(185894) 185894
191936 ; loss 0.11 ; sentence/s 718 ; words/s 46508 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(192097) 192097
198336 ; loss 0.11 ; sentence/s 723 ; words/s 46843 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(198280) 198280
204736 ; loss 0.11 ; sentence/s 716 ; words/s 46977 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(204477) 204477
211136 ; loss 0.11 ; sentence/s 728 ; words/s 45692 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(210646) 210646
217536 ; loss 0.11 ; sentence/s 717 ; words/s 45822 ; accuracy train : 96.8
<class 'torch.Tensor'> tensor(216847) 216847
223936 ; loss 0.11 ; sentence/s 722 ; words/s 46222 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(223034) 223034
230336 ; loss 0.11 ; sentence/s 737 ; words/s 45234 ; accuracy train : 96.8
<class 'torch.Tensor'> tensor(229238) 229238
236736 ; loss 0.1 ; sentence/s 709 ; words/s 47390 ; accuracy train : 96.81
results : epoch 8 ; mean accuracy train : 96.8

VALIDATION : Epoch 8
togrep : results : epoch 8 ; mean accuracy valid :              83.25
Shrinking lr by : 5. New lr = 0.00014913045566511838

TRAINING : Epoch 9
Learning rate : 0.00014763915110846718
<class 'torch.Tensor'> tensor(6199) 6199
6336 ; loss 0.1 ; sentence/s 703 ; words/s 47237 ; accuracy train : 96.86
<class 'torch.Tensor'> tensor(12394) 12394
12736 ; loss 0.11 ; sentence/s 720 ; words/s 46375 ; accuracy train : 96.83
<class 'torch.Tensor'> tensor(18593) 18593
19136 ; loss 0.1 ; sentence/s 709 ; words/s 47323 ; accuracy train : 96.84
<class 'torch.Tensor'> tensor(24791) 24791
25536 ; loss 0.11 ; sentence/s 737 ; words/s 45170 ; accuracy train : 96.84
<class 'torch.Tensor'> tensor(31000) 31000
31936 ; loss 0.1 ; sentence/s 722 ; words/s 46402 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(37206) 37206
38336 ; loss 0.1 ; sentence/s 723 ; words/s 46045 ; accuracy train : 96.89
<class 'torch.Tensor'> tensor(43393) 43393
44736 ; loss 0.1 ; sentence/s 718 ; words/s 47261 ; accuracy train : 96.86
<class 'torch.Tensor'> tensor(49570) 49570
51136 ; loss 0.11 ; sentence/s 713 ; words/s 47072 ; accuracy train : 96.82
<class 'torch.Tensor'> tensor(55747) 55747
57536 ; loss 0.11 ; sentence/s 723 ; words/s 46038 ; accuracy train : 96.78
<class 'torch.Tensor'> tensor(61945) 61945
63936 ; loss 0.1 ; sentence/s 713 ; words/s 46535 ; accuracy train : 96.79
<class 'torch.Tensor'> tensor(68129) 68129
70336 ; loss 0.11 ; sentence/s 719 ; words/s 46104 ; accuracy train : 96.77
<class 'torch.Tensor'> tensor(74348) 74348
76736 ; loss 0.1 ; sentence/s 730 ; words/s 45624 ; accuracy train : 96.81
<class 'torch.Tensor'> tensor(80538) 80538
83136 ; loss 0.1 ; sentence/s 714 ; words/s 46861 ; accuracy train : 96.8
<class 'torch.Tensor'> tensor(86730) 86730
89536 ; loss 0.1 ; sentence/s 711 ; words/s 47264 ; accuracy train : 96.8
<class 'torch.Tensor'> tensor(92953) 92953
95936 ; loss 0.1 ; sentence/s 726 ; words/s 46323 ; accuracy train : 96.83
<class 'torch.Tensor'> tensor(99172) 99172
102336 ; loss 0.1 ; sentence/s 709 ; words/s 46717 ; accuracy train : 96.85
<class 'torch.Tensor'> tensor(105400) 105400
108736 ; loss 0.1 ; sentence/s 720 ; words/s 45918 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(111622) 111622
115136 ; loss 0.1 ; sentence/s 729 ; words/s 45456 ; accuracy train : 96.89
<class 'torch.Tensor'> tensor(117798) 117798
121536 ; loss 0.11 ; sentence/s 722 ; words/s 46289 ; accuracy train : 96.87
<class 'torch.Tensor'> tensor(124011) 124011
127936 ; loss 0.1 ; sentence/s 712 ; words/s 46659 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(130180) 130180
134336 ; loss 0.11 ; sentence/s 732 ; words/s 45296 ; accuracy train : 96.86
<class 'torch.Tensor'> tensor(136388) 136388
140736 ; loss 0.1 ; sentence/s 721 ; words/s 46281 ; accuracy train : 96.87
<class 'torch.Tensor'> tensor(142612) 142612
147136 ; loss 0.1 ; sentence/s 712 ; words/s 46936 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(148810) 148810
153536 ; loss 0.11 ; sentence/s 713 ; words/s 46285 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(154973) 154973
159936 ; loss 0.11 ; sentence/s 723 ; words/s 46373 ; accuracy train : 96.86
<class 'torch.Tensor'> tensor(161190) 161190
166336 ; loss 0.1 ; sentence/s 723 ; words/s 46421 ; accuracy train : 96.87
<class 'torch.Tensor'> tensor(167400) 167400
172736 ; loss 0.1 ; sentence/s 718 ; words/s 46561 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(173615) 173615
179136 ; loss 0.1 ; sentence/s 710 ; words/s 46857 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(179800) 179800
185536 ; loss 0.11 ; sentence/s 720 ; words/s 45775 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(186016) 186016
191936 ; loss 0.1 ; sentence/s 706 ; words/s 46861 ; accuracy train : 96.88
<class 'torch.Tensor'> tensor(192220) 192220
198336 ; loss 0.1 ; sentence/s 714 ; words/s 46192 ; accuracy train : 96.89
<class 'torch.Tensor'> tensor(198444) 198444
204736 ; loss 0.1 ; sentence/s 725 ; words/s 45912 ; accuracy train : 96.9
<class 'torch.Tensor'> tensor(204665) 204665
211136 ; loss 0.1 ; sentence/s 721 ; words/s 46630 ; accuracy train : 96.91
<class 'torch.Tensor'> tensor(210898) 210898
217536 ; loss 0.1 ; sentence/s 718 ; words/s 46593 ; accuracy train : 96.92
<class 'torch.Tensor'> tensor(217102) 217102
223936 ; loss 0.11 ; sentence/s 707 ; words/s 46947 ; accuracy train : 96.92
<class 'torch.Tensor'> tensor(223296) 223296
230336 ; loss 0.1 ; sentence/s 712 ; words/s 46956 ; accuracy train : 96.92
<class 'torch.Tensor'> tensor(229504) 229504
236736 ; loss 0.1 ; sentence/s 696 ; words/s 48106 ; accuracy train : 96.92
results : epoch 9 ; mean accuracy train : 96.92

VALIDATION : Epoch 9
togrep : results : epoch 9 ; mean accuracy valid :              83.39
saving model at epoch 9

TRAINING : Epoch 10
Learning rate : 0.0001461627595973825
<class 'torch.Tensor'> tensor(6229) 6229
6336 ; loss 0.1 ; sentence/s 704 ; words/s 45986 ; accuracy train : 97.33
<class 'torch.Tensor'> tensor(12423) 12423
12736 ; loss 0.11 ; sentence/s 724 ; words/s 46366 ; accuracy train : 97.05
<class 'torch.Tensor'> tensor(18640) 18640
19136 ; loss 0.1 ; sentence/s 726 ; words/s 46713 ; accuracy train : 97.08
<class 'torch.Tensor'> tensor(24845) 24845
25536 ; loss 0.1 ; sentence/s 727 ; words/s 46124 ; accuracy train : 97.05
<class 'torch.Tensor'> tensor(31030) 31030
31936 ; loss 0.11 ; sentence/s 728 ; words/s 46133 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(37252) 37252
38336 ; loss 0.1 ; sentence/s 721 ; words/s 46690 ; accuracy train : 97.01
<class 'torch.Tensor'> tensor(43448) 43448
44736 ; loss 0.1 ; sentence/s 730 ; words/s 45789 ; accuracy train : 96.98
<class 'torch.Tensor'> tensor(49673) 49673
51136 ; loss 0.1 ; sentence/s 712 ; words/s 47212 ; accuracy train : 97.02
<class 'torch.Tensor'> tensor(55870) 55870
57536 ; loss 0.11 ; sentence/s 732 ; words/s 46269 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(62063) 62063
63936 ; loss 0.11 ; sentence/s 736 ; words/s 45827 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(68253) 68253
70336 ; loss 0.11 ; sentence/s 720 ; words/s 47051 ; accuracy train : 96.95
<class 'torch.Tensor'> tensor(74472) 74472
76736 ; loss 0.1 ; sentence/s 721 ; words/s 46783 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(80662) 80662
83136 ; loss 0.11 ; sentence/s 726 ; words/s 46284 ; accuracy train : 96.95
<class 'torch.Tensor'> tensor(86879) 86879
89536 ; loss 0.1 ; sentence/s 718 ; words/s 46362 ; accuracy train : 96.96
<class 'torch.Tensor'> tensor(93109) 93109
95936 ; loss 0.1 ; sentence/s 726 ; words/s 47000 ; accuracy train : 96.99
<class 'torch.Tensor'> tensor(99293) 99293
102336 ; loss 0.11 ; sentence/s 726 ; words/s 46149 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(105531) 105531
108736 ; loss 0.1 ; sentence/s 704 ; words/s 47211 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(111737) 111737
115136 ; loss 0.1 ; sentence/s 721 ; words/s 46336 ; accuracy train : 96.99
<class 'torch.Tensor'> tensor(117934) 117934
121536 ; loss 0.1 ; sentence/s 712 ; words/s 47247 ; accuracy train : 96.99
<class 'torch.Tensor'> tensor(124155) 124155
127936 ; loss 0.1 ; sentence/s 724 ; words/s 46196 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(130367) 130367
134336 ; loss 0.1 ; sentence/s 726 ; words/s 45792 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(136564) 136564
140736 ; loss 0.11 ; sentence/s 723 ; words/s 45794 ; accuracy train : 96.99
<class 'torch.Tensor'> tensor(142768) 142768
147136 ; loss 0.1 ; sentence/s 709 ; words/s 46929 ; accuracy train : 96.99
<class 'torch.Tensor'> tensor(148987) 148987
153536 ; loss 0.1 ; sentence/s 720 ; words/s 46542 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(155204) 155204
159936 ; loss 0.1 ; sentence/s 719 ; words/s 46534 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(161407) 161407
166336 ; loss 0.1 ; sentence/s 725 ; words/s 46527 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(167610) 167610
172736 ; loss 0.1 ; sentence/s 708 ; words/s 47333 ; accuracy train : 97.0
<class 'torch.Tensor'> tensor(173806) 173806
179136 ; loss 0.1 ; sentence/s 725 ; words/s 46250 ; accuracy train : 96.99
<class 'torch.Tensor'> tensor(179996) 179996
185536 ; loss 0.11 ; sentence/s 712 ; words/s 47588 ; accuracy train : 96.98
<class 'torch.Tensor'> tensor(186185) 186185
191936 ; loss 0.11 ; sentence/s 728 ; words/s 46163 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(192383) 192383
198336 ; loss 0.1 ; sentence/s 714 ; words/s 46718 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(198588) 198588
204736 ; loss 0.1 ; sentence/s 724 ; words/s 46442 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(204792) 204792
211136 ; loss 0.11 ; sentence/s 728 ; words/s 46224 ; accuracy train : 96.97
<class 'torch.Tensor'> tensor(210982) 210982
217536 ; loss 0.11 ; sentence/s 715 ; words/s 46829 ; accuracy train : 96.96
<class 'torch.Tensor'> tensor(217185) 217185
223936 ; loss 0.1 ; sentence/s 740 ; words/s 45455 ; accuracy train : 96.96
<class 'torch.Tensor'> tensor(223399) 223399
230336 ; loss 0.1 ; sentence/s 710 ; words/s 47532 ; accuracy train : 96.96
<class 'torch.Tensor'> tensor(229622) 229622
236736 ; loss 0.1 ; sentence/s 705 ; words/s 48015 ; accuracy train : 96.97
results : epoch 10 ; mean accuracy train : 96.96

VALIDATION : Epoch 10
togrep : results : epoch 10 ; mean accuracy valid :              83.37
Shrinking lr by : 5. New lr = 2.92325519194765e-05
saving state dict
