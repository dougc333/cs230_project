
togrep : []

<<<<<<< HEAD
Namespace(LSTM_num_layers=1, batch_size=128, data_dir='/home/ubuntu/cs230_project/dataset', decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='InferSent', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=2, n_enc_layers=1, n_epochs=12, nlipath='/home/ubuntu/InferSent/dataset/SNLI', nonlinear_fc=0, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='3layerlinear.pickle', pool_type='max', seed=1234, weight_decay=0.0005, word_emb_dim=300)
=======
Namespace(LSTM_num_layers=1, batch_size=128, data_dir='/home/dc/cs230_project/dataset', decay=0.99, dpout_fc=0.0, dpout_model=0.0, enc_lstm_dim=2048, encoder_type='InferSent', fc_dim=512, gpu_id=0, lrshrink=5, max_norm=5.0, minlr=1e-05, n_classes=2, n_enc_layers=1, n_epochs=12, nlipath='/home/dc/InferSent/dataset/SNLI', nonlinear_fc=0, optimizer='sgd,lr=0.1', outputdir='savedir/', outputmodelname='3layerlinear.pickle', pool_type='max', seed=1234, weight_decay=0.0005, word_emb_dim=300)
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
quora checkpoint len(train[s1]):60623,len(train[s2]):60623,          len(train[label]):60623
============
len(valid['s1']):20208, len(valid[s2]):20208,           len(valid['label']):20208
============
len(test['s1']):20208,len(test['s2']):20208,           len(test['label']):20208
Found 47877(/106290) words with glove vectors
Vocab size : 47877
self.inputdim:16384, self.fc_dim:512
<class 'int'> <class 'int'>
NLINet(
  (encoder): InferSent(
    (enc_lstm): LSTM(300, 2048, bidirectional=True)
  )
  (classifier): Sequential(
    (0): Linear(in_features=16384, out_features=512, bias=True)
    (1): Linear(in_features=512, out_features=512, bias=True)
    (2): Linear(in_features=512, out_features=2, bias=True)
  )
)
total num epochs:12

TRAINING : Epoch 1
Learning rate : 0.1
<class 'torch.Tensor'> tensor(4899) 4899
<<<<<<< HEAD
12672 ; loss 0.7 ; sentence/s 919 ; words/s 68051 ; accuracy train : 38.27
<class 'torch.Tensor'> tensor(12852) 12852
25472 ; loss 0.69 ; sentence/s 937 ; words/s 66842 ; accuracy train : 50.2
<class 'torch.Tensor'> tensor(20889) 20889
38272 ; loss 0.68 ; sentence/s 918 ; words/s 68923 ; accuracy train : 54.4
<class 'torch.Tensor'> tensor(28923) 28923
51072 ; loss 0.68 ; sentence/s 915 ; words/s 69234 ; accuracy train : 56.49
=======
12672 ; loss 0.7 ; sentence/s 474 ; words/s 35153 ; accuracy train : 38.27
<class 'torch.Tensor'> tensor(12852) 12852
25472 ; loss 0.69 ; sentence/s 479 ; words/s 34209 ; accuracy train : 50.2
<class 'torch.Tensor'> tensor(20889) 20889
38272 ; loss 0.68 ; sentence/s 463 ; words/s 34800 ; accuracy train : 54.4
<class 'torch.Tensor'> tensor(28923) 28923
51072 ; loss 0.68 ; sentence/s 456 ; words/s 34484 ; accuracy train : 56.49
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 1 ; mean accuracy train : 57.57

VALIDATION : Epoch 1
togrep : results : epoch 1 ; mean accuracy valid :              62.53
saving model at epoch 1

TRAINING : Epoch 2
Learning rate : 0.099
<class 'torch.Tensor'> tensor(8043) 8043
<<<<<<< HEAD
12672 ; loss 0.67 ; sentence/s 919 ; words/s 67737 ; accuracy train : 62.84
<class 'torch.Tensor'> tensor(16071) 16071
25472 ; loss 0.67 ; sentence/s 924 ; words/s 68622 ; accuracy train : 62.78
<class 'torch.Tensor'> tensor(24115) 24115
38272 ; loss 0.66 ; sentence/s 934 ; words/s 67124 ; accuracy train : 62.8
<class 'torch.Tensor'> tensor(32113) 32113
51072 ; loss 0.66 ; sentence/s 918 ; words/s 68487 ; accuracy train : 62.72
=======
12672 ; loss 0.67 ; sentence/s 464 ; words/s 34238 ; accuracy train : 62.84
<class 'torch.Tensor'> tensor(16071) 16071
25472 ; loss 0.67 ; sentence/s 461 ; words/s 34270 ; accuracy train : 62.78
<class 'torch.Tensor'> tensor(24115) 24115
38272 ; loss 0.66 ; sentence/s 465 ; words/s 33478 ; accuracy train : 62.8
<class 'torch.Tensor'> tensor(32113) 32113
51072 ; loss 0.66 ; sentence/s 460 ; words/s 34338 ; accuracy train : 62.72
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 2 ; mean accuracy train : 62.82

VALIDATION : Epoch 2
togrep : results : epoch 2 ; mean accuracy valid :              62.53
Shrinking lr by : 5. New lr = 0.0198

TRAINING : Epoch 3
Learning rate : 0.019602
<class 'torch.Tensor'> tensor(8078) 8078
<<<<<<< HEAD
12672 ; loss 0.66 ; sentence/s 921 ; words/s 67867 ; accuracy train : 63.11
<class 'torch.Tensor'> tensor(16079) 16079
25472 ; loss 0.66 ; sentence/s 936 ; words/s 66603 ; accuracy train : 62.81
<class 'torch.Tensor'> tensor(24162) 24162
38272 ; loss 0.66 ; sentence/s 917 ; words/s 67711 ; accuracy train : 62.92
<class 'torch.Tensor'> tensor(32131) 32131
51072 ; loss 0.66 ; sentence/s 911 ; words/s 69811 ; accuracy train : 62.76
=======
12672 ; loss 0.66 ; sentence/s 469 ; words/s 34580 ; accuracy train : 63.11
<class 'torch.Tensor'> tensor(16079) 16079
25472 ; loss 0.66 ; sentence/s 476 ; words/s 33870 ; accuracy train : 62.81
<class 'torch.Tensor'> tensor(24162) 24162
38272 ; loss 0.66 ; sentence/s 465 ; words/s 34380 ; accuracy train : 62.92
<class 'torch.Tensor'> tensor(32131) 32131
51072 ; loss 0.66 ; sentence/s 459 ; words/s 35219 ; accuracy train : 62.76
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 3 ; mean accuracy train : 62.82

VALIDATION : Epoch 3
togrep : results : epoch 3 ; mean accuracy valid :              62.53
Shrinking lr by : 5. New lr = 0.0039204

TRAINING : Epoch 4
Learning rate : 0.003881196
<class 'torch.Tensor'> tensor(8039) 8039
<<<<<<< HEAD
12672 ; loss 0.66 ; sentence/s 898 ; words/s 69396 ; accuracy train : 62.8
<class 'torch.Tensor'> tensor(16037) 16037
25472 ; loss 0.66 ; sentence/s 933 ; words/s 67018 ; accuracy train : 62.64
<class 'torch.Tensor'> tensor(24039) 24039
38272 ; loss 0.66 ; sentence/s 921 ; words/s 68497 ; accuracy train : 62.6
<class 'torch.Tensor'> tensor(32127) 32127
51072 ; loss 0.66 ; sentence/s 915 ; words/s 68199 ; accuracy train : 62.75
=======
12672 ; loss 0.66 ; sentence/s 457 ; words/s 35349 ; accuracy train : 62.8
<class 'torch.Tensor'> tensor(16037) 16037
25472 ; loss 0.66 ; sentence/s 474 ; words/s 34110 ; accuracy train : 62.64
<class 'torch.Tensor'> tensor(24039) 24039
38272 ; loss 0.66 ; sentence/s 467 ; words/s 34744 ; accuracy train : 62.6
<class 'torch.Tensor'> tensor(32127) 32127
51072 ; loss 0.66 ; sentence/s 465 ; words/s 34670 ; accuracy train : 62.75
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 4 ; mean accuracy train : 62.82

VALIDATION : Epoch 4
togrep : results : epoch 4 ; mean accuracy valid :              62.53
Shrinking lr by : 5. New lr = 0.0007762392

TRAINING : Epoch 5
Learning rate : 0.0007684768080000001
<class 'torch.Tensor'> tensor(8136) 8136
<<<<<<< HEAD
12672 ; loss 0.66 ; sentence/s 935 ; words/s 66543 ; accuracy train : 63.56
<class 'torch.Tensor'> tensor(16216) 16216
25472 ; loss 0.66 ; sentence/s 928 ; words/s 67254 ; accuracy train : 63.34
<class 'torch.Tensor'> tensor(24182) 24182
38272 ; loss 0.66 ; sentence/s 926 ; words/s 67608 ; accuracy train : 62.97
<class 'torch.Tensor'> tensor(32168) 32168
51072 ; loss 0.66 ; sentence/s 905 ; words/s 69773 ; accuracy train : 62.83
=======
12672 ; loss 0.66 ; sentence/s 474 ; words/s 33726 ; accuracy train : 63.56
<class 'torch.Tensor'> tensor(16216) 16216
25472 ; loss 0.66 ; sentence/s 462 ; words/s 33526 ; accuracy train : 63.34
<class 'torch.Tensor'> tensor(24182) 24182
38272 ; loss 0.66 ; sentence/s 470 ; words/s 34355 ; accuracy train : 62.97
<class 'torch.Tensor'> tensor(32168) 32168
51072 ; loss 0.66 ; sentence/s 457 ; words/s 35256 ; accuracy train : 62.83
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 5 ; mean accuracy train : 62.82

VALIDATION : Epoch 5
togrep : results : epoch 5 ; mean accuracy valid :              62.53
Shrinking lr by : 5. New lr = 0.00015369536160000002

TRAINING : Epoch 6
Learning rate : 0.00015215840798400002
<class 'torch.Tensor'> tensor(8024) 8024
<<<<<<< HEAD
12672 ; loss 0.66 ; sentence/s 908 ; words/s 68614 ; accuracy train : 62.69
<class 'torch.Tensor'> tensor(16054) 16054
25472 ; loss 0.66 ; sentence/s 923 ; words/s 67836 ; accuracy train : 62.71
<class 'torch.Tensor'> tensor(24210) 24210
38272 ; loss 0.66 ; sentence/s 911 ; words/s 68352 ; accuracy train : 63.05
<class 'torch.Tensor'> tensor(32205) 32205
51072 ; loss 0.66 ; sentence/s 915 ; words/s 68597 ; accuracy train : 62.9
=======
12672 ; loss 0.66 ; sentence/s 454 ; words/s 34337 ; accuracy train : 62.69
<class 'torch.Tensor'> tensor(16054) 16054
25472 ; loss 0.66 ; sentence/s 461 ; words/s 33893 ; accuracy train : 62.71
<class 'torch.Tensor'> tensor(24210) 24210
38272 ; loss 0.66 ; sentence/s 456 ; words/s 34220 ; accuracy train : 63.05
<class 'torch.Tensor'> tensor(32205) 32205
51072 ; loss 0.66 ; sentence/s 458 ; words/s 34355 ; accuracy train : 62.9
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 6 ; mean accuracy train : 62.82

VALIDATION : Epoch 6
togrep : results : epoch 6 ; mean accuracy valid :              62.53
Shrinking lr by : 5. New lr = 3.0431681596800004e-05

TRAINING : Epoch 7
Learning rate : 3.0127364780832004e-05
<class 'torch.Tensor'> tensor(8073) 8073
<<<<<<< HEAD
12672 ; loss 0.66 ; sentence/s 918 ; words/s 68059 ; accuracy train : 63.07
<class 'torch.Tensor'> tensor(16086) 16086
25472 ; loss 0.66 ; sentence/s 919 ; words/s 67601 ; accuracy train : 62.84
<class 'torch.Tensor'> tensor(24122) 24122
38272 ; loss 0.66 ; sentence/s 926 ; words/s 67832 ; accuracy train : 62.82
<class 'torch.Tensor'> tensor(32128) 32128
51072 ; loss 0.66 ; sentence/s 928 ; words/s 67291 ; accuracy train : 62.75
=======
12672 ; loss 0.66 ; sentence/s 464 ; words/s 34376 ; accuracy train : 63.07
<class 'torch.Tensor'> tensor(16086) 16086
25472 ; loss 0.66 ; sentence/s 461 ; words/s 33956 ; accuracy train : 62.84
<class 'torch.Tensor'> tensor(24122) 24122
38272 ; loss 0.66 ; sentence/s 465 ; words/s 34082 ; accuracy train : 62.82
<class 'torch.Tensor'> tensor(32128) 32128
51072 ; loss 0.66 ; sentence/s 467 ; words/s 33852 ; accuracy train : 62.75
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
results : epoch 7 ; mean accuracy train : 62.82

VALIDATION : Epoch 7
togrep : results : epoch 7 ; mean accuracy valid :              62.53
Shrinking lr by : 5. New lr = 6.0254729561664e-06
saving state dict
done saving state dict

TEST : Epoch 8
calculating validation error

VALIDATION : Epoch 1000000.0
finalgrep : accuracy valid : 62.53
calculating test error
finalgrep : accuracy test : 62.69
<<<<<<< HEAD
fin 569.828672170639
=======
fin 1062.2989225387573
>>>>>>> 92a01203ab33ef52a91163ffc69b5ff98cb0c2d9
